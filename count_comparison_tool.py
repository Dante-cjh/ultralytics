#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ£€æµ‹æ•°é‡å¯¹æ¯”å·¥å…· - ç®€åŒ–ç‰ˆæœ¬
é€šè¿‡æ¯”è¾ƒçœŸå®žæ ‡ç­¾å’Œé¢„æµ‹æ ‡ç­¾æ–‡ä»¶çš„è¡Œæ•°æ¥è¯„ä¼°æ£€æµ‹æ•°é‡å‡†ç¡®æ€§

ä½¿ç”¨æ–¹æ³•:
1. ä¿®æ”¹ä¸‹é¢çš„è·¯å¾„å˜é‡
2. è¿è¡Œè„šæœ¬: python count_comparison_tool.py

ä½œè€…: AI Assistant
æ—¥æœŸ: 2025-01-29
"""

import os
from pathlib import Path


def count_lines_in_file(file_path: str) -> int:
    """è®¡ç®—txtæ–‡ä»¶ä¸­çš„éžç©ºè¡Œæ•°"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        return len([line for line in lines if line.strip()])
    except Exception as e:
        print(f"   âŒ è¯»å–æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
        return 0


def check_file_consistency(true_dir: str, pred_dir: str):
    """æ£€æŸ¥æ–‡ä»¶åä¸€è‡´æ€§"""
    print("ðŸ” æ£€æŸ¥æ–‡ä»¶åä¸€è‡´æ€§...")
    print("="*50)
    
    # èŽ·å–æ–‡ä»¶å
    true_files = set(f.stem for f in Path(true_dir).glob("*.txt"))
    pred_files = set(f.stem for f in Path(pred_dir).glob("*.txt"))
    
    print(f"ðŸ“‚ çœŸå®žæ ‡ç­¾: {len(true_files)} ä¸ªæ–‡ä»¶")
    print(f"ðŸ“‚ é¢„æµ‹æ ‡ç­¾: {len(pred_files)} ä¸ªæ–‡ä»¶")
    
    # æ¯”è¾ƒ
    common_files = true_files & pred_files
    only_in_true = true_files - pred_files
    only_in_pred = pred_files - true_files
    
    print(f"\nðŸ“Š æ¯”è¾ƒç»“æžœ:")
    print(f"   å…±åŒæ–‡ä»¶: {len(common_files)}")
    print(f"   ä»…åœ¨çœŸå®žæ ‡ç­¾ä¸­: {len(only_in_true)}")
    print(f"   ä»…åœ¨é¢„æµ‹æ ‡ç­¾ä¸­: {len(only_in_pred)}")
    
    if only_in_true:
        print(f"\nâš ï¸  ä»…åœ¨çœŸå®žæ ‡ç­¾ä¸­çš„æ–‡ä»¶:")
        for filename in sorted(only_in_true)[:5]:
            print(f"   - {filename}.txt")
        if len(only_in_true) > 5:
            print(f"   ... è¿˜æœ‰ {len(only_in_true) - 5} ä¸ª")
    
    if only_in_pred:
        print(f"\nâš ï¸  ä»…åœ¨é¢„æµ‹æ ‡ç­¾ä¸­çš„æ–‡ä»¶:")
        for filename in sorted(only_in_pred)[:5]:
            print(f"   - {filename}.txt")
        if len(only_in_pred) > 5:
            print(f"   ... è¿˜æœ‰ {len(only_in_pred) - 5} ä¸ª")
    
    if len(common_files) == 0:
        print(f"\nâŒ æ²¡æœ‰å…±åŒæ–‡ä»¶ï¼è¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®ã€‚")
        return []
    elif len(only_in_true) == 0 and len(only_in_pred) == 0:
        print(f"\nâœ… æ–‡ä»¶åå®Œå…¨ä¸€è‡´ï¼")
    else:
        print(f"\nâš ï¸  æ–‡ä»¶åä¸å®Œå…¨ä¸€è‡´ï¼Œä½†å¯ä»¥ç»§ç»­å¤„ç†å…±åŒæ–‡ä»¶ã€‚")
    
    return sorted(common_files)


def calculate_accuracy(true_dir: str, pred_dir: str):
    """è®¡ç®—æ£€æµ‹æ•°é‡å‡†ç¡®æ€§"""
    print(f"\nðŸ“Š è®¡ç®—æ£€æµ‹æ•°é‡å‡†ç¡®æ€§...")
    print("="*50)
    
    # æ£€æŸ¥æ–‡ä»¶åä¸€è‡´æ€§
    common_files = check_file_consistency(true_dir, pred_dir)
    
    if not common_files:
        return
    
    # è®¡ç®—æ¯ä¸ªæ–‡ä»¶çš„æ£€æµ‹æ•°é‡
    results = []
    total_true = 0
    total_pred = 0
    
    print(f"\nðŸ”¢ è®¡ç®— {len(common_files)} ä¸ªæ–‡ä»¶çš„æ£€æµ‹æ•°é‡...")
    
    for filename in common_files:
        true_file = Path(true_dir) / f"{filename}.txt"
        pred_file = Path(pred_dir) / f"{filename}.txt"
        
        true_count = count_lines_in_file(str(true_file))
        pred_count = count_lines_in_file(str(pred_file))
        
        # è®¡ç®—metric: 1 - |pred - true| / true
        if true_count > 0:
            metric = 1 - abs(pred_count - true_count) / true_count
        else:
            metric = 1.0 if pred_count == 0 else float('-inf')
        
        results.append({
            "filename": filename,
            "true_count": true_count,
            "pred_count": pred_count,
            "metric": metric,
            "diff": abs(pred_count - true_count)
        })
        
        total_true += true_count
        total_pred += pred_count
    
    # è¿‡æ»¤æœ‰æ•ˆç»“æžœ
    valid_results = [r for r in results if r["metric"] != float('-inf')]
    
    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    if valid_results:
        avg_metric = sum(r["metric"] for r in valid_results) / len(valid_results)
        min_metric = min(r["metric"] for r in valid_results)
        max_metric = max(r["metric"] for r in valid_results)
        
        # æŽ’åºæ‰¾å‡ºæœ€å¥½å’Œæœ€å·®çš„
        sorted_results = sorted(valid_results, key=lambda x: x["metric"], reverse=True)
        top_5 = sorted_results[:5]
        bottom_5 = sorted_results[-5:]
    else:
        avg_metric = min_metric = max_metric = 0
        top_5 = bottom_5 = []
    
    # æ‰“å°ç»“æžœ
    print(f"\nðŸ“ˆ æ€»ä½“ç»Ÿè®¡:")
    print(f"   å¤„ç†æ–‡ä»¶æ•°: {len(results)}")
    print(f"   æœ‰æ•ˆæ–‡ä»¶æ•°: {len(valid_results)}")
    print(f"   æ€»çœŸå®žæ£€æµ‹æ•°: {total_true}")
    print(f"   æ€»é¢„æµ‹æ£€æµ‹æ•°: {total_pred}")
    print(f"   å¹³å‡æ¯æ–‡ä»¶çœŸå®žæ£€æµ‹æ•°: {total_true/len(results):.2f}")
    print(f"   å¹³å‡æ¯æ–‡ä»¶é¢„æµ‹æ£€æµ‹æ•°: {total_pred/len(results):.2f}")
    
    if valid_results:
        print(f"\nðŸŽ¯ Metricå€¼ç»Ÿè®¡:")
        print(f"   å¹³å‡Metricå€¼: {avg_metric:.4f}")
        print(f"   MetricèŒƒå›´: [{min_metric:.4f}, {max_metric:.4f}]")
        
        # åˆ†ç±»ç»Ÿè®¡
        perfect = sum(1 for r in valid_results if r["metric"] == 1.0)
        good = sum(1 for r in valid_results if r["metric"] >= 0.8)
        poor = sum(1 for r in valid_results if r["metric"] < 0.5)
        
        print(f"   å®Œç¾ŽåŒ¹é…: {perfect} ä¸ª ({perfect/len(valid_results)*100:.1f}%)")
        print(f"   è‰¯å¥½é¢„æµ‹: {good} ä¸ª ({good/len(valid_results)*100:.1f}%)")
        print(f"   è¾ƒå·®é¢„æµ‹: {poor} ä¸ª ({poor/len(valid_results)*100:.1f}%)")
        
        print(f"\nðŸ† å‡†ç¡®åº¦æœ€é«˜çš„5ä¸ªæ–‡ä»¶:")
        for i, result in enumerate(top_5):
            print(f"   {i+1}. {result['filename']}.txt: "
                  f"çœŸå®ž={result['true_count']}, é¢„æµ‹={result['pred_count']}, "
                  f"Metric={result['metric']:.4f}")
        
        print(f"\nâš ï¸  å‡†ç¡®åº¦æœ€ä½Žçš„5ä¸ªæ–‡ä»¶:")
        for i, result in enumerate(bottom_5):
            print(f"   {i+1}. {result['filename']}.txt: "
                  f"çœŸå®ž={result['true_count']}, é¢„æµ‹={result['pred_count']}, "
                  f"Metric={result['metric']:.4f}")
    
    print(f"\nðŸŽ‰ åˆ†æžå®Œæˆ!")


def main():
    """ä¸»å‡½æ•°"""
    print("ðŸ”¬ æ£€æµ‹æ•°é‡å¯¹æ¯”å·¥å…·")
    print("é€šè¿‡æ¯”è¾ƒtxtæ–‡ä»¶è¡Œæ•°è¯„ä¼°æ£€æµ‹æ•°é‡å‡†ç¡®æ€§")
    print("="*60)
    
    # ========== è¯·ä¿®æ”¹ä¸‹é¢çš„è·¯å¾„ ==========
    # çœŸå®žæ ‡ç­¾ç›®å½•è·¯å¾„
    true_labels_dir = "/home/cjh/mmdetection/data/balloon/yolo_format/labels/val"
    
    # é¢„æµ‹æ ‡ç­¾ç›®å½•è·¯å¾„  
    pred_labels_dir = "/home/cjh/ultralytics/runs/inference/balloon_yolo11x_20251022_211601_val/predict/labels"
    # =====================================
    
    print(f"ðŸ“‚ çœŸå®žæ ‡ç­¾ç›®å½•: {true_labels_dir}")
    print(f"ðŸ“‚ é¢„æµ‹æ ‡ç­¾ç›®å½•: {pred_labels_dir}")
    
    # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
    if not Path(true_labels_dir).exists():
        print(f"âŒ çœŸå®žæ ‡ç­¾ç›®å½•ä¸å­˜åœ¨: {true_labels_dir}")
        return
    
    if not Path(pred_labels_dir).exists():
        print(f"âŒ é¢„æµ‹æ ‡ç­¾ç›®å½•ä¸å­˜åœ¨: {pred_labels_dir}")
        return
    
    # è®¡ç®—å‡†ç¡®æ€§
    calculate_accuracy(true_labels_dir, pred_labels_dir)


if __name__ == "__main__":
    main()