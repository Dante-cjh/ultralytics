#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ£€æµ‹æ•°é‡å¯¹æ¯”å·¥å…· - ç®€åŒ–ç‰ˆæœ¬
é€šè¿‡æ¯”è¾ƒçœŸå®æ ‡ç­¾å’Œé¢„æµ‹æ ‡ç­¾æ–‡ä»¶çš„è¡Œæ•°æ¥è¯„ä¼°æ£€æµ‹æ•°é‡å‡†ç¡®æ€§

ä½¿ç”¨æ–¹æ³•:
python count_comparison_tool.py --model_name D1_yolov8l_20251028_174321_val

å‚æ•°è¯´æ˜:
  --model_name: æ¨¡å‹åç§°ï¼ˆå¿…éœ€ï¼‰
  --true_labels_dir: çœŸå®æ ‡ç­¾ç›®å½•ï¼ˆå¯é€‰ï¼Œæœ‰é»˜è®¤å€¼ï¼‰
  --good_threshold: å¥½å›¾ç‰‡é˜ˆå€¼ï¼ˆé»˜è®¤0.95ï¼‰
  --bad_threshold: åå›¾ç‰‡é˜ˆå€¼ï¼ˆé»˜è®¤0.1ï¼‰
  --save_images: æ˜¯å¦ä¿å­˜å›¾ç‰‡ï¼ˆé»˜è®¤Trueï¼‰

ä½œè€…: AI Assistant
æ—¥æœŸ: 2025-01-29
"""

import os
import argparse
import shutil
from pathlib import Path


def count_lines_in_file(file_path: str) -> int:
    """è®¡ç®—txtæ–‡ä»¶ä¸­çš„éç©ºè¡Œæ•°"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        return len([line for line in lines if line.strip()])
    except Exception as e:
        print(f"   âŒ è¯»å–æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
        return 0


def check_file_consistency(true_dir: str, pred_dir: str):
    """æ£€æŸ¥æ–‡ä»¶åä¸€è‡´æ€§"""
    print("ğŸ” æ£€æŸ¥æ–‡ä»¶åä¸€è‡´æ€§...")
    print("="*50)
    
    # è·å–æ–‡ä»¶å
    true_files = set(f.stem for f in Path(true_dir).glob("*.txt"))
    pred_files = set(f.stem for f in Path(pred_dir).glob("*.txt"))
    
    print(f"ğŸ“‚ çœŸå®æ ‡ç­¾: {len(true_files)} ä¸ªæ–‡ä»¶")
    print(f"ğŸ“‚ é¢„æµ‹æ ‡ç­¾: {len(pred_files)} ä¸ªæ–‡ä»¶")
    
    # æ¯”è¾ƒ
    common_files = true_files & pred_files
    only_in_true = true_files - pred_files
    only_in_pred = pred_files - true_files
    
    print(f"\nğŸ“Š æ¯”è¾ƒç»“æœ:")
    print(f"   å…±åŒæ–‡ä»¶: {len(common_files)}")
    print(f"   ä»…åœ¨çœŸå®æ ‡ç­¾ä¸­: {len(only_in_true)}")
    print(f"   ä»…åœ¨é¢„æµ‹æ ‡ç­¾ä¸­: {len(only_in_pred)}")
    
    if only_in_true:
        print(f"\nâš ï¸  ä»…åœ¨çœŸå®æ ‡ç­¾ä¸­çš„æ–‡ä»¶:")
        for filename in sorted(only_in_true)[:5]:
            print(f"   - {filename}.txt")
        if len(only_in_true) > 5:
            print(f"   ... è¿˜æœ‰ {len(only_in_true) - 5} ä¸ª")
    
    if only_in_pred:
        print(f"\nâš ï¸  ä»…åœ¨é¢„æµ‹æ ‡ç­¾ä¸­çš„æ–‡ä»¶:")
        for filename in sorted(only_in_pred)[:5]:
            print(f"   - {filename}.txt")
        if len(only_in_pred) > 5:
            print(f"   ... è¿˜æœ‰ {len(only_in_pred) - 5} ä¸ª")
    
    if len(common_files) == 0:
        print(f"\nâŒ æ²¡æœ‰å…±åŒæ–‡ä»¶ï¼è¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®ã€‚")
        return []
    elif len(only_in_true) == 0 and len(only_in_pred) == 0:
        print(f"\nâœ… æ–‡ä»¶åå®Œå…¨ä¸€è‡´ï¼")
    else:
        print(f"\nâš ï¸  æ–‡ä»¶åä¸å®Œå…¨ä¸€è‡´ï¼Œä½†å¯ä»¥ç»§ç»­å¤„ç†å…±åŒæ–‡ä»¶ã€‚")
    
    return sorted(common_files)


def calculate_accuracy(true_dir: str, pred_dir: str, save_images: bool = False, 
                      good_threshold: float = 0.95, bad_threshold: float = 0.1,
                      model_name: str = "", images_dir: str = ""):
    """è®¡ç®—æ£€æµ‹æ•°é‡å‡†ç¡®æ€§
    
    å‚æ•°:
        true_dir: çœŸå®æ ‡ç­¾ç›®å½•
        pred_dir: é¢„æµ‹æ ‡ç­¾ç›®å½•
        save_images: æ˜¯å¦ä¿å­˜å›¾ç‰‡
        good_threshold: å¥½å›¾ç‰‡é˜ˆå€¼ï¼ˆå‡†ç¡®ç‡é«˜äºæ­¤å€¼ï¼‰
        bad_threshold: åå›¾ç‰‡é˜ˆå€¼ï¼ˆå‡†ç¡®ç‡ä½äºæ­¤å€¼ï¼‰
        model_name: æ¨¡å‹åç§°ï¼ˆç”¨äºæ„å»ºä¿å­˜è·¯å¾„ï¼‰
        images_dir: å›¾ç‰‡ç›®å½•
    """
    print(f"\nğŸ“Š è®¡ç®—æ£€æµ‹æ•°é‡å‡†ç¡®æ€§...")
    print("="*50)
    
    # æ£€æŸ¥æ–‡ä»¶åä¸€è‡´æ€§
    common_files = check_file_consistency(true_dir, pred_dir)
    
    if not common_files:
        return
    
    # è®¡ç®—æ¯ä¸ªæ–‡ä»¶çš„æ£€æµ‹æ•°é‡
    results = []
    total_true = 0
    total_pred = 0
    
    print(f"\nğŸ”¢ è®¡ç®— {len(common_files)} ä¸ªæ–‡ä»¶çš„æ£€æµ‹æ•°é‡...")
    
    for filename in common_files:
        true_file = Path(true_dir) / f"{filename}.txt"
        pred_file = Path(pred_dir) / f"{filename}.txt"
        
        true_count = count_lines_in_file(str(true_file))
        pred_count = count_lines_in_file(str(pred_file))
        
        # è®¡ç®—metric: 1 - |pred - true| / true
        if true_count > 0:
            metric = 1 - abs(pred_count - true_count) / true_count
        else:
            metric = 1.0 if pred_count == 0 else float('-inf')
        
        results.append({
            "filename": filename,
            "true_count": true_count,
            "pred_count": pred_count,
            "metric": metric,
            "diff": abs(pred_count - true_count)
        })
        
        total_true += true_count
        total_pred += pred_count
    
    # è¿‡æ»¤æœ‰æ•ˆç»“æœ
    valid_results = [r for r in results if r["metric"] != float('-inf')]
    
    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    if valid_results:
        avg_metric = sum(r["metric"] for r in valid_results) / len(valid_results)
        min_metric = min(r["metric"] for r in valid_results)
        max_metric = max(r["metric"] for r in valid_results)
        
        # æ’åºæ‰¾å‡ºæœ€å¥½å’Œæœ€å·®çš„
        sorted_results = sorted(valid_results, key=lambda x: x["metric"], reverse=True)
        top_5 = sorted_results[:5]
        bottom_5 = sorted_results[-5:]
    else:
        avg_metric = min_metric = max_metric = 0
        top_5 = bottom_5 = []
    
    # æ‰“å°ç»“æœ
    print(f"\nğŸ“ˆ æ€»ä½“ç»Ÿè®¡:")
    print(f"   å¤„ç†æ–‡ä»¶æ•°: {len(results)}")
    print(f"   æœ‰æ•ˆæ–‡ä»¶æ•°: {len(valid_results)}")
    print(f"   æ€»çœŸå®æ£€æµ‹æ•°: {total_true}")
    print(f"   æ€»é¢„æµ‹æ£€æµ‹æ•°: {total_pred}")
    print(f"   å·®å€¼: {total_pred - total_true} ({'+' if total_pred >= total_true else ''}{total_pred - total_true})")
    print(f"   å¹³å‡æ¯æ–‡ä»¶çœŸå®æ£€æµ‹æ•°: {total_true/len(results):.2f}")
    print(f"   å¹³å‡æ¯æ–‡ä»¶é¢„æµ‹æ£€æµ‹æ•°: {total_pred/len(results):.2f}")
    
    # è®¡ç®—å…¨å±€Metricï¼ˆåŸºäºæ€»æ•°ï¼‰
    if total_true > 0:
        global_metric = 1 - abs(total_pred - total_true) / total_true
        global_error_rate = abs(total_pred - total_true) / total_true
    else:
        global_metric = 1.0 if total_pred == 0 else 0.0
        global_error_rate = 0.0
    
    if valid_results:
        print(f"\nğŸ¯ Metricå€¼ç»Ÿè®¡ (ä¸¤ç§è®¡ç®—æ–¹æ³•):")
        print(f"   â”Œâ”€ æ–¹æ³•1: æ ·æœ¬å¹³å‡Metric = {avg_metric:.4f}")
        print(f"   â”‚  è¯´æ˜: å…ˆè®¡ç®—æ¯ä¸ªæ ·æœ¬çš„metricï¼Œå†æ±‚å¹³å‡")
        print(f"   â”‚  è®¡ç®—: mean([metric_1, metric_2, ..., metric_n])")
        print(f"   â”‚")
        print(f"   â””â”€ æ–¹æ³•2: å…¨å±€æ€»æ•°Metric = {global_metric:.4f}")
        print(f"      è¯´æ˜: åŸºäºæ‰€æœ‰é¢„æµ‹æ¡†æ€»æ•° vs æ‰€æœ‰çœŸå®æ¡†æ€»æ•°")
        print(f"      è®¡ç®—: 1 - |{total_pred} - {total_true}| / {total_true} = {global_metric:.4f}")
        print(f"      å…¨å±€è¯¯å·®ç‡: {global_error_rate:.2%}")
        print(f"")
        print(f"   æ ·æœ¬MetricèŒƒå›´: [{min_metric:.4f}, {max_metric:.4f}]")
        
        # åˆ†ç±»ç»Ÿè®¡
        perfect = sum(1 for r in valid_results if r["metric"] == 1.0)
        good = sum(1 for r in valid_results if r["metric"] >= 0.8)
        poor = sum(1 for r in valid_results if r["metric"] < 0.5)
        
        print(f"   å®Œç¾åŒ¹é…: {perfect} ä¸ª ({perfect/len(valid_results)*100:.1f}%)")
        print(f"   è‰¯å¥½é¢„æµ‹: {good} ä¸ª ({good/len(valid_results)*100:.1f}%)")
        print(f"   è¾ƒå·®é¢„æµ‹: {poor} ä¸ª ({poor/len(valid_results)*100:.1f}%)")
        
        print(f"\nğŸ† å‡†ç¡®åº¦æœ€é«˜çš„5ä¸ªæ–‡ä»¶:")
        for i, result in enumerate(top_5):
            print(f"   {i+1}. {result['filename']}.txt: "
                  f"çœŸå®={result['true_count']}, é¢„æµ‹={result['pred_count']}, "
                  f"Metric={result['metric']:.4f}")
        
        print(f"\nâš ï¸  å‡†ç¡®åº¦æœ€ä½çš„5ä¸ªæ–‡ä»¶:")
        for i, result in enumerate(bottom_5):
            print(f"   {i+1}. {result['filename']}.txt: "
                  f"çœŸå®={result['true_count']}, é¢„æµ‹={result['pred_count']}, "
                  f"Metric={result['metric']:.4f}")
    
    # ä¿å­˜å¥½å›¾ç‰‡å’Œåå›¾ç‰‡
    if save_images and model_name and images_dir:
        print(f"\nğŸ’¾ å¼€å§‹ä¿å­˜å›¾ç‰‡...")
        print(f"   å¥½å›¾ç‰‡é˜ˆå€¼: {good_threshold}")
        print(f"   åå›¾ç‰‡é˜ˆå€¼: {bad_threshold}")
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        save_base_dir = Path("/public/home/baichen/download/dcu_yolo/ultralytics/runs/good_bad_imgs") / model_name
        good_img_dir = save_base_dir / "good_img"
        bad_img_dir = save_base_dir / "bad_img"
        
        good_img_dir.mkdir(parents=True, exist_ok=True)
        bad_img_dir.mkdir(parents=True, exist_ok=True)
        
        good_count = 0
        bad_count = 0
        
        # éå†æ‰€æœ‰ç»“æœï¼Œä¿å­˜ç¬¦åˆæ¡ä»¶çš„å›¾ç‰‡
        for result in valid_results:
            metric = result["metric"]
            filename = result["filename"]
            
            # æŸ¥æ‰¾å¯¹åº”çš„å›¾ç‰‡æ–‡ä»¶ï¼ˆæ”¯æŒå¸¸è§çš„å›¾ç‰‡æ ¼å¼ï¼‰
            image_found = False
            for ext in ['.jpg', '.jpeg', '.png', '.bmp', '.JPG', '.JPEG', '.PNG', '.BMP']:
                image_path = Path(images_dir) / f"{filename}{ext}"
                if image_path.exists():
                    image_found = True
                    
                    # åˆ¤æ–­æ˜¯å¥½å›¾ç‰‡è¿˜æ˜¯åå›¾ç‰‡
                    if metric >= good_threshold:
                        # å¤åˆ¶åˆ°good_imgç›®å½•
                        dst_path = good_img_dir / f"{filename}{ext}"
                        shutil.copy2(str(image_path), str(dst_path))
                        good_count += 1
                    elif metric <= bad_threshold:
                        # å¤åˆ¶åˆ°bad_imgç›®å½•
                        dst_path = bad_img_dir / f"{filename}{ext}"
                        shutil.copy2(str(image_path), str(dst_path))
                        bad_count += 1
                    
                    break
            
            if not image_found and (metric >= good_threshold or metric <= bad_threshold):
                print(f"   âš ï¸  æœªæ‰¾åˆ°å›¾ç‰‡: {filename}")
        
        print(f"\nâœ… å›¾ç‰‡ä¿å­˜å®Œæˆ!")
        print(f"   ä¿å­˜è·¯å¾„: {save_base_dir}")
        print(f"   å¥½å›¾ç‰‡æ•°é‡: {good_count} ä¸ª (å‡†ç¡®ç‡ >= {good_threshold})")
        print(f"   åå›¾ç‰‡æ•°é‡: {bad_count} ä¸ª (å‡†ç¡®ç‡ <= {bad_threshold})")
    elif save_images:
        print(f"\nâš ï¸  æœªèƒ½ä¿å­˜å›¾ç‰‡: ç¼ºå°‘å¿…è¦å‚æ•°ï¼ˆmodel_nameæˆ–images_dirï¼‰")
    
    print(f"\nğŸ‰ åˆ†æå®Œæˆ!")


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description='æ£€æµ‹æ•°é‡å¯¹æ¯”å·¥å…· - è¯„ä¼°YOLOæ£€æµ‹æ•°é‡å‡†ç¡®æ€§',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument(
        '--model_name',
        type=str,
        required=True,
        help='æ¨¡å‹åç§°ï¼Œä¾‹å¦‚: balloon_yolo11x_20251022_211601_val'
    )
    
    parser.add_argument(
        '--true_labels_dir',
        type=str,
        default='/public/home/baichen/download/dcu_yolo/ultralytics/data/D1_type3/yolo_format/labels/val',
        help='çœŸå®æ ‡ç­¾ç›®å½•è·¯å¾„ (é»˜è®¤: /public/home/baichen/download/dcu_yolo/ultralytics/data/D1_type3/yolo_format/labels/val)'
    )
    
    parser.add_argument(
        '--good_threshold',
        type=float,
        default=1,
        help='å¥½å›¾ç‰‡çš„å‡†ç¡®ç‡é˜ˆå€¼ (é»˜è®¤: 0.95)'
    )
    
    parser.add_argument(
        '--bad_threshold',
        type=float,
        default=0.3,
        help='åå›¾ç‰‡çš„å‡†ç¡®ç‡é˜ˆå€¼ (é»˜è®¤: 0.1)'
    )
    
    parser.add_argument(
        '--save_images',
        type=lambda x: x.lower() in ['true', '1', 'yes', 'y'],
        default=True,
        help='æ˜¯å¦ä¿å­˜å›¾ç‰‡ (é»˜è®¤: True)'
    )
    
    parser.add_argument(
        '--images_dir',
        type=str,
        default='/public/home/baichen/download/dcu_yolo/ultralytics/data/D1_type3/yolo_format/images/val',
        help='å›¾ç‰‡ç›®å½•è·¯å¾„ (é»˜è®¤: /public/home/baichen/download/dcu_yolo/ultralytics/data/D1_type3/yolo_format/images/val)'
    )
    
    return parser.parse_args()


def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parse_args()
    
    print("ğŸ”¬ æ£€æµ‹æ•°é‡å¯¹æ¯”å·¥å…·")
    print("é€šè¿‡æ¯”è¾ƒtxtæ–‡ä»¶è¡Œæ•°è¯„ä¼°æ£€æµ‹æ•°é‡å‡†ç¡®æ€§")
    print("="*60)
    
    # æ„å»ºé¢„æµ‹æ ‡ç­¾ç›®å½•è·¯å¾„
    pred_labels_dir = f"/public/home/baichen/download/dcu_yolo/ultralytics/runs/inference/{args.model_name}/predict/labels"
    
    print(f"\nğŸ“‹ å‚æ•°è®¾ç½®:")
    print(f"   æ¨¡å‹åç§°: {args.model_name}")
    print(f"   çœŸå®æ ‡ç­¾ç›®å½•: {args.true_labels_dir}")
    print(f"   é¢„æµ‹æ ‡ç­¾ç›®å½•: {pred_labels_dir}")
    print(f"   å›¾ç‰‡ç›®å½•: {args.images_dir}")
    print(f"   å¥½å›¾ç‰‡é˜ˆå€¼: {args.good_threshold}")
    print(f"   åå›¾ç‰‡é˜ˆå€¼: {args.bad_threshold}")
    print(f"   ä¿å­˜å›¾ç‰‡: {'æ˜¯' if args.save_images else 'å¦'}")
    
    # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
    if not Path(args.true_labels_dir).exists():
        print(f"\nâŒ çœŸå®æ ‡ç­¾ç›®å½•ä¸å­˜åœ¨: {args.true_labels_dir}")
        return
    
    if not Path(pred_labels_dir).exists():
        print(f"\nâŒ é¢„æµ‹æ ‡ç­¾ç›®å½•ä¸å­˜åœ¨: {pred_labels_dir}")
        return
    
    if args.save_images and not Path(args.images_dir).exists():
        print(f"\nâš ï¸  è­¦å‘Š: å›¾ç‰‡ç›®å½•ä¸å­˜åœ¨: {args.images_dir}")
        print(f"   å°†ç»§ç»­è¿›è¡Œå‡†ç¡®ç‡è®¡ç®—ï¼Œä½†ä¸ä¼šä¿å­˜å›¾ç‰‡")
        args.save_images = False
    
    # è®¡ç®—å‡†ç¡®æ€§
    calculate_accuracy(
        true_dir=args.true_labels_dir,
        pred_dir=pred_labels_dir,
        save_images=args.save_images,
        good_threshold=args.good_threshold,
        bad_threshold=args.bad_threshold,
        model_name=args.model_name,
        images_dir=args.images_dir
    )


if __name__ == "__main__":
    main()