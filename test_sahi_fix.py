#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æµ‹è¯•SAHIæ¨ç†ä¿®å¤æ•ˆæœ - æ¯”è¾ƒåˆ‡ç‰‡å’Œåˆå¹¶ç»“æœ
"""

import sys
from pathlib import Path
import cv2
import numpy as np
from sahi.predict import get_sliced_prediction
from sahi.utils.cv import read_image
from sahi import AutoDetectionModel

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent))

from balloon_inference_with_sahi import BalloonSAHIInference
from ultralytics.utils import LOGGER

def visualize_slices(image, detection_model, slice_height=640, slice_width=640, overlap_ratio=0.2):
    """å¯è§†åŒ–åˆ‡ç‰‡è¿‡ç¨‹"""
    h, w = image.shape[:2]
    LOGGER.info(f"ğŸ“ å›¾åƒå°ºå¯¸: {w}x{h}")
    LOGGER.info(f"ğŸ”ª åˆ‡ç‰‡å‚æ•°: {slice_width}x{slice_height}, é‡å : {overlap_ratio:.1%}")
    
    # è®¡ç®—åˆ‡ç‰‡æ•°é‡
    step_h = int(slice_height * (1 - overlap_ratio))
    step_w = int(slice_width * (1 - overlap_ratio))
    
    num_slices_h = max(1, (h - slice_height) // step_h + 1)
    num_slices_w = max(1, (w - slice_width) // step_w + 1)
    
    LOGGER.info(f"ğŸ“Š åˆ‡ç‰‡æ•°é‡: {num_slices_w} x {num_slices_h} = {num_slices_w * num_slices_h} ä¸ªåˆ‡ç‰‡")
    
    # åˆ›å»ºåˆ‡ç‰‡å¯è§†åŒ–å›¾åƒ
    slice_vis = image.copy()
    
    # ç»˜åˆ¶åˆ‡ç‰‡ç½‘æ ¼
    for i in range(num_slices_h):
        for j in range(num_slices_w):
            y1 = i * step_h
            x1 = j * step_w
            y2 = min(y1 + slice_height, h)
            x2 = min(x1 + slice_width, w)
            
            # ç»˜åˆ¶åˆ‡ç‰‡è¾¹ç•Œï¼ˆçº¢è‰²ï¼‰
            cv2.rectangle(slice_vis, (x1, y1), (x2, y2), (0, 0, 255), 2)
            
            # æ·»åŠ åˆ‡ç‰‡ç¼–å·
            cv2.putText(slice_vis, f"{i*num_slices_w + j + 1}", 
                       (x1 + 5, y1 + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
    
    return slice_vis, num_slices_h, num_slices_w

def test_individual_slices(image, detection_model, slice_height=640, slice_width=640, overlap_ratio=0.2, save_dir="runs/sahi_inference/test_fix"):
    """æµ‹è¯•æ¯ä¸ªåˆ‡ç‰‡çš„å•ç‹¬æ£€æµ‹ç»“æœ"""
    h, w = image.shape[:2]
    
    # è®¡ç®—åˆ‡ç‰‡å‚æ•°
    step_h = int(slice_height * (1 - overlap_ratio))
    step_w = int(slice_width * (1 - overlap_ratio))
    
    num_slices_h = max(1, (h - slice_height) // step_h + 1)
    num_slices_w = max(1, (w - slice_width) // step_w + 1)
    
    LOGGER.info(f"ğŸ” å¼€å§‹æµ‹è¯•æ¯ä¸ªåˆ‡ç‰‡çš„æ£€æµ‹ç»“æœ...")
    
    # åˆ›å»ºåˆ‡ç‰‡ç»“æœç›®å½•
    slice_dir = Path(save_dir) / "individual_slices"
    slice_dir.mkdir(parents=True, exist_ok=True)
    
    slice_results = []
    
    for i in range(num_slices_h):
        for j in range(num_slices_w):
            y1 = i * step_h
            x1 = j * step_w
            y2 = min(y1 + slice_height, h)
            x2 = min(x1 + slice_width, w)
            
            # æå–åˆ‡ç‰‡
            slice_img = image[y1:y2, x1:x2]
            
            # å¯¹åˆ‡ç‰‡è¿›è¡Œæ£€æµ‹
            try:
                slice_result = get_sliced_prediction(
                    slice_img,
                    detection_model,
                    slice_height=slice_height,
                    slice_width=slice_width,
                    overlap_height_ratio=0.0,  # å•ä¸ªåˆ‡ç‰‡ä¸éœ€è¦é‡å 
                    overlap_width_ratio=0.0,
                )
                
                # å¯è§†åŒ–åˆ‡ç‰‡æ£€æµ‹ç»“æœ
                vis_slice = slice_img.copy()
                for pred in slice_result.object_prediction_list:
                    bbox = pred.bbox.to_xyxy()
                    x1_det, y1_det, x2_det, y2_det = map(int, bbox)
                    
                    # ç»˜åˆ¶æ£€æµ‹æ¡†
                    cv2.rectangle(vis_slice, (x1_det, y1_det), (x2_det, y2_det), (0, 255, 0), 2)
                    
                    # ç»˜åˆ¶æ ‡ç­¾
                    label = f"{pred.category.name}: {pred.score.value:.2f}"
                    cv2.putText(vis_slice, label, (x1_det, y1_det - 5), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
                
                # ä¿å­˜åˆ‡ç‰‡æ£€æµ‹ç»“æœ
                slice_filename = f"slice_{i*num_slices_w + j + 1:02d}_detection.jpg"
                slice_path = slice_dir / slice_filename
                cv2.imwrite(str(slice_path), cv2.cvtColor(vis_slice, cv2.COLOR_RGB2BGR))
                
                slice_results.append({
                    'slice_id': i * num_slices_w + j + 1,
                    'coordinates': (x1, y1, x2, y2),
                    'detections': len(slice_result.object_prediction_list),
                    'result': slice_result
                })
                
                LOGGER.info(f"   åˆ‡ç‰‡ {i*num_slices_w + j + 1}: ä½ç½®({x1},{y1})-({x2},{y2}), æ£€æµ‹åˆ°{len(slice_result.object_prediction_list)}ä¸ªç›®æ ‡")
                
            except Exception as e:
                LOGGER.error(f"   åˆ‡ç‰‡ {i*num_slices_w + j + 1} æ£€æµ‹å¤±è´¥: {e}")
    
    LOGGER.info(f"ğŸ“ åˆ‡ç‰‡æ£€æµ‹ç»“æœä¿å­˜åˆ°: {slice_dir}")
    return slice_results

def test_sahi_inference():
    """æµ‹è¯•SAHIæ¨ç† - æ¯”è¾ƒåˆ‡ç‰‡å’Œåˆå¹¶ç»“æœ"""
    
    # æµ‹è¯•å‚æ•°
    model_path = "runs/detect/balloon_yolo11l_slice_20251023_102255/weights/best.pt"
    test_image = "/home/cjh/mmdetection/data/balloon/yolo_format/images/val/24631331976_defa3bb61f_k.jpg"
    save_dir = "runs/sahi_inference/test_fix"
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not Path(model_path).exists():
        LOGGER.error(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return False
    
    if not Path(test_image).exists():
        LOGGER.error(f"âŒ æµ‹è¯•å›¾åƒä¸å­˜åœ¨: {test_image}")
        return False
    
    try:
        # åˆ›å»ºæ¨ç†å™¨
        LOGGER.info("ğŸš€ å¼€å§‹æµ‹è¯•SAHIæ¨ç†ä¿®å¤...")
        inferencer = BalloonSAHIInference(
            model_path=model_path,
            confidence_threshold=0.25,
            device="cuda:5"
        )
        
        # è¯»å–å›¾åƒ
        image = read_image(test_image)
        h, w = image.shape[:2]
        
        # 1. å¯è§†åŒ–åˆ‡ç‰‡è¿‡ç¨‹
        LOGGER.info("ğŸ“¸ æ­¥éª¤1: å¯è§†åŒ–åˆ‡ç‰‡è¿‡ç¨‹...")
        slice_vis, num_slices_h, num_slices_w = visualize_slices(
            image, inferencer.detection_model, 640, 640, 0.2
        )
        
        # ä¿å­˜åˆ‡ç‰‡å¯è§†åŒ–
        Path(save_dir).mkdir(parents=True, exist_ok=True)
        slice_path = Path(save_dir) / "slice_visualization.jpg"
        cv2.imwrite(str(slice_path), cv2.cvtColor(slice_vis, cv2.COLOR_RGB2BGR))
        LOGGER.info(f"   åˆ‡ç‰‡å¯è§†åŒ–ä¿å­˜åˆ°: {slice_path}")
        
        # 2. æµ‹è¯•æ¯ä¸ªåˆ‡ç‰‡çš„å•ç‹¬æ£€æµ‹ç»“æœ
        LOGGER.info("ğŸ” æ­¥éª¤2: æµ‹è¯•æ¯ä¸ªåˆ‡ç‰‡çš„å•ç‹¬æ£€æµ‹ç»“æœ...")
        slice_results = test_individual_slices(
            image, inferencer.detection_model, 640, 640, 0.2, save_dir
        )
        
        # 3. æ‰§è¡ŒSAHIæ¨ç†ï¼ˆåˆå¹¶ç»“æœï¼‰
        LOGGER.info("ğŸ” æ­¥éª¤3: æ‰§è¡ŒSAHIæ¨ç†...")
        result = inferencer.predict_image(
            image_path=test_image,
            slice_height=640,
            slice_width=640,
            overlap_height_ratio=0.2,
            overlap_width_ratio=0.2,
            save_dir=save_dir,
            visualize=True
        )
        
        # 4. åˆ›å»ºå¯¹æ¯”å›¾åƒ
        LOGGER.info("ğŸ“Š æ­¥éª¤4: åˆ›å»ºå¯¹æ¯”å›¾åƒ...")
        comparison = np.hstack([
            slice_vis,  # å·¦ä¾§ï¼šåˆ‡ç‰‡å¯è§†åŒ–
            cv2.imread(str(Path(save_dir) / f"{Path(test_image).stem}_visual.jpg"))  # å³ä¾§ï¼šåˆå¹¶ç»“æœ
        ])
        
        # æ·»åŠ æ ‡é¢˜
        cv2.putText(comparison, "Slice Visualization", (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
        cv2.putText(comparison, "SAHI Merged Result", (w + 10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        
        # ä¿å­˜å¯¹æ¯”å›¾åƒ
        comparison_path = Path(save_dir) / "comparison.jpg"
        cv2.imwrite(str(comparison_path), comparison)
        LOGGER.info(f"   å¯¹æ¯”å›¾åƒä¿å­˜åˆ°: {comparison_path}")
        
        # 5. ç»Ÿè®¡å’Œæ€»ç»“
        total_slice_detections = sum(sr['detections'] for sr in slice_results)
        LOGGER.info(f"âœ… æµ‹è¯•å®Œæˆï¼")
        LOGGER.info(f"   å›¾åƒå°ºå¯¸: {result['image_size']}")
        LOGGER.info(f"   åˆ‡ç‰‡æ•°é‡: {num_slices_w} x {num_slices_h}")
        LOGGER.info(f"   åˆ‡ç‰‡æ£€æµ‹æ€»æ•°: {total_slice_detections}")
        LOGGER.info(f"   SAHIåˆå¹¶æ£€æµ‹æ•°: {result['num_detections']}")
        LOGGER.info(f"   ç»“æœä¿å­˜åˆ°: {save_dir}")
        LOGGER.info(f"   - åˆ‡ç‰‡å¯è§†åŒ–: {slice_path}")
        LOGGER.info(f"   - å¯¹æ¯”å›¾åƒ: {comparison_path}")
        LOGGER.info(f"   - å•ç‹¬åˆ‡ç‰‡æ£€æµ‹: {Path(save_dir) / 'individual_slices'}")
        
        return True
        
    except Exception as e:
        LOGGER.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_sahi_inference()
    if success:
        print("\nğŸ‰ SAHIæ¨ç†ä¿®å¤æµ‹è¯•æˆåŠŸï¼")
    else:
        print("\nâŒ SAHIæ¨ç†ä¿®å¤æµ‹è¯•å¤±è´¥ï¼")
