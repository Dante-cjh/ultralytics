#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
D1 æ•°æ®é›† SAHI åˆ‡ç‰‡æ¨ç†è„šæœ¬
ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹å¯¹å¤§å°ºå¯¸å›¾åƒè¿›è¡Œåˆ‡ç‰‡æ¨ç†
"""

import argparse
from pathlib import Path
from typing import Optional

import cv2
import numpy as np
from sahi import AutoDetectionModel
from sahi.predict import get_sliced_prediction
from sahi.utils.cv import read_image

from ultralytics.utils import LOGGER

# æ£€æŸ¥SAHIç‰ˆæœ¬
try:
    import sahi
    LOGGER.info(f"ğŸ“¦ SAHIç‰ˆæœ¬: {sahi.__version__}")
except ImportError:
    LOGGER.error("âŒ SAHIæœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install sahi")
    exit(1)


class BalloonSAHIInference:
    """D1 æ•°æ®é›† SAHI åˆ‡ç‰‡æ¨ç†ç±»"""
    
    def __init__(
        self,
        model_path: str,
        confidence_threshold: float = 0.25,
        device: str = "cuda:0"
    ):
        """
        åˆå§‹åŒ– SAHI æ¨ç†å™¨
        
        Args:
            model_path (str): è®­ç»ƒå¥½çš„æ¨¡å‹è·¯å¾„
            confidence_threshold (float): ç½®ä¿¡åº¦é˜ˆå€¼
            device (str): è®¾å¤‡ ('cuda:0' æˆ– 'cpu')
        """
        self.model_path = Path(model_path)
        self.confidence_threshold = confidence_threshold
        self.device = device
        self.detection_model = None
        
        # éªŒè¯æ¨¡å‹æ–‡ä»¶
        if not self.model_path.exists():
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
        
        LOGGER.info(f"ğŸ” åŠ è½½æ¨¡å‹: {self.model_path}")
        self._load_model()
    
    def _load_model(self):
        """åŠ è½½ YOLO æ¨¡å‹"""
        try:
            # SAHI 0.11.14 ä½¿ç”¨ yolov8 ä½œä¸º model_type
            self.detection_model = AutoDetectionModel.from_pretrained(
                model_type="yolov8",
                model_path=str(self.model_path),
                confidence_threshold=self.confidence_threshold,
                device=self.device,
            )
            LOGGER.info(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
            LOGGER.info(f"   æ¨¡å‹è·¯å¾„: {self.model_path}")
            LOGGER.info(f"   ç½®ä¿¡åº¦é˜ˆå€¼: {self.confidence_threshold}")
            LOGGER.info(f"   è®¾å¤‡: {self.device}")
        except Exception as e:
            LOGGER.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise
    
    def predict_image(
        self,
        image_path: str,
        slice_height: int = 640,
        slice_width: int = 640,
        overlap_height_ratio: float = 0.15,
        overlap_width_ratio: float = 0.15,
        postprocess_type: str = "NMS",
        postprocess_threshold: float = 0.5,
        postprocess_metric: str = "IOS",
        save_dir: Optional[str] = None,
        visualize: bool = True,
        save_txt: bool = True,
        save_conf: bool = True,
        min_box_area: int = 100,  # æœ€å°æ£€æµ‹æ¡†é¢ç§¯
        max_detections: int = 100,  # æœ€å¤§æ£€æµ‹æ•°é‡
    ) -> dict:
        """
        å¯¹å•å¼ å›¾åƒè¿›è¡Œåˆ‡ç‰‡æ¨ç†
        
        Args:
            image_path (str): å›¾åƒè·¯å¾„
            slice_height (int): åˆ‡ç‰‡é«˜åº¦
            slice_width (int): åˆ‡ç‰‡å®½åº¦
            overlap_height_ratio (float): é«˜åº¦é‡å æ¯”ä¾‹ (0.0-1.0)
            overlap_width_ratio (float): å®½åº¦é‡å æ¯”ä¾‹ (0.0-1.0)
            save_dir (str, optional): ä¿å­˜å¯è§†åŒ–ç»“æœçš„ç›®å½•
            visualize (bool): æ˜¯å¦ä¿å­˜å¯è§†åŒ–ç»“æœ
        
        Returns:
            dict: åŒ…å«æ£€æµ‹ç»“æœçš„å­—å…¸
        """
        image_path = Path(image_path)
        if not image_path.exists():
            raise FileNotFoundError(f"å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
        
        LOGGER.info(f"ğŸ“¸ å¤„ç†å›¾åƒ: {image_path.name}")
        
        # è¯»å–å›¾åƒ
        image = read_image(str(image_path))
        h, w = image.shape[:2]
        LOGGER.info(f"   å›¾åƒå°ºå¯¸: {w}x{h}")
        
        # æ‰§è¡Œåˆ‡ç‰‡æ¨ç†
        try:
            LOGGER.info(f"   å¼€å§‹SAHIåˆ‡ç‰‡æ¨ç†...")
            LOGGER.info(f"   åˆ‡ç‰‡å‚æ•°: {slice_width}x{slice_height}, é‡å : {overlap_width_ratio:.1%}x{overlap_height_ratio:.1%}")
            
            result = get_sliced_prediction(
                image,
                self.detection_model,
                slice_height=slice_height,
                slice_width=slice_width,
                overlap_height_ratio=overlap_height_ratio,
                overlap_width_ratio=overlap_width_ratio,
                postprocess_type=postprocess_type,  # ä½¿ç”¨NMSå»é™¤é‡å¤æ£€æµ‹æ¡†
                postprocess_match_metric=postprocess_metric,  # ä½¿ç”¨IOSåŒ¹é…æŒ‡æ ‡
                postprocess_match_threshold=postprocess_threshold,  # NMS IoUé˜ˆå€¼
                postprocess_class_agnostic=False,  # ç±»åˆ«æ„ŸçŸ¥çš„NMS
            )
            LOGGER.info(f"   SAHIæ¨ç†å®Œæˆ")
            LOGGER.info(f"   åŸå§‹æ£€æµ‹æ•°é‡: {len(result.object_prediction_list)}")
        except Exception as e:
            LOGGER.error(f"   âŒ SAHIæ¨ç†å¤±è´¥: {e}")
            raise
        
        # åº”ç”¨é¢å¤–çš„è¿‡æ»¤é€»è¾‘
        filtered_predictions = []
        for pred in result.object_prediction_list:
            bbox = pred.bbox.to_xyxy()
            x1, y1, x2, y2 = bbox
            box_area = (x2 - x1) * (y2 - y1)
            
            # è¿‡æ»¤æ¡ä»¶
            if box_area >= min_box_area:
                filtered_predictions.append(pred)
        
        # æŒ‰ç½®ä¿¡åº¦æ’åºå¹¶é™åˆ¶æ•°é‡
        filtered_predictions.sort(key=lambda x: x.score.value, reverse=True)
        if len(filtered_predictions) > max_detections:
            filtered_predictions = filtered_predictions[:max_detections]
            LOGGER.info(f"   æ£€æµ‹æ¡†æ•°é‡é™åˆ¶: {len(result.object_prediction_list)} -> {max_detections}")
        
        # æ›´æ–°ç»“æœ
        result.object_prediction_list = filtered_predictions
        
        # ç»Ÿè®¡æ£€æµ‹ç»“æœ
        num_detections = len(result.object_prediction_list)
        LOGGER.info(f"   æ£€æµ‹åˆ° {num_detections} ä¸ªç›®æ ‡ (è¿‡æ»¤å)")
        
        # è°ƒè¯•ä¿¡æ¯ï¼šæ‰“å°æ£€æµ‹ç»“æœè¯¦æƒ…
        if num_detections > 0:
            LOGGER.info(f"   æ£€æµ‹è¯¦æƒ…:")
            # æŒ‰ç½®ä¿¡åº¦æ’åºæ˜¾ç¤º
            sorted_predictions = sorted(result.object_prediction_list, 
                                      key=lambda x: x.score.value, reverse=True)
            for i, pred in enumerate(sorted_predictions[:5]):  # åªæ˜¾ç¤ºå‰5ä¸ª
                bbox = pred.bbox.to_xyxy()
                LOGGER.info(f"     [{i+1}] {pred.category.name}: {pred.score.value:.3f} "
                           f"bbox=({bbox[0]:.1f}, {bbox[1]:.1f}, {bbox[2]:.1f}, {bbox[3]:.1f})")
            if num_detections > 5:
                LOGGER.info(f"     ... è¿˜æœ‰ {num_detections - 5} ä¸ªæ£€æµ‹ç»“æœ")
            
            # ç»Ÿè®¡ç½®ä¿¡åº¦åˆ†å¸ƒ
            confidences = [pred.score.value for pred in result.object_prediction_list]
            LOGGER.info(f"   ç½®ä¿¡åº¦ç»Ÿè®¡: æœ€é«˜={max(confidences):.3f}, æœ€ä½={min(confidences):.3f}, å¹³å‡={sum(confidences)/len(confidences):.3f}")
        
        # ä¿å­˜å¯è§†åŒ–ç»“æœ
        if visualize and save_dir:
            save_path = Path(save_dir)
            save_path.mkdir(parents=True, exist_ok=True)
            
            # æ‰‹åŠ¨ç»˜åˆ¶æ£€æµ‹æ¡†ï¼ˆä¿®å¤ç‰ˆæœ¬ï¼‰
            vis_image = image.copy()
            img_h, img_w = vis_image.shape[:2]
            
            for pred in result.object_prediction_list:
                bbox = pred.bbox.to_xyxy()
                x1, y1, x2, y2 = map(int, bbox)
                
                # è¾¹ç•Œæ£€æŸ¥ï¼šç¡®ä¿åæ ‡åœ¨å›¾åƒèŒƒå›´å†…
                x1 = max(0, min(x1, img_w - 1))
                y1 = max(0, min(y1, img_h - 1))
                x2 = max(0, min(x2, img_w - 1))
                y2 = max(0, min(y2, img_h - 1))
                
                # ç¡®ä¿è¾¹ç•Œæ¡†æœ‰æ•ˆ
                if x2 > x1 and y2 > y1:
                    # ç»˜åˆ¶è¾¹ç•Œæ¡†ï¼ˆç»¿è‰²ï¼‰
                    cv2.rectangle(vis_image, (x1, y1), (x2, y2), (0, 255, 0), 2)
                    
                    # ç»˜åˆ¶æ ‡ç­¾å’Œç½®ä¿¡åº¦
                    label = f"{pred.category.name}: {pred.score.value:.2f}"
                    
                    # è®¡ç®—æ ‡ç­¾èƒŒæ™¯å¤§å°
                    (label_w, label_h), baseline = cv2.getTextSize(
                        label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2
                    )
                    
                    # è®¡ç®—æ ‡ç­¾ä½ç½®ï¼Œç¡®ä¿ä¸è¶…å‡ºå›¾åƒè¾¹ç•Œ
                    label_x = x1
                    label_y = y1 - 5  # æ ‡ç­¾åœ¨è¾¹ç•Œæ¡†ä¸Šæ–¹
                    
                    # å¦‚æœæ ‡ç­¾ä¼šè¶…å‡ºå›¾åƒé¡¶éƒ¨ï¼Œåˆ™æ”¾åœ¨è¾¹ç•Œæ¡†å†…éƒ¨
                    if label_y - label_h < 0:
                        label_y = y1 + label_h + 5
                    
                    # ç¡®ä¿æ ‡ç­¾ä¸è¶…å‡ºå›¾åƒè¾¹ç•Œ
                    label_x = max(0, min(label_x, img_w - label_w))
                    label_y = max(label_h, min(label_y, img_h))
                    
                    # ç»˜åˆ¶æ ‡ç­¾èƒŒæ™¯
                    cv2.rectangle(
                        vis_image, 
                        (label_x, label_y - label_h - baseline), 
                        (label_x + label_w, label_y), 
                        (0, 255, 0), 
                        -1
                    )
                    
                    # ç»˜åˆ¶æ ‡ç­¾æ–‡å­—ï¼ˆé»‘è‰²ï¼‰
                    cv2.putText(
                        vis_image, label, (label_x, label_y - baseline), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2
                    )
                else:
                    LOGGER.warning(f"   è·³è¿‡æ— æ•ˆè¾¹ç•Œæ¡†: ({x1}, {y1}, {x2}, {y2})")
            
            # ä¿å­˜å›¾åƒ
            output_path = save_path / f"{image_path.stem}_visual.jpg"
            cv2.imwrite(str(output_path), cv2.cvtColor(vis_image, cv2.COLOR_RGB2BGR))
            LOGGER.info(f"   å¯è§†åŒ–ç»“æœä¿å­˜åˆ°: {output_path}")
        
        # ä¿å­˜txtæ ¼å¼æ ‡ç­¾
        if save_txt and save_dir:
            save_path = Path(save_dir)
            labels_dir = save_path / "labels"
            labels_dir.mkdir(parents=True, exist_ok=True)

            # ç”ŸæˆYOLOæ ¼å¼çš„txtæ ‡ç­¾æ–‡ä»¶
            txt_path = labels_dir / f"{image_path.stem}.txt"
            with open(txt_path, 'w') as f:
                for pred in result.object_prediction_list:
                    bbox = pred.bbox.to_xyxy()
                    x1, y1, x2, y2 = bbox

                    x_center = (x1 + x2) / 2.0 / w
                    y_center = (y1 + y2) / 2.0 / h
                    box_width = (x2-x1) / w
                    box_height = (y2 - y1) / h

                    # è·å–ç±»åˆ«ID
                    class_id = pred.category.id

                    # å†™å…¥æ ¼å¼ï¼šclass_id x_center y_center width height [confidence]
                    if save_conf:
                        f.write(f"{class_id} {x_center:.6f} {y_center:.6f} {box_width:.6f} {box_height:.6f} {pred.score.value:.6f}\n")
                    else:
                        f.write(f"{class_id} {x_center:.6f} {y_center:.6f} {box_width:.6f} {box_height:.6f}\n")
                    
                LOGGER.info(f"   æ ‡ç­¾æ–‡ä»¶ä¿å­˜åˆ°: {txt_path}")

        # è¿”å›ç»“æœä¿¡æ¯
        return {
            "image_path": str(image_path),
            "image_size": (w, h),
            "num_detections": num_detections,
            "detections": result.object_prediction_list,
            "result": result,
        }
    
    def predict_directory(
        self,
        image_dir: str,
        slice_height: int = 640,
        slice_width: int = 640,
        overlap_height_ratio: float = 0.15,
        overlap_width_ratio: float = 0.15,
        postprocess_type: str = "NMS",
        postprocess_threshold: float = 0.5,
        postprocess_metric: str = "IOS",
        save_dir: str = "runs/sahi_inference",
        visualize: bool = True,
        save_txt: bool = True,
        save_conf: bool = True,
        min_box_area: int = 100,
        max_detections: int = 100,
        image_extensions: tuple = (".jpg", ".jpeg", ".png", ".bmp"),
    ) -> list:
        """
        å¯¹ç›®å½•ä¸­æ‰€æœ‰å›¾åƒè¿›è¡Œæ‰¹é‡æ¨ç†
        
        Args:
            image_dir (str): å›¾åƒç›®å½•
            slice_height (int): åˆ‡ç‰‡é«˜åº¦
            slice_width (int): åˆ‡ç‰‡å®½åº¦
            overlap_height_ratio (float): é«˜åº¦é‡å æ¯”ä¾‹
            overlap_width_ratio (float): å®½åº¦é‡å æ¯”ä¾‹
            save_dir (str): ä¿å­˜ç»“æœçš„ç›®å½•
            visualize (bool): æ˜¯å¦ä¿å­˜å¯è§†åŒ–ç»“æœ
            image_extensions (tuple): æ”¯æŒçš„å›¾åƒæ‰©å±•å
        
        Returns:
            list: æ‰€æœ‰å›¾åƒçš„æ£€æµ‹ç»“æœåˆ—è¡¨
        """
        image_dir = Path(image_dir)
        if not image_dir.exists():
            raise FileNotFoundError(f"å›¾åƒç›®å½•ä¸å­˜åœ¨: {image_dir}")
        
        # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶
        image_files = []
        for ext in image_extensions:
            image_files.extend(image_dir.glob(f"*{ext}"))
            image_files.extend(image_dir.glob(f"*{ext.upper()}"))
        
        if not image_files:
            LOGGER.warning(f"âš ï¸ ç›®å½•ä¸­æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶: {image_dir}")
            return []
        
        LOGGER.info(f"ğŸ¯ å¼€å§‹æ‰¹é‡æ¨ç†ï¼Œå…± {len(image_files)} å¼ å›¾åƒ")
        LOGGER.info(f"   åˆ‡ç‰‡å‚æ•°: {slice_width}x{slice_height}, é‡å : {overlap_width_ratio:.1%}x{overlap_height_ratio:.1%}")
        
        # å¤„ç†æ¯å¼ å›¾åƒ
        results = []
        for i, image_path in enumerate(image_files, 1):
            LOGGER.info(f"[{i}/{len(image_files)}]")
            try:
                result = self.predict_image(
                    image_path=str(image_path),
                    slice_height=slice_height,
                    slice_width=slice_width,
                    overlap_height_ratio=overlap_height_ratio,
                    overlap_width_ratio=overlap_width_ratio,
                    postprocess_type=postprocess_type,
                    postprocess_threshold=postprocess_threshold,
                    postprocess_metric=postprocess_metric,
                    save_dir=save_dir,
                    visualize=visualize,
                    save_txt=save_txt,
                    save_conf=save_conf,
                    min_box_area=min_box_area,
                    max_detections=max_detections,
                )
                results.append(result)
            except Exception as e:
                LOGGER.error(f"   âŒ å¤„ç†å¤±è´¥: {e}")
        
        # ç»Ÿè®¡æ€»ç»“
        total_detections = sum(r["num_detections"] for r in results)
        LOGGER.info(f"\nğŸ‰ æ‰¹é‡æ¨ç†å®Œæˆï¼")
        LOGGER.info(f"   å¤„ç†å›¾åƒ: {len(results)}/{len(image_files)}")
        LOGGER.info(f"   æ€»æ£€æµ‹æ•°: {total_detections}")
        LOGGER.info(f"   å¹³å‡æ¯å¼ : {total_detections/len(results):.1f} ä¸ªç›®æ ‡")
        if visualize:
            LOGGER.info(f"   ç»“æœä¿å­˜: {save_dir}")
        
        return results


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="D1 æ•°æ®é›† SAHI åˆ‡ç‰‡æ¨ç†è„šæœ¬")
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument("--model", type=str, required=True, help="è®­ç»ƒå¥½çš„æ¨¡å‹è·¯å¾„")
    parser.add_argument("--confidence", type=float, default=0.25, help="ç½®ä¿¡åº¦é˜ˆå€¼")
    parser.add_argument("--device", type=str, default="cuda:0", help="è®¾å¤‡ (cuda:0 æˆ– cpu)")
    
    # è¾“å…¥è¾“å‡º
    parser.add_argument("--source", type=str, required=True, help="å›¾åƒè·¯å¾„æˆ–ç›®å½•")
    parser.add_argument("--save-dir", type=str, default="runs/sahi_inference", help="ç»“æœä¿å­˜ç›®å½•")
    parser.add_argument("--no-visualize", action="store_true", help="ä¸ä¿å­˜å¯è§†åŒ–ç»“æœ")
    parser.add_argument("--no-save-txt", action="store_true", help="ä¸ä¿å­˜txtæ ¼å¼æ ‡ç­¾")
    parser.add_argument("--no-save-conf", action="store_true", help="ä¸ä¿å­˜ç½®ä¿¡åº¦")
    
    # åˆ‡ç‰‡å‚æ•°
    parser.add_argument("--slice-height", type=int, default=640, help="åˆ‡ç‰‡é«˜åº¦")
    parser.add_argument("--slice-width", type=int, default=640, help="åˆ‡ç‰‡å®½åº¦")
    parser.add_argument("--overlap-height", type=float, default=0.15, help="é«˜åº¦é‡å æ¯”ä¾‹ (0.0-1.0)")
    parser.add_argument("--overlap-width", type=float, default=0.15, help="å®½åº¦é‡å æ¯”ä¾‹ (0.0-1.0)")
    
    # åå¤„ç†å‚æ•°
    parser.add_argument("--postprocess-type", type=str, default="NMS", choices=["NMS", "NMM"], help="åå¤„ç†æ–¹æ³•")
    parser.add_argument("--postprocess-threshold", type=float, default=0.5, help="NMS/NMMé˜ˆå€¼")
    parser.add_argument("--postprocess-metric", type=str, default="IOS", choices=["IOS", "IOU"], help="åŒ¹é…æŒ‡æ ‡")
    
    # é«˜çº§è¿‡æ»¤å‚æ•°
    parser.add_argument("--min-box-area", type=int, default=100, help="æœ€å°æ£€æµ‹æ¡†é¢ç§¯")
    parser.add_argument("--max-detections", type=int, default=100, help="æœ€å¤§æ£€æµ‹æ•°é‡")
    
    args = parser.parse_args()
    
    try:
        # åˆ›å»ºæ¨ç†å™¨
        LOGGER.info("ğŸš€ åˆå§‹åŒ– SAHI æ¨ç†å™¨...")
        inferencer = BalloonSAHIInference(
            model_path=args.model,
            confidence_threshold=args.confidence,
            device=args.device,
        )
        
        # åˆ¤æ–­è¾“å…¥æ˜¯æ–‡ä»¶è¿˜æ˜¯ç›®å½•
        source_path = Path(args.source)
        visualize = not args.no_visualize
        save_txt = not args.no_save_txt
        save_conf = not args.no_save_conf
        
        if source_path.is_file():
            # å•å¼ å›¾åƒæ¨ç†
            result = inferencer.predict_image(
                image_path=str(source_path),
                slice_height=args.slice_height,
                slice_width=args.slice_width,
                overlap_height_ratio=args.overlap_height,
                overlap_width_ratio=args.overlap_width,
                postprocess_type=args.postprocess_type,
                postprocess_threshold=args.postprocess_threshold,
                postprocess_metric=args.postprocess_metric,
                save_dir=args.save_dir,
                visualize=visualize,
                save_txt=save_txt,
                save_conf=save_conf,
                min_box_area=args.min_box_area,
                max_detections=args.max_detections,
            )
            LOGGER.info(f"\nâœ… æ¨ç†å®Œæˆï¼")
            
        elif source_path.is_dir():
            # æ‰¹é‡æ¨ç†
            results = inferencer.predict_directory(
                image_dir=str(source_path),
                slice_height=args.slice_height,
                slice_width=args.slice_width,
                overlap_height_ratio=args.overlap_height,
                overlap_width_ratio=args.overlap_width,
                postprocess_type=args.postprocess_type,
                postprocess_threshold=args.postprocess_threshold,
                postprocess_metric=args.postprocess_metric,
                save_dir=args.save_dir,
                visualize=visualize,
                save_txt=save_txt,
                save_conf=save_conf,
                min_box_area=args.min_box_area,
                max_detections=args.max_detections,
            )
        else:
            LOGGER.error(f"âŒ æ— æ•ˆçš„è¾“å…¥è·¯å¾„: {source_path}")
            return
        
    except Exception as e:
        LOGGER.error(f"âŒ æ¨ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()

