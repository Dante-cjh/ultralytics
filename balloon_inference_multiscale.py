#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å¤šå°ºåº¦æ¨ç†è„šæœ¬
ä½¿ç”¨å¤šä¸ªå›¾åƒå°ºåº¦è¿›è¡Œæ¨ç†ï¼Œç„¶åèåˆæ‰€æœ‰å°ºåº¦çš„æ£€æµ‹ç»“æœ
æ”¯æŒNMSå’ŒWBFä¸¤ç§èåˆæ–¹å¼
"""

import argparse
import os
from pathlib import Path
from typing import List, Optional, Tuple
import time

import cv2
import numpy as np
import torch
from ultralytics import YOLO
from ultralytics.utils import LOGGER


def cross_class_nms(boxes, scores, classes, iou_threshold=0.5):
    """
    è·¨ç±»åˆ«NMSï¼šå¯¹æ‰€æœ‰ç±»åˆ«çš„æ£€æµ‹æ¡†è¿›è¡ŒNMSï¼Œå»é™¤é‡å¤æ£€æµ‹
    ç”¨äºè§£å†³å¤šå°ºåº¦èåˆæ—¶åŒä¸€ä¸ªç›®æ ‡è¢«å¤šä¸ªç±»åˆ«æ£€æµ‹çš„é—®é¢˜
    
    Args:
        boxes (np.ndarray): æ£€æµ‹æ¡† [N, 4] (x1, y1, x2, y2) å½’ä¸€åŒ–åæ ‡
        scores (np.ndarray): ç½®ä¿¡åº¦ [N]
        classes (np.ndarray): ç±»åˆ« [N]
        iou_threshold (float): IoUé˜ˆå€¼
    
    Returns:
        boxes, scores, classes: è¿‡æ»¤åçš„æ£€æµ‹ç»“æœ
    """
    if len(boxes) == 0:
        return boxes, scores, classes
    
    # è®¡ç®—é¢ç§¯
    x1 = boxes[:, 0]
    y1 = boxes[:, 1]
    x2 = boxes[:, 2]
    y2 = boxes[:, 3]
    areas = (x2 - x1) * (y2 - y1)
    
    # æŒ‰ç½®ä¿¡åº¦æ’åº
    order = scores.argsort()[::-1]
    
    keep = []
    while order.size > 0:
        i = order[0]
        keep.append(i)
        
        if order.size == 1:
            break
        
        # è®¡ç®—IoU
        xx1 = np.maximum(x1[i], x1[order[1:]])
        yy1 = np.maximum(y1[i], y1[order[1:]])
        xx2 = np.minimum(x2[i], x2[order[1:]])
        yy2 = np.minimum(y2[i], y2[order[1:]])
        
        w = np.maximum(0.0, xx2 - xx1)
        h = np.maximum(0.0, yy2 - yy1)
        inter = w * h
        
        iou = inter / (areas[i] + areas[order[1:]] - inter)
        
        # ä¿ç•™IoUå°äºé˜ˆå€¼çš„æ¡†
        inds = np.where(iou <= iou_threshold)[0]
        order = order[inds + 1]
    
    # è¿”å›ä¿ç•™çš„æ£€æµ‹ç»“æœ
    return boxes[keep], scores[keep], classes[keep]


class MultiScaleInference:
    """å¤šå°ºåº¦æ¨ç†ç±»"""
    
    def __init__(
        self,
        model_path: str,
        scales: List[int] = [640, 832, 1024, 1280],
        confidence_threshold: float = 0.25,
        iou_threshold: float = 0.5,
        device: str = "cuda:0",
        fusion_method: str = "nms",  # 'nms' æˆ– 'wbf'
        class_agnostic_nms: bool = True,  # æ˜¯å¦ä½¿ç”¨è·¨ç±»åˆ«NMS
    ):
        """
        åˆå§‹åŒ–å¤šå°ºåº¦æ¨ç†å™¨
        
        Args:
            model_path (str): è®­ç»ƒå¥½çš„æ¨¡å‹è·¯å¾„
            scales (List[int]): å¤šä¸ªæ¨ç†å°ºåº¦ï¼Œä¾‹å¦‚ [640, 832, 1024, 1280]
            confidence_threshold (float): ç½®ä¿¡åº¦é˜ˆå€¼
            iou_threshold (float): NMS/WBF IoUé˜ˆå€¼
            device (str): è®¾å¤‡ ('cuda:0' æˆ– 'cpu')
            fusion_method (str): èåˆæ–¹æ³• 'nms' æˆ– 'wbf'
            class_agnostic_nms (bool): æ˜¯å¦ä½¿ç”¨è·¨ç±»åˆ«NMSï¼ˆé»˜è®¤Trueï¼Œè§£å†³å¤šæ ‡ç­¾é‡å¤é—®é¢˜ï¼‰
        """
        self.model_path = Path(model_path)
        self.scales = sorted(scales)  # æŒ‰å°ºåº¦æ’åº
        self.confidence_threshold = confidence_threshold
        self.iou_threshold = iou_threshold
        self.device = device
        self.fusion_method = fusion_method.lower()
        self.class_agnostic_nms = class_agnostic_nms
        self.model = None
        
        # éªŒè¯æ¨¡å‹æ–‡ä»¶
        if not self.model_path.exists():
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
        
        # æ£€æŸ¥WBFä¾èµ–
        if self.fusion_method == "wbf":
            try:
                from ensemble_boxes import weighted_boxes_fusion
                self.wbf = weighted_boxes_fusion
                LOGGER.info("âœ… WBF (Weighted Boxes Fusion) å·²å¯ç”¨")
            except ImportError:
                LOGGER.warning("âš ï¸ ensemble-boxesæœªå®‰è£…ï¼Œå›é€€åˆ°NMS")
                LOGGER.warning("   å®‰è£…å‘½ä»¤: pip install ensemble-boxes")
                self.fusion_method = "nms"
        
        LOGGER.info(f"ğŸ” åŠ è½½æ¨¡å‹: {self.model_path}")
        LOGGER.info(f"   æ¨ç†å°ºåº¦: {self.scales}")
        LOGGER.info(f"   èåˆæ–¹æ³•: {self.fusion_method.upper()}")
        LOGGER.info(f"   è·¨ç±»åˆ«NMS: {'å¯ç”¨' if self.class_agnostic_nms else 'ç¦ç”¨'}")
        self._load_model()
    
    def _load_model(self):
        """åŠ è½½ YOLO æ¨¡å‹"""
        self.model = YOLO(str(self.model_path))
        LOGGER.info(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    
    def _predict_single_scale(
        self,
        image: np.ndarray,
        scale: int,
    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """
        åœ¨å•ä¸ªå°ºåº¦ä¸Šè¿›è¡Œæ¨ç†
        
        Args:
            image (np.ndarray): è¾“å…¥å›¾åƒ (H, W, C)
            scale (int): æ¨ç†å°ºåº¦
        
        Returns:
            boxes (np.ndarray): æ£€æµ‹æ¡† [N, 4] (x1, y1, x2, y2) å½’ä¸€åŒ–åæ ‡
            scores (np.ndarray): ç½®ä¿¡åº¦ [N]
            classes (np.ndarray): ç±»åˆ« [N]
        """
        # æ‰§è¡Œæ¨ç†
        results = self.model.predict(
            source=image,
            imgsz=scale,
            conf=self.confidence_threshold,
            iou=self.iou_threshold,
            device=self.device,
            verbose=False,
            save=False,
        )
        
        result = results[0]
        
        # æå–æ£€æµ‹ç»“æœ
        if len(result.boxes) == 0:
            return np.array([]), np.array([]), np.array([])
        
        boxes = result.boxes.xyxy.cpu().numpy()  # [N, 4]
        scores = result.boxes.conf.cpu().numpy()  # [N]
        classes = result.boxes.cls.cpu().numpy()  # [N]
        
        # è½¬æ¢ä¸ºå½’ä¸€åŒ–åæ ‡ (0-1)
        h, w = image.shape[:2]
        boxes_norm = boxes.copy()
        boxes_norm[:, [0, 2]] /= w  # xåæ ‡å½’ä¸€åŒ–
        boxes_norm[:, [1, 3]] /= h  # yåæ ‡å½’ä¸€åŒ–
        
        return boxes_norm, scores, classes
    
    def _nms_fusion(
        self,
        all_boxes: List[np.ndarray],
        all_scores: List[np.ndarray],
        all_classes: List[np.ndarray],
    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """
        ä½¿ç”¨NMSèåˆå¤šå°ºåº¦æ£€æµ‹ç»“æœ
        
        Args:
            all_boxes: æ‰€æœ‰å°ºåº¦çš„æ£€æµ‹æ¡†åˆ—è¡¨
            all_scores: æ‰€æœ‰å°ºåº¦çš„ç½®ä¿¡åº¦åˆ—è¡¨
            all_classes: æ‰€æœ‰å°ºåº¦çš„ç±»åˆ«åˆ—è¡¨
        
        Returns:
            boxes, scores, classes: èåˆåçš„ç»“æœ
        """
        # åˆå¹¶æ‰€æœ‰å°ºåº¦çš„æ£€æµ‹ç»“æœ
        boxes = np.concatenate(all_boxes, axis=0)
        scores = np.concatenate(all_scores, axis=0)
        classes = np.concatenate(all_classes, axis=0)
        
        if len(boxes) == 0:
            return boxes, scores, classes
        
        num_before = len(boxes)
        
        # ä½¿ç”¨è·¨ç±»åˆ«NMS
        if self.class_agnostic_nms:
            boxes, scores, classes = cross_class_nms(
                boxes, scores, classes, self.iou_threshold
            )
            LOGGER.info(f"   è·¨ç±»åˆ«NMS: {num_before} -> {len(boxes)}")
        else:
            # æŒ‰ç±»åˆ«NMSï¼ˆåŸå§‹æ–¹æ³•ï¼‰
            # è½¬æ¢ä¸ºtorch tensorè¿›è¡ŒNMS
            boxes_tensor = torch.from_numpy(boxes).float()
            scores_tensor = torch.from_numpy(scores).float()
            classes_tensor = torch.from_numpy(classes).long()
            
            # å¯¹æ¯ä¸ªç±»åˆ«åˆ†åˆ«æ‰§è¡ŒNMS
            keep_indices = []
            unique_classes = torch.unique(classes_tensor)
            
            for cls in unique_classes:
                cls_mask = classes_tensor == cls
                cls_boxes = boxes_tensor[cls_mask]
                cls_scores = scores_tensor[cls_mask]
                
                # æ‰§è¡ŒNMS
                keep = torch.ops.torchvision.nms(
                    cls_boxes,
                    cls_scores,
                    self.iou_threshold
                )
                
                # è·å–åŸå§‹ç´¢å¼•
                cls_indices = torch.where(cls_mask)[0]
                keep_indices.extend(cls_indices[keep].tolist())
            
            # ä¿ç•™NMSåçš„æ£€æµ‹ç»“æœ
            keep_indices = sorted(keep_indices)
            boxes = boxes[keep_indices]
            scores = scores[keep_indices]
            classes = classes[keep_indices]
            
            LOGGER.info(f"   æŒ‰ç±»åˆ«NMS: {num_before} -> {len(boxes)}")
        
        return boxes, scores, classes
    
    def _wbf_fusion(
        self,
        all_boxes: List[np.ndarray],
        all_scores: List[np.ndarray],
        all_classes: List[np.ndarray],
    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """
        ä½¿ç”¨WBF (Weighted Boxes Fusion) èåˆå¤šå°ºåº¦æ£€æµ‹ç»“æœ
        
        WBFç›¸æ¯”NMSçš„ä¼˜åŠ¿:
        - ä¸æ˜¯ç®€å•åˆ é™¤é‡å æ¡†ï¼Œè€Œæ˜¯èåˆå®ƒä»¬
        - ä½¿ç”¨åŠ æƒå¹³å‡æ¥ç¡®å®šæœ€ç»ˆæ¡†çš„ä½ç½®
        - é€šå¸¸æ¯”NMSæœ‰æ›´å¥½çš„å®šä½ç²¾åº¦
        
        Args:
            all_boxes: æ‰€æœ‰å°ºåº¦çš„æ£€æµ‹æ¡†åˆ—è¡¨
            all_scores: æ‰€æœ‰å°ºåº¦çš„ç½®ä¿¡åº¦åˆ—è¡¨  
            all_classes: æ‰€æœ‰å°ºåº¦çš„ç±»åˆ«åˆ—è¡¨
        
        Returns:
            boxes, scores, classes: èåˆåçš„ç»“æœ
        """
        # WBFéœ€è¦çš„æ ¼å¼: list of [x1, y1, x2, y2] (å½’ä¸€åŒ–åæ ‡)
        boxes_list = [boxes.tolist() for boxes in all_boxes]
        scores_list = [scores.tolist() for scores in all_scores]
        labels_list = [classes.astype(int).tolist() for classes in all_classes]
        
        # æ‰§è¡ŒWBF
        boxes, scores, labels = self.wbf(
            boxes_list,
            scores_list,
            labels_list,
            weights=None,  # æ‰€æœ‰å°ºåº¦æƒé‡ç›¸åŒ
            iou_thr=self.iou_threshold,
            skip_box_thr=self.confidence_threshold,
        )
        
        return np.array(boxes), np.array(scores), np.array(labels)
    
    def predict_image(
        self,
        image_path: str,
        save_dir: Optional[str] = None,
        visualize: bool = True,
        save_txt: bool = True,
        save_conf: bool = True,
    ) -> dict:
        """
        å¯¹å•å¼ å›¾åƒè¿›è¡Œå¤šå°ºåº¦æ¨ç†
        
        Args:
            image_path (str): å›¾åƒè·¯å¾„
            save_dir (str, optional): ä¿å­˜ç»“æœçš„ç›®å½•
            visualize (bool): æ˜¯å¦ä¿å­˜å¯è§†åŒ–ç»“æœ
            save_txt (bool): æ˜¯å¦ä¿å­˜txtæ ¼å¼ç»“æœ
            save_conf (bool): æ˜¯å¦ä¿å­˜ç½®ä¿¡åº¦
        
        Returns:
            dict: åŒ…å«æ£€æµ‹ç»“æœçš„å­—å…¸
        """
        image_path = Path(image_path)
        if not image_path.exists():
            raise FileNotFoundError(f"å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
        
        LOGGER.info(f"ğŸ“¸ å¤„ç†å›¾åƒ: {image_path.name}")
        
        # è¯»å–å›¾åƒ
        image = cv2.imread(str(image_path))
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        h, w = image.shape[:2]
        LOGGER.info(f"   åŸå§‹å°ºå¯¸: {w}x{h}")
        
        # åœ¨å¤šä¸ªå°ºåº¦ä¸Šè¿›è¡Œæ¨ç†
        all_boxes = []
        all_scores = []
        all_classes = []
        
        start_time = time.time()
        
        for scale in self.scales:
            boxes, scores, classes = self._predict_single_scale(image_rgb, scale)
            
            if len(boxes) > 0:
                all_boxes.append(boxes)
                all_scores.append(scores)
                all_classes.append(classes)
                LOGGER.info(f"   å°ºåº¦ {scale}: æ£€æµ‹åˆ° {len(boxes)} ä¸ªç›®æ ‡")
            else:
                LOGGER.info(f"   å°ºåº¦ {scale}: æœªæ£€æµ‹åˆ°ç›®æ ‡")
        
        # èåˆå¤šå°ºåº¦ç»“æœ
        if len(all_boxes) == 0:
            LOGGER.info(f"   âš ï¸ æ‰€æœ‰å°ºåº¦å‡æœªæ£€æµ‹åˆ°ç›®æ ‡")
            boxes_fused = np.array([])
            scores_fused = np.array([])
            classes_fused = np.array([])
        else:
            LOGGER.info(f"   èåˆæ–¹æ³•: {self.fusion_method.upper()}")
            if self.fusion_method == "wbf":
                boxes_fused, scores_fused, classes_fused = self._wbf_fusion(
                    all_boxes, all_scores, all_classes
                )
            else:  # nms
                boxes_fused, scores_fused, classes_fused = self._nms_fusion(
                    all_boxes, all_scores, all_classes
                )
        
        inference_time = time.time() - start_time
        num_detections = len(boxes_fused)
        
        LOGGER.info(f"   âœ… èåˆå: {num_detections} ä¸ªç›®æ ‡ (è€—æ—¶: {inference_time:.2f}s)")
        
        # åå½’ä¸€åŒ–åæ ‡
        if num_detections > 0:
            boxes_pixel = boxes_fused.copy()
            boxes_pixel[:, [0, 2]] *= w
            boxes_pixel[:, [1, 3]] *= h
        else:
            boxes_pixel = boxes_fused
        
        # ä¿å­˜å¯è§†åŒ–ç»“æœ
        if visualize and save_dir and num_detections > 0:
            save_path = Path(save_dir)
            save_path.mkdir(parents=True, exist_ok=True)
            
            vis_image = image.copy()
            
            for i, (box, score, cls) in enumerate(zip(boxes_pixel, scores_fused, classes_fused)):
                x1, y1, x2, y2 = map(int, box)
                
                # ç»˜åˆ¶è¾¹ç•Œæ¡†
                cv2.rectangle(vis_image, (x1, y1), (x2, y2), (0, 255, 0), 2)
                
                # ç»˜åˆ¶æ ‡ç­¾
                label = f"Class {int(cls)}: {score:.2f}"
                (label_w, label_h), baseline = cv2.getTextSize(
                    label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2
                )
                
                # æ ‡ç­¾ä½ç½®
                label_y = max(y1 - 5, label_h)
                cv2.rectangle(
                    vis_image,
                    (x1, label_y - label_h - baseline),
                    (x1 + label_w, label_y),
                    (0, 255, 0),
                    -1
                )
                cv2.putText(
                    vis_image, label, (x1, label_y - baseline),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2
                )
            
            # ä¿å­˜å›¾åƒ
            output_path = save_path / f"{image_path.stem}_multiscale.jpg"
            cv2.imwrite(str(output_path), vis_image)
            LOGGER.info(f"   å¯è§†åŒ–ç»“æœ: {output_path}")
        
        # ä¿å­˜txtæ ¼å¼æ ‡ç­¾
        if save_txt and save_dir and num_detections > 0:
            save_path = Path(save_dir)
            labels_dir = save_path / "labels"
            labels_dir.mkdir(parents=True, exist_ok=True)
            
            txt_path = labels_dir / f"{image_path.stem}.txt"
            with open(txt_path, 'w') as f:
                for box, score, cls in zip(boxes_fused, scores_fused, classes_fused):
                    x1, y1, x2, y2 = box
                    x_center = (x1 + x2) / 2.0
                    y_center = (y1 + y2) / 2.0
                    box_width = x2 - x1
                    box_height = y2 - y1
                    
                    if save_conf:
                        f.write(f"{int(cls)} {x_center:.6f} {y_center:.6f} {box_width:.6f} {box_height:.6f} {score:.6f}\n")
                    else:
                        f.write(f"{int(cls)} {x_center:.6f} {y_center:.6f} {box_width:.6f} {box_height:.6f}\n")
            
            LOGGER.info(f"   æ ‡ç­¾æ–‡ä»¶: {txt_path}")
        
        return {
            "image_path": str(image_path),
            "image_size": (w, h),
            "num_detections": num_detections,
            "boxes": boxes_pixel,
            "scores": scores_fused,
            "classes": classes_fused,
            "inference_time": inference_time,
        }
    
    def predict_directory(
        self,
        image_dir: str,
        save_dir: str = "runs/multiscale_inference",
        visualize: bool = True,
        save_txt: bool = True,
        save_conf: bool = True,
        image_extensions: tuple = (".jpg", ".jpeg", ".png", ".bmp"),
    ) -> List[dict]:
        """
        å¯¹ç›®å½•ä¸­æ‰€æœ‰å›¾åƒè¿›è¡Œæ‰¹é‡å¤šå°ºåº¦æ¨ç†
        
        Args:
            image_dir (str): å›¾åƒç›®å½•
            save_dir (str): ä¿å­˜ç»“æœçš„ç›®å½•
            visualize (bool): æ˜¯å¦ä¿å­˜å¯è§†åŒ–ç»“æœ
            save_txt (bool): æ˜¯å¦ä¿å­˜txtæ ¼å¼ç»“æœ
            save_conf (bool): æ˜¯å¦ä¿å­˜ç½®ä¿¡åº¦
            image_extensions (tuple): æ”¯æŒçš„å›¾åƒæ‰©å±•å
        
        Returns:
            list: æ‰€æœ‰å›¾åƒçš„æ£€æµ‹ç»“æœåˆ—è¡¨
        """
        image_dir = Path(image_dir)
        if not image_dir.exists():
            raise FileNotFoundError(f"å›¾åƒç›®å½•ä¸å­˜åœ¨: {image_dir}")
        
        # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶
        image_files = []
        for ext in image_extensions:
            image_files.extend(image_dir.glob(f"*{ext}"))
            image_files.extend(image_dir.glob(f"*{ext.upper()}"))
        
        if not image_files:
            LOGGER.warning(f"âš ï¸ ç›®å½•ä¸­æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶: {image_dir}")
            return []
        
        LOGGER.info(f"ğŸ¯ å¼€å§‹æ‰¹é‡å¤šå°ºåº¦æ¨ç†")
        LOGGER.info(f"   å›¾åƒæ•°é‡: {len(image_files)}")
        LOGGER.info(f"   æ¨ç†å°ºåº¦: {self.scales}")
        LOGGER.info(f"   èåˆæ–¹æ³•: {self.fusion_method.upper()}")
        
        # å¤„ç†æ¯å¼ å›¾åƒ
        results = []
        total_start_time = time.time()
        
        for i, image_path in enumerate(image_files, 1):
            LOGGER.info(f"\n[{i}/{len(image_files)}]")
            try:
                result = self.predict_image(
                    image_path=str(image_path),
                    save_dir=save_dir,
                    visualize=visualize,
                    save_txt=save_txt,
                    save_conf=save_conf,
                )
                results.append(result)
            except Exception as e:
                LOGGER.error(f"   âŒ å¤„ç†å¤±è´¥: {e}")
        
        total_time = time.time() - total_start_time
        
        # ç»Ÿè®¡æ€»ç»“
        if results:
            total_detections = sum(r["num_detections"] for r in results)
            avg_time = total_time / len(results)
            
            LOGGER.info(f"\n{'='*70}")
            LOGGER.info(f"ğŸ‰ æ‰¹é‡æ¨ç†å®Œæˆï¼")
            LOGGER.info(f"{'='*70}")
            LOGGER.info(f"   å¤„ç†å›¾åƒ: {len(results)}/{len(image_files)}")
            LOGGER.info(f"   æ€»æ£€æµ‹æ•°: {total_detections}")
            LOGGER.info(f"   å¹³å‡æ¯å¼ : {total_detections/len(results):.1f} ä¸ªç›®æ ‡")
            LOGGER.info(f"   æ€»è€—æ—¶: {total_time:.2f}s")
            LOGGER.info(f"   å¹³å‡è€—æ—¶: {avg_time:.2f}s/å¼ ")
            if visualize:
                LOGGER.info(f"   ç»“æœä¿å­˜: {save_dir}")
            LOGGER.info(f"{'='*70}")
        
        return results


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="å¤šå°ºåº¦æ¨ç†è„šæœ¬")
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument("--model", type=str, required=True, help="è®­ç»ƒå¥½çš„æ¨¡å‹è·¯å¾„")
    parser.add_argument("--scales", type=int, nargs="+", default=[640, 832, 1024, 1280],
                       help="æ¨ç†å°ºåº¦åˆ—è¡¨ï¼Œä¾‹å¦‚: --scales 640 832 1024 1280")
    parser.add_argument("--confidence", type=float, default=0.25, help="ç½®ä¿¡åº¦é˜ˆå€¼")
    parser.add_argument("--iou", type=float, default=0.5, help="NMS/WBF IoUé˜ˆå€¼")
    parser.add_argument("--device", type=str, default="cuda:0", help="è®¾å¤‡ (cuda:0 æˆ– cpu)")
    parser.add_argument("--fusion", type=str, default="nms", choices=["nms", "wbf"],
                       help="èåˆæ–¹æ³•: nms æˆ– wbf (Weighted Boxes Fusion)")
    parser.add_argument("--no-cross-class-nms", action="store_true", 
                       help="ç¦ç”¨è·¨ç±»åˆ«NMSï¼ˆé»˜è®¤å¯ç”¨ï¼Œè§£å†³å¤šæ ‡ç­¾é‡å¤é—®é¢˜ï¼‰")
    
    # è¾“å…¥è¾“å‡º
    parser.add_argument("--source", type=str, required=True, help="å›¾åƒè·¯å¾„æˆ–ç›®å½•")
    parser.add_argument("--save-dir", type=str, default="runs/multiscale_inference", help="ç»“æœä¿å­˜ç›®å½•")
    parser.add_argument("--no-visualize", action="store_true", help="ä¸ä¿å­˜å¯è§†åŒ–ç»“æœ")
    parser.add_argument("--no-save-txt", action="store_true", help="ä¸ä¿å­˜txtæ ¼å¼ç»“æœ")
    parser.add_argument("--no-save-conf", action="store_true", help="ä¸ä¿å­˜ç½®ä¿¡åº¦")
    
    args = parser.parse_args()
    
    try:
        # åˆ›å»ºæ¨ç†å™¨
        LOGGER.info("ğŸš€ åˆå§‹åŒ–å¤šå°ºåº¦æ¨ç†å™¨...")
        class_agnostic_nms = not args.no_cross_class_nms
        inferencer = MultiScaleInference(
            model_path=args.model,
            scales=args.scales,
            confidence_threshold=args.confidence,
            iou_threshold=args.iou,
            device=args.device,
            fusion_method=args.fusion,
            class_agnostic_nms=class_agnostic_nms,
        )
        
        # åˆ¤æ–­è¾“å…¥æ˜¯æ–‡ä»¶è¿˜æ˜¯ç›®å½•
        source_path = Path(args.source)
        visualize = not args.no_visualize
        save_txt = not args.no_save_txt
        save_conf = not args.no_save_conf
        
        if source_path.is_file():
            # å•å¼ å›¾åƒæ¨ç†
            result = inferencer.predict_image(
                image_path=str(source_path),
                save_dir=args.save_dir,
                visualize=visualize,
                save_txt=save_txt,
                save_conf=save_conf,
            )
            LOGGER.info(f"\nâœ… æ¨ç†å®Œæˆï¼")
            
        elif source_path.is_dir():
            # æ‰¹é‡æ¨ç†
            results = inferencer.predict_directory(
                image_dir=str(source_path),
                save_dir=args.save_dir,
                visualize=visualize,
                save_txt=save_txt,
                save_conf=save_conf,
            )
        else:
            LOGGER.error(f"âŒ æ— æ•ˆçš„è¾“å…¥è·¯å¾„: {source_path}")
            return
        
    except Exception as e:
        LOGGER.error(f"âŒ æ¨ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()

