# çº§è”æ£€æµ‹äºŒé˜¶æ®µåˆ†ç±»å™¨è¿‡æ‹Ÿåˆé—®é¢˜åˆ†æä¸è§£å†³æ–¹æ¡ˆ

## ğŸ“Š é—®é¢˜æè¿°

**ç°è±¡**ï¼š
```
è®­ç»ƒé›†å‡†ç¡®ç‡: 99% âœ…
æµ‹è¯•é›†å‡†ç¡®ç‡: 86% âŒ
æ”¶æ•›è½®æ¬¡: 6-8è½®
æ ·æœ¬å¹³è¡¡: negative_ratio=1.0 å’Œ 2.0 éƒ½å‡ºç°æ­¤é—®é¢˜
```

**è¯Šæ–­**ï¼šä¸¥é‡è¿‡æ‹Ÿåˆï¼

---

## ğŸ” åŸå› åˆ†æ

### å¯èƒ½åŸå› 1ï¼šè®­ç»ƒæ•°æ®ä¸å¤Ÿå¤šæ ·åŒ–

å³ä½¿æœ‰8ä¸‡æ ·æœ¬ï¼ˆ1:1å¹³è¡¡ï¼‰ï¼Œä½†è¿™äº›æ ·æœ¬éƒ½æ¥è‡ªåŒä¸€æ‰¹å›¾åƒçš„è£å‰ªï¼š

```
D1è®­ç»ƒé›†: 929å¼ å®Œæ•´å›¾åƒ
â†“
YOLOç¬¬ä¸€é˜¶æ®µç”Ÿæˆå€™é€‰æ¡†
â†“
è£å‰ªå‡º8ä¸‡ä¸ªå°å›¾ï¼ˆå€™é€‰åŒºåŸŸï¼‰

é—®é¢˜ï¼š
- è¿™8ä¸‡ä¸ªå°å›¾éƒ½æ¥è‡ªåŒ929å¼ åŸå›¾
- åŒä¸€å¼ åŸå›¾çš„ä¸åŒè£å‰ªå…·æœ‰ç›¸ä¼¼çš„çº¹ç†ã€å…‰ç…§ã€èƒŒæ™¯
- å®é™…å¤šæ ·æ€§è¿œå°äº8ä¸‡
```

### å¯èƒ½åŸå› 2ï¼šMobileNetV2è¿‡äºå¼ºå¤§

```
MobileNetV2å‚æ•°: ~3.5M
ä»»åŠ¡: äºŒåˆ†ç±»ï¼ˆèƒŒæ™¯ vs ç›®æ ‡ï¼‰

é—®é¢˜ï¼š
- æ¨¡å‹å®¹é‡ç›¸å¯¹ä»»åŠ¡è¿‡å¤§
- å®¹æ˜“è®°ä½è®­ç»ƒé›†ç‰¹å¾
- éœ€è¦æ›´å¼ºçš„æ­£åˆ™åŒ–
```

### å¯èƒ½åŸå› 3ï¼šæ•°æ®å¢å¼ºä¸è¶³

å½“å‰MobileNetV2åªä½¿ç”¨äº†æœ€åŸºç¡€çš„é¢„å¤„ç†ï¼š

```python
transform = transforms.Compose([
    transforms.Resize((112, 112)),
    transforms.ToTensor(),
    transforms.Normalize(...)
])
```

**ç¼ºå°‘**ï¼š
- éšæœºç¿»è½¬
- éšæœºæ—‹è½¬
- é¢œè‰²æŠ–åŠ¨
- éšæœºæ“¦é™¤
- ç­‰ç­‰

---

## ğŸ’¡ è§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆ1ï¼šå¢åŠ æ•°æ®å¢å¼ºï¼ˆæ¨èä¼˜å…ˆå°è¯•ï¼‰

ä¿®æ”¹ `balloon_cascaded_detection.py` ä¸­çš„ `CascadedClassifierTrainer` ç±»ï¼š

```python
# è®­ç»ƒæ—¶çš„å¢å¼ºå˜æ¢
train_transform = transforms.Compose([
    transforms.Resize((input_size, input_size)),
    
    # å‡ ä½•å˜æ¢
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomVerticalFlip(p=0.5),
    transforms.RandomRotation(15),  # éšæœºæ—‹è½¬Â±15åº¦
    
    # é¢œè‰²å¢å¼º
    transforms.ColorJitter(
        brightness=0.2,  # äº®åº¦
        contrast=0.2,    # å¯¹æ¯”åº¦
        saturation=0.2,  # é¥±å’Œåº¦
        hue=0.1          # è‰²è°ƒ
    ),
    
    # éšæœºæ“¦é™¤ï¼ˆæ¨¡æ‹Ÿé®æŒ¡ï¼‰
    transforms.RandomErasing(p=0.3, scale=(0.02, 0.15)),
    
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    ),
])

# éªŒè¯æ—¶ä¸å¢å¼º
val_transform = transforms.Compose([
    transforms.Resize((input_size, input_size)),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    ),
])
```

### æ–¹æ¡ˆ2ï¼šå¢åŠ Dropoutå’Œæƒé‡è¡°å‡

ä¿®æ”¹ `MobileNetClassifier` ç±»ï¼š

```python
class MobileNetClassifier(nn.Module):
    def __init__(self, num_classes: int = 2, dropout: float = 0.5):  # â† å¢åŠ dropout
        super().__init__()
        # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
        mobilenet = models.mobilenet_v2(pretrained=True)
        self.features = mobilenet.features
        
        # ä¿®æ”¹åˆ†ç±»å¤´ï¼Œå¢åŠ Dropout
        self.classifier = nn.Sequential(
            nn.Dropout(p=dropout),  # â† ç¬¬ä¸€ä¸ªDropout
            nn.Linear(mobilenet.last_channel, 256),
            nn.ReLU(inplace=True),
            nn.Dropout(p=dropout),  # â† ç¬¬äºŒä¸ªDropout
            nn.Linear(256, num_classes)
        )
```

ä¿®æ”¹è®­ç»ƒå™¨çš„ä¼˜åŒ–å™¨ï¼š

```python
optimizer = torch.optim.AdamW(  # ä½¿ç”¨AdamWï¼ˆå¸¦æƒé‡è¡°å‡ï¼‰
    model.parameters(),
    lr=learning_rate,
    weight_decay=0.01  # â† å¢åŠ æƒé‡è¡°å‡ï¼ˆL2æ­£åˆ™åŒ–ï¼‰
)
```

### æ–¹æ¡ˆ3ï¼šæ—©åœç­–ç•¥

å½“å‰å¯èƒ½æ²¡æœ‰åˆé€‚çš„æ—©åœï¼Œä¿®æ”¹è®­ç»ƒå¾ªç¯ï¼š

```python
# æ—©åœå‚æ•°
patience = 10  # 10è½®ä¸æå‡å°±åœæ­¢
best_val_acc = 0.0
patience_counter = 0

for epoch in range(epochs):
    # ... è®­ç»ƒå’ŒéªŒè¯ ...
    
    # æ—©åœæ£€æŸ¥
    if val_acc > best_val_acc:
        best_val_acc = val_acc
        patience_counter = 0
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        torch.save(model.state_dict(), os.path.join(save_dir, 'best.pt'))
    else:
        patience_counter += 1
        
    if patience_counter >= patience:
        print(f"æ—©åœï¼{patience}è½®æ— æå‡")
        break
```

### æ–¹æ¡ˆ4ï¼šå­¦ä¹ ç‡è°ƒåº¦

æ·»åŠ å­¦ä¹ ç‡è¡°å‡ï¼š

```python
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
    optimizer,
    mode='max',
    factor=0.5,      # å­¦ä¹ ç‡å‡åŠ
    patience=3,      # 3è½®ä¸æå‡å°±é™ä½å­¦ä¹ ç‡
    verbose=True
)

# åœ¨æ¯ä¸ªepochå
scheduler.step(val_acc)
```

### æ–¹æ¡ˆ5ï¼šä½¿ç”¨æ›´è½»é‡çš„æ¨¡å‹æˆ–å†»ç»“éƒ¨åˆ†å±‚

```python
# æ–¹æ¡ˆ5a: å†»ç»“MobileNetV2çš„å‰åŠéƒ¨åˆ†å±‚
for i, param in enumerate(model.features.parameters()):
    if i < 10:  # å†»ç»“å‰10å±‚
        param.requires_grad = False

# æ–¹æ¡ˆ5b: ä½¿ç”¨æ›´è½»é‡çš„MobileNetV3-Small
mobilenet = models.mobilenet_v3_small(pretrained=True)
```

---

## ğŸ¯ æ¨èå®æ–½é¡ºåº

### ç¬¬ä¸€æ­¥ï¼šæ•°æ®å¢å¼ºï¼ˆæœ€å®¹æ˜“ï¼Œæ•ˆæœæœ€å¥½ï¼‰

**é¢„æœŸæ•ˆæœ**ï¼š
- æµ‹è¯•é›†å‡†ç¡®ç‡: 86% â†’ 88-90%
- æ”¶æ•›è½®æ¬¡: 6-8è½® â†’ 15-20è½®
- è¿‡æ‹Ÿåˆç¨‹åº¦: æ˜¾è‘—é™ä½

### ç¬¬äºŒæ­¥ï¼šå¢åŠ Dropoutå’Œæƒé‡è¡°å‡

**é¢„æœŸæ•ˆæœ**ï¼š
- æµ‹è¯•é›†å‡†ç¡®ç‡: +1-2%
- è®­ç»ƒé›†å‡†ç¡®ç‡: 99% â†’ 95%ï¼ˆæ›´å¥åº·ï¼‰

### ç¬¬ä¸‰æ­¥ï¼šè°ƒæ•´å­¦ä¹ ç‡å’Œæ—©åœ

**é¢„æœŸæ•ˆæœ**ï¼š
- è®­ç»ƒæ›´ç¨³å®š
- é¿å…è¿‡åº¦è®­ç»ƒ

---

## ğŸ“ å®Œæ•´ä¿®æ”¹ä»£ç 

æˆ‘ä¼šåˆ›å»ºä¸€ä¸ªå¢å¼ºç‰ˆçš„è®­ç»ƒå™¨ï¼ŒåŒ…å«ä¸Šè¿°æ‰€æœ‰æ”¹è¿›ã€‚ä½ å¯ä»¥é€šè¿‡å‚æ•°æ§åˆ¶æ˜¯å¦å¯ç”¨ã€‚

---

## ğŸ”§ è¶…å‚æ•°è°ƒä¼˜å»ºè®®

### å½“å‰é—®é¢˜ï¼šæµ‹è¯•é›†86%ï¼Œè®­ç»ƒé›†99%

**è°ƒæ•´ç­–ç•¥**ï¼š

| å‚æ•° | å½“å‰å€¼ | å»ºè®®å€¼ | æ•ˆæœ |
|------|--------|--------|------|
| dropout | 0.2 | 0.5 | å‡å°‘è¿‡æ‹Ÿåˆ |
| weight_decay | 0.0 | 0.01 | L2æ­£åˆ™åŒ– |
| learning_rate | 0.001 | 0.0005 | æ›´å¹³æ»‘æ”¶æ•› |
| batch_size | 32 | 64 | æ¢¯åº¦æ›´ç¨³å®š |
| æ•°æ®å¢å¼º | æ—  | âœ… | å¢åŠ å¤šæ ·æ€§ |

---

## ğŸ¨ å…³äºé‡å¤æ¡†é—®é¢˜

### é—®é¢˜ï¼šä¸‰ä¸ªæ¡†æ¡†ä½ä¸€ä¸ªå­”æ´ï¼Œè§’åº¦åˆé’»ï¼ŒIOUä¸æ»¡è¶³

**åŸå› **ï¼š

```
æ¡†1: [x1, y1, x2, y2]  è§’åº¦A
æ¡†2: [x3, y3, x4, y4]  è§’åº¦B
æ¡†3: [x5, y5, x6, y6]  è§’åº¦C

å¦‚æœä¸‰ä¸ªæ¡†è§’åº¦ä¸åŒä½†éƒ½æ¡†ä½åŒä¸€ç›®æ ‡ï¼š
â†’ è®¡ç®—IOUå¯èƒ½éƒ½ < 0.3
â†’ è·¨ç±»åˆ«NMSæ— æ³•è¿‡æ»¤
```

**è§£å†³æ–¹æ¡ˆ**ï¼š

#### æ–¹æ¡ˆAï¼šé™ä½NMSçš„IOUé˜ˆå€¼

```bash
# ä»0.3é™åˆ°0.2
--nms-iou 0.2

# ç”šè‡³0.15
--nms-iou 0.15
```

**ä½†è¦å°å¿ƒ**ï¼šè¿‡ä½çš„IOUé˜ˆå€¼å¯èƒ½è¯¯åˆ æ­£å¸¸çš„ç›¸é‚»ç›®æ ‡ï¼

#### æ–¹æ¡ˆBï¼šä½¿ç”¨ä¸­å¿ƒè·ç¦»NMS

ä¸ä»…çœ‹IOUï¼Œè¿˜çœ‹æ¡†ä¸­å¿ƒçš„è·ç¦»ï¼š

```python
def center_distance_nms(detections, iou_threshold=0.3, distance_threshold=20):
    """
    ç»“åˆIOUå’Œä¸­å¿ƒè·ç¦»çš„NMS
    
    Args:
        distance_threshold: åƒç´ è·ç¦»é˜ˆå€¼
    """
    # ... å‰é¢è·ŸåŸæ¥çš„NMSä¸€æ · ...
    
    # è®¡ç®—æ¡†ä¸­å¿ƒ
    cx = (boxes[:, 0] + boxes[:, 2]) / 2
    cy = (boxes[:, 1] + boxes[:, 3]) / 2
    
    for i in order:
        # è®¡ç®—IOUï¼ˆåŸæœ‰é€»è¾‘ï¼‰
        iou = calculate_iou(...)
        
        # è®¡ç®—ä¸­å¿ƒè·ç¦»
        dx = cx[i] - cx[order[1:]]
        dy = cy[i] - cy[order[1:]]
        distance = np.sqrt(dx**2 + dy**2)
        
        # å¦‚æœIOUé«˜ æˆ– è·ç¦»è¿‘ï¼Œå°±æŠ‘åˆ¶
        suppress = (iou > iou_threshold) | (distance < distance_threshold)
        
        inds = np.where(~suppress)[0]
        order = order[inds + 1]
```

#### æ–¹æ¡ˆCï¼šè°ƒæ•´YOLOè®­ç»ƒå‚æ•°ï¼ˆæ ¹æœ¬è§£å†³ï¼‰

**é‡å¤æ¡†çš„æ ¹æœ¬åŸå› **ï¼šYOLOåœ¨åŒä¸€ä½ç½®é¢„æµ‹äº†å¤šä¸ªæ¡†ã€‚

**è§£å†³æ–¹æ³•**ï¼šè°ƒæ•´YOLOè®­ç»ƒæ—¶çš„è¶…å‚æ•°

åœ¨ `D1_training.py` ä¸­ï¼š

```python
# è®­ç»ƒå‚æ•°
model.train(
    ...
    # å…³é”®å‚æ•°ï¼š
    box=7.5,        # box lossæƒé‡ï¼ˆé»˜è®¤7.5ï¼‰â†’ å¢åŠ åˆ°10.0
    cls=0.5,        # cls lossæƒé‡ï¼ˆé»˜è®¤0.5ï¼‰â†’ å¢åŠ åˆ°1.0
    dfl=1.5,        # dfl lossæƒé‡ï¼ˆé»˜è®¤1.5ï¼‰
    
    # NMSå‚æ•°ï¼ˆè®­ç»ƒæ—¶ï¼‰
    iou=0.7,        # NMS IOUé˜ˆå€¼ â†’ é™ä½åˆ°0.5
    
    # æ ‡ç­¾å¹³æ»‘ï¼ˆå‡å°‘è¿‡åº¦è‡ªä¿¡ï¼‰
    label_smoothing=0.1,  # é»˜è®¤0 â†’ 0.1
)
```

**è¿™äº›å‚æ•°çš„ä½œç”¨**ï¼š

```
box â†‘ â†’ è¾¹ç•Œæ¡†å®šä½æ›´å‡†ç¡® â†’ å‡å°‘åŒä¸€ç›®æ ‡çš„å¤šæ¡†é¢„æµ‹
cls â†‘ â†’ ç±»åˆ«é¢„æµ‹æ›´è‡ªä¿¡ â†’ å‡å°‘ä¸åŒç±»åˆ«é¢„æµ‹åŒä¸€ç›®æ ‡
iou â†“ â†’ è®­ç»ƒæ—¶NMSæ›´ä¸¥æ ¼ â†’ æ¨¡å‹å­¦ä¼šä¸é‡å¤é¢„æµ‹
label_smoothing â†‘ â†’ å‡å°‘è¿‡åº¦è‡ªä¿¡ â†’ ç±»åˆ«é¢„æµ‹æ›´ä¿å®ˆ
```

---

## ğŸš€ ç«‹å³å¯ç”¨çš„å¿«é€Ÿæ–¹æ¡ˆ

### å¦‚æœä½ ä¸æƒ³ä¿®æ”¹ä»£ç ï¼Œåªæƒ³è°ƒå‚æ•°ï¼š

#### 1. è°ƒæ•´è·¨ç±»åˆ«NMSé˜ˆå€¼ï¼ˆæœ€ç®€å•ï¼‰

```bash
# åœ¨ run_cascaded_eval.sh ä¸­æ·»åŠ 
--nms-iou 0.2  # ä»0.3é™åˆ°0.2

# å¦‚æœè¿˜æœ‰é‡å¤æ¡†
--nms-iou 0.15
```

#### 2. é™ä½ç¬¬ä¸€é˜¶æ®µYOLOçš„NMSé˜ˆå€¼

ä¿®æ”¹ `balloon_cascaded_detection.py` ä¸­çš„ `generate_proposals`:

```python
results = self.model.predict(
    ...
    iou=0.3,  # â† ä»0.45é™åˆ°0.3
)
```

#### 3. æé«˜ç¬¬ä¸€é˜¶æ®µçš„ç½®ä¿¡åº¦é˜ˆå€¼

```bash
# åœ¨ run_cascaded_detection.sh ä¸­
STAGE1_CONF=0.10  # ä»0.05æé«˜åˆ°0.10
```

**æ•ˆæœ**ï¼šæ›´å°‘çš„å€™é€‰æ¡† â†’ æ›´å°‘çš„é‡å¤é¢„æµ‹

---

## ğŸ“Š é¢„æœŸæ•ˆæœå¯¹æ¯”

### æ•°æ®å¢å¼ºå‰åå¯¹æ¯”

**ä¹‹å‰**ï¼š
```
Epoch 1: Train 85%, Val 80%
Epoch 3: Train 92%, Val 84%
Epoch 6: Train 97%, Val 86%
Epoch 8: Train 99%, Val 86% â† è¿‡æ‹Ÿåˆ
```

**ä¹‹åï¼ˆåŠ æ•°æ®å¢å¼ºï¼‰**ï¼š
```
Epoch 1: Train 75%, Val 75%
Epoch 5: Train 82%, Val 82%
Epoch 10: Train 88%, Val 87%
Epoch 15: Train 91%, Val 89%
Epoch 20: Train 93%, Val 90% â† å¥åº·æ”¶æ•›
```

### é‡å¤æ¡†é—®é¢˜æ”¹å–„

**ä¹‹å‰**ï¼š
```
ä¸€ä¸ªå­”æ´ = 3ä¸ªæ¡†ï¼ˆä¸åŒè§’åº¦ï¼‰
IOU: 0.2, 0.25, 0.18
NMSé˜ˆå€¼=0.3 â†’ æ— æ³•è¿‡æ»¤ âŒ
```

**ä¹‹åï¼ˆé™ä½NMSé˜ˆå€¼åˆ°0.15ï¼‰**ï¼š
```
ä¸€ä¸ªå­”æ´ = 1ä¸ªæ¡†
ä¿ç•™æœ€é«˜ç½®ä¿¡åº¦çš„æ¡† âœ…
```

---

## æ€»ç»“

1. **è¿‡æ‹Ÿåˆé—®é¢˜**ï¼šä¼˜å…ˆæ·»åŠ æ•°æ®å¢å¼ºï¼Œå…¶æ¬¡å¢åŠ Dropoutå’Œæƒé‡è¡°å‡
2. **é‡å¤æ¡†é—®é¢˜**ï¼šå…ˆé™ä½NMSé˜ˆå€¼ï¼ˆ0.15-0.2ï¼‰ï¼Œå¦‚æœä¸å¤Ÿå†è€ƒè™‘é‡æ–°è®­ç»ƒYOLO
3. **é•¿æœŸæ–¹æ¡ˆ**ï¼šé‡æ–°è®­ç»ƒYOLOæ—¶è°ƒæ•´box/cls lossæƒé‡å’Œlabel_smoothing

ä¸‹ä¸€æ­¥ï¼šæˆ‘ä¼šä¿®æ”¹ä»£ç å®ç°è¿™äº›æ”¹è¿›ï¼

