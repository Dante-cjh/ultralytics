#!/bin/bash
# -*- coding: utf-8 -*-

################################################################################
# D1 æ•°æ®é›†ç»¼åˆæµ‹è¯•è„šæœ¬
# æ•´åˆä¸‰ç§æ¨ç†æ–¹å¼ï¼šå¸¸è§„æ¨ç†ã€SAHIåˆ‡ç‰‡æ¨ç†ã€å¤šå°ºåº¦æ¨ç†
# ç”¨äºæ–°æ•°æ®é›†çš„éªŒæ”¶æµ‹è¯•
################################################################################

set -e  # é‡åˆ°é”™è¯¯ç«‹å³é€€å‡º

# ============================================================================
# é…ç½®å‚æ•° - è¯·æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹
# ============================================================================

# æ–°æ•°æ®é›†è·¯å¾„ï¼ˆå­˜æ”¾å¾…æµ‹è¯•å›¾åƒçš„æ–‡ä»¶å¤¹ï¼‰
NEW_DATA_DIR="/path/to/new/test/images"

# æ€»ä¿å­˜è·¯å¾„ï¼ˆæ‰€æœ‰ç»“æœéƒ½ä¿å­˜åœ¨è¿™ä¸ªç›®å½•ä¸‹ï¼‰
OUTPUT_ROOT="runs/comprehensive_test"

# è®¾å¤‡é…ç½®
DEVICE=0

# æ¨¡å‹è·¯å¾„é…ç½®
# 1. å¸¸è§„æ¨¡å‹ï¼ˆæ­£å¸¸è®­ç»ƒçš„æ¨¡å‹ï¼‰
NORMAL_MODEL="runs/detect/D1_yolo11l_20241211/weights/best.pt"

# 2. åˆ‡ç‰‡æ¨¡å‹ï¼ˆä½¿ç”¨åˆ‡ç‰‡æ•°æ®è®­ç»ƒçš„æ¨¡å‹ï¼‰
SLICE_MODEL="runs/detect/D1_yolo11l_slice_20241211/weights/best.pt"

# 3. å¤šå°ºåº¦æ¨¡å‹ï¼ˆç”¨äºå¤šå°ºåº¦æ¨ç†ï¼Œå¯ä»¥å’Œå¸¸è§„æ¨¡å‹ç›¸åŒï¼‰
MULTISCALE_MODEL="runs/detect/D1_yolo11l_20241211/weights/best.pt"

# æ¨ç†å‚æ•°
CONFIDENCE=0.3
IOU_THRESHOLD=0.5

# SAHIæ¨ç†å‚æ•°
SLICE_HEIGHT=640
SLICE_WIDTH=640
OVERLAP_RATIO=0.15
POSTPROCESS_TYPE="NMS"
POSTPROCESS_THRESHOLD=0.6
POSTPROCESS_METRIC="IOS"
MIN_BOX_AREA=200
MAX_DETECTIONS=50

# å¤šå°ºåº¦æ¨ç†å‚æ•°
SCALES="640 832 1024 1280"
FUSION_METHOD="nms"

# æ—¶é—´æˆ³
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")

# ============================================================================
# å‡½æ•°å®šä¹‰
# ============================================================================

# æ—¥å¿—å‡½æ•°
log_info() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] [INFO] $1"
}

log_error() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] [ERROR] $1" >&2
}

log_section() {
    echo ""
    echo "========================================================================"
    echo "$1"
    echo "========================================================================"
    echo ""
}

# ç»Ÿè®¡æ£€æµ‹æ•°é‡å‡½æ•°
count_detections() {
    local labels_dir=$1
    local method_name=$2
    
    log_info "ğŸ“Š ç»Ÿè®¡ ${method_name} çš„æ£€æµ‹ç»“æœ..."
    
    if [ ! -d "${labels_dir}" ]; then
        log_error "æ ‡ç­¾ç›®å½•ä¸å­˜åœ¨: ${labels_dir}"
        return 1
    fi
    
    local total_detections=0
    local image_count=0
    
    # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ä¿å­˜è¯¦ç»†ç»Ÿè®¡
    local detail_file="${labels_dir}/../detection_stats.txt"
    echo "=== ${method_name} æ£€æµ‹ç»Ÿè®¡ ===" > "${detail_file}"
    echo "ç”Ÿæˆæ—¶é—´: $(date '+%Y-%m-%d %H:%M:%S')" >> "${detail_file}"
    echo "" >> "${detail_file}"
    
    # éå†æ‰€æœ‰æ ‡ç­¾æ–‡ä»¶
    for label_file in "${labels_dir}"/*.txt; do
        if [ -f "${label_file}" ]; then
            local filename=$(basename "${label_file}")
            local count=$(wc -l < "${label_file}" 2>/dev/null || echo "0")
            
            echo "  ${filename}: ${count} ä¸ªç›®æ ‡" >> "${detail_file}"
            log_info "  ${filename}: ${count} ä¸ªç›®æ ‡"
            
            total_detections=$((total_detections + count))
            image_count=$((image_count + 1))
        fi
    done
    
    if [ ${image_count} -eq 0 ]; then
        log_error "æœªæ‰¾åˆ°ä»»ä½•æ ‡ç­¾æ–‡ä»¶"
        return 1
    fi
    
    local avg_detections=$(echo "scale=2; ${total_detections} / ${image_count}" | bc)
    
    echo "" >> "${detail_file}"
    echo "=== æ€»ç»“ ===" >> "${detail_file}"
    echo "å›¾åƒæ€»æ•°: ${image_count}" >> "${detail_file}"
    echo "æ£€æµ‹æ€»æ•°: ${total_detections}" >> "${detail_file}"
    echo "å¹³å‡æ¯å¼ : ${avg_detections} ä¸ªç›®æ ‡" >> "${detail_file}"
    
    log_section "ğŸ“Š ${method_name} ç»Ÿè®¡ç»“æœ"
    log_info "  å›¾åƒæ€»æ•°: ${image_count}"
    log_info "  æ£€æµ‹æ€»æ•°: ${total_detections}"
    log_info "  å¹³å‡æ¯å¼ : ${avg_detections} ä¸ªç›®æ ‡"
    log_info "  è¯¦ç»†ç»Ÿè®¡: ${detail_file}"
    
    return 0
}

# 1. å¸¸è§„æ¨ç†å‡½æ•°
run_normal_inference() {
    local model_path=$1
    local source_dir=$2
    local save_dir=$3
    
    log_section "ğŸ” æ–¹æ³•1: å¸¸è§„æ¨ç†"
    log_info "æ¨¡å‹: ${model_path}"
    log_info "æ•°æ®: ${source_dir}"
    log_info "ä¿å­˜: ${save_dir}"
    
    if [ ! -f "${model_path}" ]; then
        log_error "æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: ${model_path}"
        return 1
    fi
    
    if [ ! -d "${source_dir}" ]; then
        log_error "æ•°æ®ç›®å½•ä¸å­˜åœ¨: ${source_dir}"
        return 1
    fi
    
    python3 balloon_inference.py \
        --model "${model_path}" \
        --source "${source_dir}" \
        --save-dir "${save_dir}" \
        --confidence ${CONFIDENCE} \
        --iou ${IOU_THRESHOLD} \
        --device "cuda:${DEVICE}"
    
    if [ $? -eq 0 ]; then
        log_info "âœ… å¸¸è§„æ¨ç†å®Œæˆ"
        count_detections "${save_dir}/labels" "å¸¸è§„æ¨ç†"
    else
        log_error "âŒ å¸¸è§„æ¨ç†å¤±è´¥"
        return 1
    fi
}

# 2. SAHIåˆ‡ç‰‡æ¨ç†å‡½æ•°
run_sahi_inference() {
    local model_path=$1
    local source_dir=$2
    local save_dir=$3
    
    log_section "ğŸ” æ–¹æ³•2: SAHIåˆ‡ç‰‡æ¨ç†"
    log_info "æ¨¡å‹: ${model_path}"
    log_info "æ•°æ®: ${source_dir}"
    log_info "ä¿å­˜: ${save_dir}"
    
    if [ ! -f "${model_path}" ]; then
        log_error "æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: ${model_path}"
        return 1
    fi
    
    if [ ! -d "${source_dir}" ]; then
        log_error "æ•°æ®ç›®å½•ä¸å­˜åœ¨: ${source_dir}"
        return 1
    fi
    
    python3 D1_inference_with_sahi_v3.py \
        --model "${model_path}" \
        --source "${source_dir}" \
        --save-dir "${save_dir}" \
        --confidence ${CONFIDENCE} \
        --device "cuda:${DEVICE}" \
        --slice-height ${SLICE_HEIGHT} \
        --slice-width ${SLICE_WIDTH} \
        --overlap-height ${OVERLAP_RATIO} \
        --overlap-width ${OVERLAP_RATIO} \
        --postprocess-type ${POSTPROCESS_TYPE} \
        --postprocess-threshold ${POSTPROCESS_THRESHOLD} \
        --postprocess-metric ${POSTPROCESS_METRIC} \
        --min-box-area ${MIN_BOX_AREA} \
        --max-detections ${MAX_DETECTIONS}
    
    if [ $? -eq 0 ]; then
        log_info "âœ… SAHIåˆ‡ç‰‡æ¨ç†å®Œæˆ"
        count_detections "${save_dir}/labels" "SAHIåˆ‡ç‰‡æ¨ç†"
    else
        log_error "âŒ SAHIåˆ‡ç‰‡æ¨ç†å¤±è´¥"
        return 1
    fi
}

# 3. å¤šå°ºåº¦æ¨ç†å‡½æ•°
run_multiscale_inference() {
    local model_path=$1
    local source_dir=$2
    local save_dir=$3
    
    log_section "ğŸ” æ–¹æ³•3: å¤šå°ºåº¦æ¨ç†"
    log_info "æ¨¡å‹: ${model_path}"
    log_info "æ•°æ®: ${source_dir}"
    log_info "ä¿å­˜: ${save_dir}"
    log_info "å°ºåº¦: ${SCALES}"
    
    if [ ! -f "${model_path}" ]; then
        log_error "æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: ${model_path}"
        return 1
    fi
    
    if [ ! -d "${source_dir}" ]; then
        log_error "æ•°æ®ç›®å½•ä¸å­˜åœ¨: ${source_dir}"
        return 1
    fi
    
    python3 balloon_inference_multiscale.py \
        --model "${model_path}" \
        --source "${source_dir}" \
        --save-dir "${save_dir}" \
        --scales ${SCALES} \
        --confidence ${CONFIDENCE} \
        --iou ${IOU_THRESHOLD} \
        --device "cuda:${DEVICE}" \
        --fusion ${FUSION_METHOD}
    
    if [ $? -eq 0 ]; then
        log_info "âœ… å¤šå°ºåº¦æ¨ç†å®Œæˆ"
        count_detections "${save_dir}/labels" "å¤šå°ºåº¦æ¨ç†"
    else
        log_error "âŒ å¤šå°ºåº¦æ¨ç†å¤±è´¥"
        return 1
    fi
}

# ============================================================================
# ä¸»æµç¨‹
# ============================================================================

log_section "ğŸš€ D1 æ•°æ®é›†ç»¼åˆæµ‹è¯•å¼€å§‹"
log_info "æµ‹è¯•æ—¶é—´: ${TIMESTAMP}"
log_info "æ–°æ•°æ®é›†: ${NEW_DATA_DIR}"
log_info "ä¿å­˜è·¯å¾„: ${OUTPUT_ROOT}"

# éªŒè¯è¾“å…¥
if [ ! -d "${NEW_DATA_DIR}" ]; then
    log_error "æ–°æ•°æ®é›†ç›®å½•ä¸å­˜åœ¨: ${NEW_DATA_DIR}"
    log_error "è¯·ä¿®æ”¹è„šæœ¬ä¸­çš„ NEW_DATA_DIR å˜é‡"
    exit 1
fi

# ç»Ÿè®¡å›¾åƒæ•°é‡
IMAGE_COUNT=$(find "${NEW_DATA_DIR}" -type f \( -iname "*.jpg" -o -iname "*.jpeg" -o -iname "*.png" -o -iname "*.bmp" \) | wc -l)
log_info "å¾…æµ‹è¯•å›¾åƒ: ${IMAGE_COUNT} å¼ "

if [ ${IMAGE_COUNT} -eq 0 ]; then
    log_error "æœªæ‰¾åˆ°ä»»ä½•å›¾åƒæ–‡ä»¶"
    exit 1
fi

# åˆ›å»ºè¾“å‡ºç›®å½•
mkdir -p "${OUTPUT_ROOT}"

# è®°å½•å¼€å§‹æ—¶é—´
START_TIME=$(date +%s)

# ============================================================================
# æ–¹æ³•1: å¸¸è§„æ¨ç†
# ============================================================================

if [ -f "${NORMAL_MODEL}" ]; then
    NORMAL_SAVE_DIR="${OUTPUT_ROOT}/01_normal_inference_${TIMESTAMP}"
    run_normal_inference "${NORMAL_MODEL}" "${NEW_DATA_DIR}" "${NORMAL_SAVE_DIR}" || log_error "å¸¸è§„æ¨ç†å¤±è´¥"
else
    log_error "å¸¸è§„æ¨¡å‹ä¸å­˜åœ¨: ${NORMAL_MODEL}"
    log_error "è¯·ä¿®æ”¹è„šæœ¬ä¸­çš„ NORMAL_MODEL å˜é‡"
fi

# ============================================================================
# æ–¹æ³•2: SAHIåˆ‡ç‰‡æ¨ç†
# ============================================================================

if [ -f "${SLICE_MODEL}" ]; then
    SAHI_SAVE_DIR="${OUTPUT_ROOT}/02_sahi_inference_${TIMESTAMP}"
    run_sahi_inference "${SLICE_MODEL}" "${NEW_DATA_DIR}" "${SAHI_SAVE_DIR}" || log_error "SAHIæ¨ç†å¤±è´¥"
else
    log_error "åˆ‡ç‰‡æ¨¡å‹ä¸å­˜åœ¨: ${SLICE_MODEL}"
    log_error "è¯·ä¿®æ”¹è„šæœ¬ä¸­çš„ SLICE_MODEL å˜é‡"
fi

# ============================================================================
# æ–¹æ³•3: å¤šå°ºåº¦æ¨ç†
# ============================================================================

if [ -f "${MULTISCALE_MODEL}" ]; then
    MULTISCALE_SAVE_DIR="${OUTPUT_ROOT}/03_multiscale_inference_${TIMESTAMP}"
    run_multiscale_inference "${MULTISCALE_MODEL}" "${NEW_DATA_DIR}" "${MULTISCALE_SAVE_DIR}" || log_error "å¤šå°ºåº¦æ¨ç†å¤±è´¥"
else
    log_error "å¤šå°ºåº¦æ¨¡å‹ä¸å­˜åœ¨: ${MULTISCALE_MODEL}"
    log_error "è¯·ä¿®æ”¹è„šæœ¬ä¸­çš„ MULTISCALE_MODEL å˜é‡"
fi

# ============================================================================
# æ€»ç»“
# ============================================================================

END_TIME=$(date +%s)
DURATION=$((END_TIME - START_TIME))
HOURS=$((DURATION / 3600))
MINUTES=$(((DURATION % 3600) / 60))
SECONDS=$((DURATION % 60))

log_section "ğŸ‰ ç»¼åˆæµ‹è¯•å®Œæˆ"
log_info "æ€»è€—æ—¶: ${HOURS}å°æ—¶ ${MINUTES}åˆ†é’Ÿ ${SECONDS}ç§’"
log_info ""
log_info "ğŸ“ ç»“æœä¿å­˜ä½ç½®:"
log_info "  æ€»ç›®å½•: ${OUTPUT_ROOT}"
log_info ""

if [ -d "${NORMAL_SAVE_DIR}" ]; then
    log_info "  1ï¸âƒ£  å¸¸è§„æ¨ç†:"
    log_info "     å›¾åƒ: ${NORMAL_SAVE_DIR}/*_visual.jpg"
    log_info "     æ ‡ç­¾: ${NORMAL_SAVE_DIR}/labels/*.txt"
    log_info "     ç»Ÿè®¡: ${NORMAL_SAVE_DIR}/detection_stats.txt"
    log_info ""
fi

if [ -d "${SAHI_SAVE_DIR}" ]; then
    log_info "  2ï¸âƒ£  SAHIåˆ‡ç‰‡æ¨ç†:"
    log_info "     å›¾åƒ: ${SAHI_SAVE_DIR}/*_visual.jpg"
    log_info "     æ ‡ç­¾: ${SAHI_SAVE_DIR}/labels/*.txt"
    log_info "     ç»Ÿè®¡: ${SAHI_SAVE_DIR}/detection_stats.txt"
    log_info ""
fi

if [ -d "${MULTISCALE_SAVE_DIR}" ]; then
    log_info "  3ï¸âƒ£  å¤šå°ºåº¦æ¨ç†:"
    log_info "     å›¾åƒ: ${MULTISCALE_SAVE_DIR}/*_multiscale.jpg"
    log_info "     æ ‡ç­¾: ${MULTISCALE_SAVE_DIR}/labels/*.txt"
    log_info "     ç»Ÿè®¡: ${MULTISCALE_SAVE_DIR}/detection_stats.txt"
    log_info ""
fi

log_info "========================================================================"
log_info ""
log_info "ğŸ’¡ ä½¿ç”¨è¯´æ˜ï¼š"
log_info "  1. æŸ¥çœ‹å¯è§†åŒ–ç»“æœå›¾ç‰‡ï¼Œäº†è§£æ£€æµ‹æ•ˆæœ"
log_info "  2. æŸ¥çœ‹ detection_stats.txt æ–‡ä»¶ï¼Œäº†è§£æ¯å¼ å›¾ç‰‡çš„æ£€æµ‹æ•°é‡"
log_info "  3. æ¯”è¾ƒä¸‰ç§æ–¹æ³•çš„æ£€æµ‹ç»“æœï¼Œé€‰æ‹©æœ€ä¼˜æ–¹æ¡ˆ"
log_info ""
log_info "ğŸ“Š å¿«é€Ÿå¯¹æ¯”å‘½ä»¤ï¼š"
log_info "  cat ${OUTPUT_ROOT}/*/detection_stats.txt"
log_info ""

