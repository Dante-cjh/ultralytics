#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤šç½®ä¿¡åº¦æ¨ç†è„šæœ¬
æµ‹è¯•ä¸åŒç½®ä¿¡åº¦é˜ˆå€¼å¯¹æ£€æµ‹æ•°é‡çš„å½±å“
æ‰¾åˆ°æœ€ä¼˜çš„ç½®ä¿¡åº¦å‚æ•°ä»¥è¾¾åˆ°æœ€ä½³æ•°é‡å‡†ç¡®ç‡

ä½¿ç”¨æ–¹æ³•:
python balloon_inference_multi_conf.py \
    --model best.pt \
    --source /path/to/images \
    --true-labels /path/to/labels \
    --conf-list 0.05 0.1 0.15 0.2 0.25 0.3
"""

import argparse
import os
from pathlib import Path
from typing import List, Dict, Tuple
import time
import json

import cv2
import numpy as np
from ultralytics import YOLO
from ultralytics.utils import LOGGER


def count_lines_in_file(file_path: str) -> int:
    """è®¡ç®—txtæ–‡ä»¶ä¸­çš„éç©ºè¡Œæ•°"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        return len([line for line in lines if line.strip()])
    except Exception:
        return 0


def evaluate_count_accuracy(
    pred_labels_dir: str,
    true_labels_dir: str,
) -> Dict:
    """
    è¯„ä¼°æ£€æµ‹æ•°é‡å‡†ç¡®ç‡
    
    Args:
        pred_labels_dir: é¢„æµ‹æ ‡ç­¾ç›®å½•
        true_labels_dir: çœŸå®æ ‡ç­¾ç›®å½•
    
    Returns:
        è¯„ä¼°ç»“æœå­—å…¸
    """
    pred_dir = Path(pred_labels_dir)
    true_dir = Path(true_labels_dir)
    
    # è·å–å…±åŒæ–‡ä»¶
    pred_files = {f.stem for f in pred_dir.glob("*.txt")}
    true_files = {f.stem for f in true_dir.glob("*.txt")}
    common_files = pred_files & true_files
    
    if not common_files:
        return {"error": "æ²¡æœ‰å…±åŒæ–‡ä»¶", "global_metric": 0}
    
    total_true = 0
    total_pred = 0
    metrics = []
    
    for filename in common_files:
        true_count = count_lines_in_file(str(true_dir / f"{filename}.txt"))
        pred_count = count_lines_in_file(str(pred_dir / f"{filename}.txt"))
        
        total_true += true_count
        total_pred += pred_count
        
        if true_count > 0:
            metric = 1 - abs(pred_count - true_count) / true_count
        else:
            metric = 1.0 if pred_count == 0 else 0.0
        
        metrics.append(metric)
    
    # è®¡ç®—å…¨å±€æŒ‡æ ‡
    if total_true > 0:
        global_metric = 1 - abs(total_pred - total_true) / total_true
    else:
        global_metric = 1.0 if total_pred == 0 else 0.0
    
    avg_metric = sum(metrics) / len(metrics) if metrics else 0
    
    return {
        "global_metric": global_metric,
        "avg_metric": avg_metric,
        "total_true": total_true,
        "total_pred": total_pred,
        "diff": total_pred - total_true,
        "num_files": len(common_files),
    }


class MultiConfInference:
    """å¤šç½®ä¿¡åº¦æ¨ç†ç±»"""
    
    def __init__(
        self,
        model_path: str,
        device: str = "cuda:0"
    ):
        """
        åˆå§‹åŒ–æ¨ç†å™¨
        
        Args:
            model_path: æ¨¡å‹è·¯å¾„
            device: è®¾å¤‡
        """
        self.model_path = Path(model_path)
        self.device = device
        self.model = None
        
        if not self.model_path.exists():
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
        
        LOGGER.info(f"ğŸ” åŠ è½½æ¨¡å‹: {self.model_path}")
        self._load_model()
    
    def _load_model(self):
        """åŠ è½½æ¨¡å‹"""
        self.model = YOLO(str(self.model_path))
        LOGGER.info("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    
    def predict_with_conf(
        self,
        image_dir: str,
        save_dir: str,
        imgsz: int = 1280,
        conf_threshold: float = 0.25,
        iou_threshold: float = 0.5,
    ) -> int:
        """
        ä½¿ç”¨æŒ‡å®šç½®ä¿¡åº¦è¿›è¡Œæ¨ç†
        
        Args:
            image_dir: å›¾åƒç›®å½•
            save_dir: ä¿å­˜ç›®å½•
            imgsz: æ¨ç†å°ºå¯¸
            conf_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
            iou_threshold: NMS IoUé˜ˆå€¼
        
        Returns:
            æ€»æ£€æµ‹æ•°é‡
        """
        image_dir = Path(image_dir)
        save_dir = Path(save_dir)
        
        # åˆ›å»ºæ ‡ç­¾ç›®å½•
        labels_dir = save_dir / "labels"
        labels_dir.mkdir(parents=True, exist_ok=True)
        
        # è·å–å›¾åƒåˆ—è¡¨
        image_files = []
        for ext in [".jpg", ".jpeg", ".png", ".bmp"]:
            image_files.extend(image_dir.glob(f"*{ext}"))
            image_files.extend(image_dir.glob(f"*{ext.upper()}"))
        
        if not image_files:
            LOGGER.warning(f"âš ï¸ æœªæ‰¾åˆ°å›¾åƒ: {image_dir}")
            return 0
        
        total_detections = 0
        
        # æ‰¹é‡æ¨ç†
        results = self.model.predict(
            source=str(image_dir),
            imgsz=imgsz,
            conf=conf_threshold,
            iou=iou_threshold,
            device=self.device,
            verbose=False,
            save=False,
            save_txt=False,
        )
        
        # ä¿å­˜ç»“æœ
        for result in results:
            img_path = Path(result.path)
            num_detections = len(result.boxes)
            total_detections += num_detections
            
            # ä¿å­˜txtæ ‡ç­¾
            txt_path = labels_dir / f"{img_path.stem}.txt"
            
            if num_detections > 0:
                boxes = result.boxes.xyxy.cpu().numpy()
                scores = result.boxes.conf.cpu().numpy()
                classes = result.boxes.cls.cpu().numpy()
                
                # è·å–å›¾åƒå°ºå¯¸
                h, w = result.orig_shape
                
                with open(txt_path, 'w') as f:
                    for box, score, cls in zip(boxes, scores, classes):
                        x1, y1, x2, y2 = box
                        x_center = (x1 + x2) / 2.0 / w
                        y_center = (y1 + y2) / 2.0 / h
                        box_width = (x2 - x1) / w
                        box_height = (y2 - y1) / h
                        f.write(f"{int(cls)} {x_center:.6f} {y_center:.6f} {box_width:.6f} {box_height:.6f} {score:.6f}\n")
            else:
                # åˆ›å»ºç©ºæ–‡ä»¶
                txt_path.touch()
        
        return total_detections
    
    def test_multi_conf(
        self,
        image_dir: str,
        true_labels_dir: str,
        save_base_dir: str,
        imgsz: int = 1280,
        conf_list: List[float] = None,
        iou_threshold: float = 0.5,
    ) -> Dict:
        """
        æµ‹è¯•å¤šä¸ªç½®ä¿¡åº¦é˜ˆå€¼
        
        Args:
            image_dir: å›¾åƒç›®å½•
            true_labels_dir: çœŸå®æ ‡ç­¾ç›®å½•
            save_base_dir: ä¿å­˜åŸºç¡€ç›®å½•
            imgsz: æ¨ç†å°ºå¯¸
            conf_list: ç½®ä¿¡åº¦åˆ—è¡¨
            iou_threshold: NMS IoUé˜ˆå€¼
        
        Returns:
            æ‰€æœ‰ç»“æœ
        """
        if conf_list is None:
            conf_list = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]
        
        LOGGER.info(f"ğŸ¯ å¼€å§‹å¤šç½®ä¿¡åº¦æµ‹è¯•")
        LOGGER.info(f"   ç½®ä¿¡åº¦åˆ—è¡¨: {conf_list}")
        LOGGER.info(f"   IoUé˜ˆå€¼: {iou_threshold}")
        LOGGER.info(f"   å›¾åƒå°ºå¯¸: {imgsz}")
        
        results = []
        best_result = None
        best_metric = -float('inf')
        
        for i, conf in enumerate(conf_list, 1):
            LOGGER.info(f"\n{'='*60}")
            LOGGER.info(f"[{i}/{len(conf_list)}] æµ‹è¯•ç½®ä¿¡åº¦: {conf}")
            LOGGER.info(f"{'='*60}")
            
            # åˆ›å»ºä¿å­˜ç›®å½•
            save_dir = Path(save_base_dir) / f"conf_{conf}"
            
            # æ¨ç†
            start_time = time.time()
            total_detections = self.predict_with_conf(
                image_dir=image_dir,
                save_dir=str(save_dir),
                imgsz=imgsz,
                conf_threshold=conf,
                iou_threshold=iou_threshold,
            )
            inference_time = time.time() - start_time
            
            # è¯„ä¼°
            eval_result = evaluate_count_accuracy(
                str(save_dir / "labels"),
                true_labels_dir
            )
            
            result = {
                "conf": conf,
                "iou": iou_threshold,
                "total_detections": total_detections,
                "inference_time": inference_time,
                **eval_result
            }
            results.append(result)
            
            LOGGER.info(f"   æ€»æ£€æµ‹æ•°: {total_detections}")
            LOGGER.info(f"   çœŸå®æ€»æ•°: {eval_result['total_true']}")
            LOGGER.info(f"   å·®å€¼: {eval_result['diff']:+d}")
            LOGGER.info(f"   å…¨å±€Metric: {eval_result['global_metric']:.4f} ({eval_result['global_metric']*100:.2f}%)")
            LOGGER.info(f"   å¹³å‡Metric: {eval_result['avg_metric']:.4f}")
            LOGGER.info(f"   è€—æ—¶: {inference_time:.2f}s")
            
            if eval_result['global_metric'] > best_metric:
                best_metric = eval_result['global_metric']
                best_result = result
        
        # æ‰“å°æ€»ç»“
        LOGGER.info(f"\n{'='*70}")
        LOGGER.info(f"ğŸ† å¤šç½®ä¿¡åº¦æµ‹è¯•å®Œæˆï¼")
        LOGGER.info(f"{'='*70}")
        
        LOGGER.info(f"\nğŸ“Š ç»“æœæ±‡æ€»è¡¨:")
        LOGGER.info(f"{'conf':>8} | {'é¢„æµ‹æ•°':>8} | {'çœŸå®æ•°':>8} | {'å·®å€¼':>8} | {'å…¨å±€Metric':>12} | {'å¹³å‡Metric':>12}")
        LOGGER.info(f"{'-'*8}-+-{'-'*8}-+-{'-'*8}-+-{'-'*8}-+-{'-'*12}-+-{'-'*12}")
        
        for r in results:
            LOGGER.info(f"{r['conf']:>8.2f} | {r['total_detections']:>8d} | {r['total_true']:>8d} | {r['diff']:>+8d} | {r['global_metric']:>12.4f} | {r['avg_metric']:>12.4f}")
        
        LOGGER.info(f"\nğŸ† æœ€ä½³å‚æ•°:")
        LOGGER.info(f"   ç½®ä¿¡åº¦: {best_result['conf']}")
        LOGGER.info(f"   å…¨å±€Metric: {best_result['global_metric']:.4f} ({best_result['global_metric']*100:.2f}%)")
        LOGGER.info(f"   é¢„æµ‹æ€»æ•°: {best_result['total_detections']}")
        LOGGER.info(f"   çœŸå®æ€»æ•°: {best_result['total_true']}")
        LOGGER.info(f"   å·®å€¼: {best_result['diff']:+d}")
        
        # ä¿å­˜ç»“æœåˆ°JSON
        save_path = Path(save_base_dir) / "multi_conf_results.json"
        with open(save_path, 'w') as f:
            json.dump({
                "best_conf": best_result['conf'],
                "best_metric": best_metric,
                "all_results": results
            }, f, indent=2)
        LOGGER.info(f"\nğŸ“ ç»“æœå·²ä¿å­˜: {save_path}")
        
        return {
            "best_conf": best_result['conf'],
            "best_metric": best_metric,
            "best_result": best_result,
            "all_results": results
        }


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="å¤šç½®ä¿¡åº¦æ¨ç†æµ‹è¯•è„šæœ¬",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:

1. æµ‹è¯•å¤šä¸ªç½®ä¿¡åº¦:
   python balloon_inference_multi_conf.py \\
       --model best.pt \\
       --source /path/to/images \\
       --true-labels /path/to/labels \\
       --conf-list 0.05 0.1 0.15 0.2 0.25 0.3

2. ä½¿ç”¨é»˜è®¤ç½®ä¿¡åº¦åˆ—è¡¨:
   python balloon_inference_multi_conf.py \\
       --model best.pt \\
       --source /path/to/images \\
       --true-labels /path/to/labels

3. æŒ‡å®šNMS IoUé˜ˆå€¼:
   python balloon_inference_multi_conf.py \\
       --model best.pt \\
       --source /path/to/images \\
       --true-labels /path/to/labels \\
       --iou 0.6
        """
    )
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument("--model", type=str, required=True, help="æ¨¡å‹è·¯å¾„")
    parser.add_argument("--device", type=str, default="cuda:0", help="è®¾å¤‡")
    parser.add_argument("--imgsz", type=int, default=1280, help="æ¨ç†å°ºå¯¸")
    
    # è¾“å…¥è¾“å‡º
    parser.add_argument("--source", type=str, required=True, help="å›¾åƒç›®å½•")
    parser.add_argument("--true-labels", type=str, required=True, help="çœŸå®æ ‡ç­¾ç›®å½•")
    parser.add_argument("--save-dir", type=str, default="runs/multi_conf_test", help="ä¿å­˜ç›®å½•")
    
    # æµ‹è¯•å‚æ•°
    parser.add_argument("--conf-list", type=float, nargs="+", 
                       default=[0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4],
                       help="ç½®ä¿¡åº¦åˆ—è¡¨")
    parser.add_argument("--iou", type=float, default=0.5, help="NMS IoUé˜ˆå€¼")
    
    args = parser.parse_args()
    
    try:
        LOGGER.info("ğŸš€ åˆå§‹åŒ–å¤šç½®ä¿¡åº¦æ¨ç†å™¨...")
        inferencer = MultiConfInference(args.model, args.device)
        
        results = inferencer.test_multi_conf(
            image_dir=args.source,
            true_labels_dir=args.true_labels,
            save_base_dir=args.save_dir,
            imgsz=args.imgsz,
            conf_list=args.conf_list,
            iou_threshold=args.iou,
        )
        
    except Exception as e:
        LOGGER.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()

