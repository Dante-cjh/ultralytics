# Balloon æ•°æ®é›† SAHI åˆ‡ç‰‡æ¨ç†æŒ‡å—

## æ¦‚è¿°

æœ¬æŒ‡å—è¯´æ˜å¦‚ä½•ä½¿ç”¨ SAHI (Slicing Aided Hyper Inference) å¯¹è®­ç»ƒå¥½çš„ Balloon æ¨¡å‹è¿›è¡Œå¤§å°ºå¯¸å›¾åƒçš„åˆ‡ç‰‡æ¨ç†ã€‚

## âœ… å®˜æ–¹æ”¯æŒç¡®è®¤

**å¥½æ¶ˆæ¯**ï¼šUltralytics å®˜æ–¹å®Œå…¨æ”¯æŒ SAHI åˆ‡ç‰‡æ¨ç†ï¼Œå¯ä»¥ç›´æ¥ç”¨äº COCO æ ¼å¼ï¼ˆæ°´å¹³æ¡†ï¼‰ï¼

- ğŸ“š **å®˜æ–¹æ–‡æ¡£**: `docs/en/guides/sahi-tiled-inference.md`
- ğŸ’» **ç¤ºä¾‹ä»£ç **: `examples/YOLOv8-SAHI-Inference-Video/`
- ğŸ”„ **æ ¼å¼æ”¯æŒ**: COCOã€YOLOã€OBB ç­‰æ‰€æœ‰æ ¼å¼

## SAHI vs æ‰‹åŠ¨åˆ‡ç‰‡å¯¹æ¯”

### DOTA æ‰‹åŠ¨åˆ‡ç‰‡æ–¹å¼

```python
# è®­ç»ƒæ—¶åˆ‡ç‰‡
from ultralytics.data.split_dota import split_trainval
split_trainval(data_root="DOTA", save_dir="DOTA-split")

# æ¨ç†æ—¶ï¼šéœ€è¦è‡ªå·±å®ç°
# 1. æ‰‹åŠ¨åˆ‡ç‰‡å›¾åƒ
# 2. é€ç‰‡æ¨ç†
# 3. æ‰‹åŠ¨åˆå¹¶ç»“æœï¼ˆå¤æ‚çš„NMSï¼‰
```

### SAHI è‡ªåŠ¨åŒ–æ–¹å¼ âœ…

```python
# è®­ç»ƒæ—¶åˆ‡ç‰‡ï¼ˆæˆ‘ä»¬å·²å®ç°ï¼‰
from ultralytics.data.split_yolo import split_trainval
split_trainval(data_root="balloon", save_dir="balloon-split")

# æ¨ç†æ—¶ï¼šSAHI ä¸€è¡Œæå®šï¼
from sahi.predict import get_sliced_prediction
result = get_sliced_prediction(
    image,
    detection_model,
    slice_height=640,
    slice_width=640,
    overlap_height_ratio=0.2,
    overlap_width_ratio=0.2,
)
```

**SAHI è‡ªåŠ¨å¤„ç†ï¼š**
- âœ… è‡ªåŠ¨åˆ‡ç‰‡
- âœ… æ‰¹é‡æ¨ç†
- âœ… æ™ºèƒ½åˆå¹¶ï¼ˆNMS å»é‡ï¼‰
- âœ… è¾¹ç•Œæ¡†ä¿®æ­£
- âœ… æ”¯æŒå¤šç§è¾“å‡ºæ ¼å¼

## å®‰è£…ä¾èµ–

```bash
# æ¿€æ´»ç¯å¢ƒ
source /home/cjh/anaconda3/bin/activate ultralytics

# å®‰è£… SAHI
pip install sahi
```

## ä½¿ç”¨æ–¹æ³•

### 1. å•å¼ å›¾åƒæ¨ç†

```bash
python balloon_inference_with_sahi.py \
    --model runs/detect/balloon_yolo11n_slice/weights/best.pt \
    --source test_image.jpg \
    --slice-height 640 \
    --slice-width 640 \
    --overlap-height 0.2 \
    --overlap-width 0.2 \
    --save-dir runs/sahi_inference
```

### 2. æ‰¹é‡å›¾åƒæ¨ç†

```bash
python balloon_inference_with_sahi.py \
    --model runs/detect/balloon_yolo11n_slice/weights/best.pt \
    --source /path/to/test/images/ \
    --slice-height 640 \
    --slice-width 640 \
    --save-dir runs/sahi_inference
```

### 3. ä½¿ç”¨å¤šå°ºåº¦è®­ç»ƒçš„æ¨¡å‹

```bash
# ä½¿ç”¨å¤šå°ºåº¦åˆ‡ç‰‡è®­ç»ƒçš„æ¨¡å‹
python balloon_inference_with_sahi.py \
    --model runs/detect/balloon_yolo11n_multi_slice/weights/best.pt \
    --source /path/to/test/images/ \
    --slice-height 640 \
    --slice-width 640
```

### 4. è°ƒæ•´ç½®ä¿¡åº¦é˜ˆå€¼

```bash
python balloon_inference_with_sahi.py \
    --model best.pt \
    --source test_images/ \
    --confidence 0.5 \
    --slice-height 640 \
    --slice-width 640
```

### 5. ä»…æ¨ç†ä¸ä¿å­˜å¯è§†åŒ–

```bash
python balloon_inference_with_sahi.py \
    --model best.pt \
    --source test_images/ \
    --no-visualize
```

## å‚æ•°è¯´æ˜

### å¿…éœ€å‚æ•°

| å‚æ•° | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| `--model` | è®­ç»ƒå¥½çš„æ¨¡å‹è·¯å¾„ | `best.pt` |
| `--source` | å›¾åƒè·¯å¾„æˆ–ç›®å½• | `test.jpg` æˆ– `test_images/` |

### åˆ‡ç‰‡å‚æ•°

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ | å»ºè®® |
|------|------|--------|------|
| `--slice-height` | åˆ‡ç‰‡é«˜åº¦ | 640 | ä¸è®­ç»ƒåˆ‡ç‰‡å¤§å°ä¸€è‡´ |
| `--slice-width` | åˆ‡ç‰‡å®½åº¦ | 640 | ä¸è®­ç»ƒåˆ‡ç‰‡å¤§å°ä¸€è‡´ |
| `--overlap-height` | é«˜åº¦é‡å æ¯”ä¾‹ | 0.2 | 0.1-0.3ï¼Œæ›´å¤§å¯å‡å°‘è¾¹ç•Œæ¼æ£€ |
| `--overlap-width` | å®½åº¦é‡å æ¯”ä¾‹ | 0.2 | 0.1-0.3 |

### æ¨¡å‹å‚æ•°

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| `--confidence` | ç½®ä¿¡åº¦é˜ˆå€¼ | 0.25 |
| `--device` | è®¾å¤‡ | cuda:0 |

### è¾“å‡ºå‚æ•°

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| `--save-dir` | ç»“æœä¿å­˜ç›®å½• | runs/sahi_inference |
| `--no-visualize` | ä¸ä¿å­˜å¯è§†åŒ–ç»“æœ | False |

## åˆ‡ç‰‡å‚æ•°é€‰æ‹©æŒ‡å—

### æ ¹æ®è®­ç»ƒé…ç½®é€‰æ‹©

**å•å°ºåº¦è®­ç»ƒï¼ˆrate=1.0ï¼‰**:
```bash
# è®­ç»ƒæ—¶åˆ‡ç‰‡: crop_size=640, gap=100
# æ¨ç†æ—¶å»ºè®®:
--slice-height 640 --slice-width 640
--overlap-height 0.15 --overlap-width 0.15
```

**å¤šå°ºåº¦è®­ç»ƒï¼ˆrates=[0.5, 1.0, 1.5]ï¼‰**:
```bash
# è®­ç»ƒåŒ…å«å¤šä¸ªå°ºåº¦ï¼Œæ¨ç†æ—¶ä½¿ç”¨æ ‡å‡†å°ºåº¦
--slice-height 640 --slice-width 640
--overlap-height 0.2 --overlap-width 0.2
```

### æ ¹æ®å›¾åƒç‰¹ç‚¹é€‰æ‹©

**å¯†é›†å°ç›®æ ‡**:
```bash
# æ›´å°çš„åˆ‡ç‰‡ï¼Œæ›´å¤§çš„é‡å 
--slice-height 512 --slice-width 512
--overlap-height 0.3 --overlap-width 0.3
```

**ç¨€ç–å¤§ç›®æ ‡**:
```bash
# æ›´å¤§çš„åˆ‡ç‰‡ï¼Œè¾ƒå°çš„é‡å 
--slice-height 800 --slice-width 800
--overlap-height 0.1 --overlap-width 0.1
```

## Python API ä½¿ç”¨

### åŸºç¡€ç”¨æ³•

```python
from balloon_inference_with_sahi import BalloonSAHIInference

# åˆå§‹åŒ–æ¨ç†å™¨
inferencer = BalloonSAHIInference(
    model_path="runs/detect/balloon_yolo11n_slice/weights/best.pt",
    confidence_threshold=0.25,
    device="cuda:0"
)

# æ¨ç†å•å¼ å›¾åƒ
result = inferencer.predict_image(
    image_path="test.jpg",
    slice_height=640,
    slice_width=640,
    overlap_height_ratio=0.2,
    overlap_width_ratio=0.2,
    save_dir="results",
    visualize=True
)

print(f"æ£€æµ‹åˆ° {result['num_detections']} ä¸ªç›®æ ‡")
```

### æ‰¹é‡æ¨ç†

```python
# æ¨ç†æ•´ä¸ªç›®å½•
results = inferencer.predict_directory(
    image_dir="test_images/",
    slice_height=640,
    slice_width=640,
    save_dir="results",
    visualize=True
)

# ç»Ÿè®¡ç»“æœ
for r in results:
    print(f"{r['image_path']}: {r['num_detections']} ä¸ªç›®æ ‡")
```

### è·å–æ£€æµ‹æ¡†è¯¦æƒ…

```python
result = inferencer.predict_image("test.jpg")

# è®¿é—®æ£€æµ‹ç»“æœ
for detection in result['detections']:
    bbox = detection.bbox  # [x_min, y_min, x_max, y_max]
    score = detection.score.value
    category = detection.category.name
    
    print(f"ç±»åˆ«: {category}, ç½®ä¿¡åº¦: {score:.2f}, ä½ç½®: {bbox}")
```

## è¾“å‡ºæ–‡ä»¶

æ¨ç†å®Œæˆåï¼Œåœ¨ `save_dir` ç›®å½•ä¸‹ä¼šç”Ÿæˆï¼š

```
runs/sahi_inference/
â”œâ”€â”€ image1_visual.png          # å¯è§†åŒ–ç»“æœï¼ˆå¸¦æ£€æµ‹æ¡†ï¼‰
â”œâ”€â”€ image2_visual.png
â””â”€â”€ ...
```

## é«˜çº§ç”¨æ³•ï¼šç›´æ¥ä½¿ç”¨ SAHI

å¦‚æœä½ æƒ³å®Œå…¨è‡ªå®šä¹‰ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ SAHI APIï¼š

```python
from sahi import AutoDetectionModel
from sahi.predict import get_sliced_prediction

# åŠ è½½æ¨¡å‹
detection_model = AutoDetectionModel.from_pretrained(
    model_type="ultralytics",
    model_path="best.pt",
    confidence_threshold=0.25,
    device="cuda:0"
)

# æ¨ç†
result = get_sliced_prediction(
    "test.jpg",
    detection_model,
    slice_height=640,
    slice_width=640,
    overlap_height_ratio=0.2,
    overlap_width_ratio=0.2,
)

# å¯¼å‡ºç»“æœ
result.export_visuals(export_dir="results/")

# è½¬æ¢ä¸ºCOCOæ ¼å¼
coco_dict = result.to_coco_annotations()

# è½¬æ¢ä¸ºYOLOæ ¼å¼  
result.export_visuals(export_dir="results/", text_size=1, rect_th=2)
```

## å®Œæ•´è®­ç»ƒ+æ¨ç†æµç¨‹

### æ­¥éª¤ 1: è®­ç»ƒæ¨¡å‹

```bash
# å•å°ºåº¦åˆ‡ç‰‡è®­ç»ƒ
python balloon_training_with_slice.py \
    --epochs 100 \
    --crop-size 640 \
    --gap 100

# æˆ–å¤šå°ºåº¦åˆ‡ç‰‡è®­ç»ƒ
python balloon_training_with_multi_slice.py \
    --epochs 100 \
    --crop-size 640 \
    --gap 100 \
    --rates 0.5 1.0 1.5
```

### æ­¥éª¤ 2: SAHI æ¨ç†

```bash
# ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹æ¨ç†
python balloon_inference_with_sahi.py \
    --model runs/detect/balloon_yolo11n_slice/weights/best.pt \
    --source test_images/ \
    --slice-height 640 \
    --slice-width 640
```

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. åˆ‡ç‰‡å¤§å°é€‰æ‹©
- âœ… **æ¨è**: ä¸è®­ç»ƒæ—¶çš„åˆ‡ç‰‡å¤§å°ä¸€è‡´
- âš ï¸ **è¿‡å°**: å¢åŠ æ¨ç†æ—¶é—´ï¼Œå¯èƒ½æ¼æ£€è¾¹ç•Œç›®æ ‡
- âš ï¸ **è¿‡å¤§**: å†…å­˜å ç”¨é«˜ï¼Œå°ç›®æ ‡æ£€æµ‹æ•ˆæœå·®

### 2. é‡å æ¯”ä¾‹é€‰æ‹©
- ğŸ“ˆ **0.1-0.15**: å¿«é€Ÿæ¨ç†ï¼Œé€‚åˆç¨€ç–ç›®æ ‡
- ğŸ“Š **0.2-0.25**: å¹³è¡¡æ¨èï¼Œé€‚åˆå¤§å¤šæ•°åœºæ™¯
- ğŸ“‰ **0.3-0.4**: é«˜è´¨é‡ï¼Œé€‚åˆå¯†é›†å°ç›®æ ‡

### 3. æ‰¹å¤„ç†å»ºè®®
```python
# å¯¹äºå¤§é‡å›¾åƒï¼Œå»ºè®®æ‰¹é‡å¤„ç†
results = inferencer.predict_directory(
    image_dir="large_dataset/",
    slice_height=640,
    slice_width=640,
)
```

## æ•…éšœæ’æŸ¥

### é—®é¢˜ 1: æ‰¾ä¸åˆ° SAHI æ¨¡å—

```bash
pip install sahi
```

### é—®é¢˜ 2: CUDA å†…å­˜ä¸è¶³

```bash
# ä½¿ç”¨ CPU æ¨ç†
python balloon_inference_with_sahi.py \
    --model best.pt \
    --source test.jpg \
    --device cpu
```

### é—®é¢˜ 3: æ£€æµ‹ç»“æœé‡å¤

```python
# SAHI å·²è‡ªåŠ¨å¤„ç† NMSï¼Œå¦‚æœä»æœ‰é‡å¤ï¼š
# 1. å‡å°é‡å æ¯”ä¾‹
--overlap-height 0.1 --overlap-width 0.1

# 2. æé«˜ç½®ä¿¡åº¦é˜ˆå€¼
--confidence 0.4
```

### é—®é¢˜ 4: è¾¹ç•Œç›®æ ‡æ¼æ£€

```python
# å¢åŠ é‡å æ¯”ä¾‹
--overlap-height 0.3 --overlap-width 0.3
```

## ä¸ DOTA æ¨ç†å¯¹æ¯”

| ç‰¹æ€§ | DOTA (æ‰‹åŠ¨) | Balloon (SAHI) |
|------|------------|----------------|
| åˆ‡ç‰‡æ–¹å¼ | æ‰‹åŠ¨å®ç° | SAHI è‡ªåŠ¨ âœ… |
| NMS åˆå¹¶ | éœ€è¦è‡ªå·±å†™ | SAHI è‡ªåŠ¨ âœ… |
| è¾¹ç•Œå¤„ç† | å¤æ‚ | SAHI è‡ªåŠ¨ âœ… |
| æ ¼å¼æ”¯æŒ | OBB | æ°´å¹³æ¡†/OBB âœ… |
| ä»£ç é‡ | 200+ è¡Œ | 10 è¡Œ âœ… |

## å‚è€ƒèµ„æº

- ğŸ“– [SAHI å®˜æ–¹æ–‡æ¡£](https://github.com/obss/sahi)
- ğŸ“– [Ultralytics SAHI é›†æˆæŒ‡å—](docs/en/guides/sahi-tiled-inference.md)
- ğŸ’» [å®˜æ–¹ç¤ºä¾‹ä»£ç ](examples/YOLOv8-SAHI-Inference-Video/)
- ğŸ“ [Colab æ•™ç¨‹](https://colab.research.google.com/github/ultralytics/notebooks/blob/main/notebooks/how-to-use-ultralytics-yolo-with-sahi.ipynb)

## æ€»ç»“

âœ… **SAHI å®Œå…¨å¯ä»¥ç”¨äº COCO æ ¼å¼æ•°æ®**  
âœ… **è‡ªåŠ¨å¤„ç†åˆ‡ç‰‡ã€æ¨ç†ã€åˆå¹¶å…¨æµç¨‹**  
âœ… **æ¯”æ‰‹åŠ¨å®ç°ç®€å• 10 å€ä»¥ä¸Š**  
âœ… **å®˜æ–¹æ”¯æŒï¼Œç¨³å®šå¯é **

å¼€å§‹ä½¿ç”¨å§ï¼ğŸš€

