================================================================================
D1 数据集综合测试脚本使用说明
================================================================================

📝 脚本文件: D1_comprehensive_test.sh

🎯 功能说明:
  - 整合三种推理方式，用于新数据集的验收测试
  - 自动生成检测图片和标签文件
  - 统计每张图片的检测数量
  - 生成详细的统计报告

================================================================================
三种推理方式
================================================================================

1️⃣  常规推理 (Normal Inference)
   - 使用常规训练的模型
   - 适合标准尺寸图像
   - 速度最快

2️⃣  SAHI切片推理 (SAHI Sliced Inference)
   - 使用切片数据训练的模型
   - 对大图进行切片推理后拼接
   - 支持跨标签NMS，避免重复检测
   - 适合小目标检测

3️⃣  多尺度推理 (Multi-Scale Inference)
   - 在多个尺度上进行推理并融合
   - 支持跨标签NMS
   - 检测效果最好，但速度较慢

================================================================================
使用步骤
================================================================================

步骤1: 修改配置参数
-----------------
打开 D1_comprehensive_test.sh 文件，修改以下配置：

# 1. 新数据集路径（必须修改）
NEW_DATA_DIR="/path/to/new/test/images"

# 2. 总保存路径（可选）
OUTPUT_ROOT="runs/comprehensive_test"

# 3. 模型路径（根据实际情况修改）
NORMAL_MODEL="runs/detect/D1_yolo11l_20241211/weights/best.pt"
SLICE_MODEL="runs/detect/D1_yolo11l_slice_20241211/weights/best.pt"
MULTISCALE_MODEL="runs/detect/D1_yolo11l_20241211/weights/best.pt"

# 4. 其他参数（可选）
DEVICE=0                 # GPU设备号
CONFIDENCE=0.3           # 置信度阈值
IOU_THRESHOLD=0.5        # IoU阈值

步骤2: 运行测试
-----------------
bash D1_comprehensive_test.sh

步骤3: 查看结果
-----------------
测试完成后，会在 OUTPUT_ROOT 目录下生成三个子目录：

runs/comprehensive_test/
├── 01_normal_inference_YYYYMMDD_HHMMSS/
│   ├── *_visual.jpg              # 可视化图片
│   ├── labels/*.txt               # YOLO格式标签
│   └── detection_stats.txt        # 检测统计
├── 02_sahi_inference_YYYYMMDD_HHMMSS/
│   ├── *_visual.jpg
│   ├── labels/*.txt
│   └── detection_stats.txt
└── 03_multiscale_inference_YYYYMMDD_HHMMSS/
    ├── *_multiscale.jpg
    ├── labels/*.txt
    └── detection_stats.txt

================================================================================
查看统计结果
================================================================================

方法1: 查看所有统计文件
-----------------------
cat runs/comprehensive_test/*/detection_stats.txt

方法2: 查看单个方法的统计
-----------------------
cat runs/comprehensive_test/01_normal_inference_*/detection_stats.txt
cat runs/comprehensive_test/02_sahi_inference_*/detection_stats.txt
cat runs/comprehensive_test/03_multiscale_inference_*/detection_stats.txt

方法3: 查看可视化图片
-----------------------
# 使用图片查看器打开对应目录下的图片

================================================================================
输出示例
================================================================================

detection_stats.txt 文件内容示例：

=== 常规推理 检测统计 ===
生成时间: 2024-12-11 15:30:00

  image001.txt: 15 个目标
  image002.txt: 23 个目标
  image003.txt: 8 个目标
  ...

=== 总结 ===
图像总数: 50
检测总数: 850
平均每张: 17.00 个目标

================================================================================
高级配置
================================================================================

1. SAHI推理参数调整
-----------------------
SLICE_HEIGHT=640          # 切片高度
SLICE_WIDTH=640           # 切片宽度
OVERLAP_RATIO=0.15        # 重叠比例
MIN_BOX_AREA=200          # 最小检测框面积
MAX_DETECTIONS=50         # 最大检测数量

2. 多尺度推理参数调整
-----------------------
SCALES="640 832 1024 1280"    # 推理尺度列表
FUSION_METHOD="nms"           # 融合方法 (nms 或 wbf)

3. 跨标签NMS
-----------------------
默认启用跨标签NMS，避免同一个目标被多个类别重复检测。
如需禁用，需要修改对应的Python脚本调用参数。

================================================================================
常见问题
================================================================================

Q1: 模型文件不存在怎么办？
A1: 检查模型路径是否正确，确保模型已训练完成。

Q2: 新数据集目录找不到？
A2: 确保 NEW_DATA_DIR 路径正确，且包含图像文件。

Q3: 显存不足怎么办？
A3: 可以调整以下参数：
    - 减少多尺度的尺度数量
    - 减小SAHI的切片尺寸
    - 减小批处理大小

Q4: 如何只运行某一种推理方式？
A4: 可以注释掉不需要的部分，或将对应模型路径设为不存在的文件。

Q5: 如何比较三种方法的效果？
A5: 查看各自的 detection_stats.txt 文件，比较：
    - 检测总数
    - 平均每张图片的检测数
    - 可视化效果

================================================================================
技术支持
================================================================================

如有问题，请检查：
1. 模型文件路径是否正确
2. 数据集路径是否正确
3. Python依赖是否安装完整
4. GPU显存是否充足

相关脚本：
- balloon_inference.py         # 常规推理
- D1_inference_with_sahi_v3.py # SAHI切片推理
- balloon_inference_multiscale.py # 多尺度推理

================================================================================

