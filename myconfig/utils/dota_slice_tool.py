#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
DOTA æ•°æ®åˆ‡ç‰‡å·¥å…·
åŸºäº ultralytics å†…ç½®çš„æ•°æ®åˆ‡ç‰‡åŠŸèƒ½ï¼Œæä¾›ç®€å•æ˜“ç”¨çš„æ¥å£
æ”¯æŒå¤šå°ºåº¦åˆ‡ç‰‡ã€è‡ªå®šä¹‰çª—å£å¤§å°ã€é‡å åº¦ç­‰å‚æ•°
"""

import argparse
import sys
from pathlib import Path
from typing import Tuple

from ultralytics.data.split_dota import split_trainval, split_test
from ultralytics.utils import LOGGER


def setup_logger():
    """è®¾ç½®æ—¥å¿—è¾“å‡ºæ ¼å¼"""
    import logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(sys.stdout),
        ]
    )


def check_data_structure(data_root: Path) -> bool:
    """
    æ£€æŸ¥ DOTA æ•°æ®é›†çš„ç›®å½•ç»“æ„æ˜¯å¦æ­£ç¡®
    
    Args:
        data_root (Path): æ•°æ®æ ¹ç›®å½•
    
    Returns:
        bool: ç»“æ„æ˜¯å¦æ­£ç¡®
    """
    required_dirs = [
        "images/train",
        "images/val", 
        "labels/train",
        "labels/val"
    ]
    
    missing_dirs = []
    for dir_path in required_dirs:
        full_path = data_root / dir_path
        if not full_path.exists():
            missing_dirs.append(str(full_path))
    
    if missing_dirs:
        LOGGER.error(f"ç¼ºå°‘ä»¥ä¸‹ç›®å½•:")
        for missing_dir in missing_dirs:
            LOGGER.error(f"  - {missing_dir}")
        LOGGER.error(f"æœŸæœ›çš„ç›®å½•ç»“æ„:")
        LOGGER.error(f"  {data_root}/")
        LOGGER.error(f"  â”œâ”€â”€ images/")
        LOGGER.error(f"  â”‚   â”œâ”€â”€ train/")
        LOGGER.error(f"  â”‚   â””â”€â”€ val/")
        LOGGER.error(f"  â””â”€â”€ labels/")
        LOGGER.error(f"      â”œâ”€â”€ train/")
        LOGGER.error(f"      â””â”€â”€ val/")
        return False
    
    return True


def get_dataset_info(data_root: Path) -> dict:
    """
    è·å–æ•°æ®é›†åŸºæœ¬ä¿¡æ¯
    
    Args:
        data_root (Path): æ•°æ®æ ¹ç›®å½•
    
    Returns:
        dict: æ•°æ®é›†ä¿¡æ¯
    """
    info = {}
    for split in ["train", "val"]:
        img_dir = data_root / "images" / split
        lbl_dir = data_root / "labels" / split
        
        img_files = list(img_dir.glob("*.*")) if img_dir.exists() else []
        lbl_files = list(lbl_dir.glob("*.txt")) if lbl_dir.exists() else []
        
        info[split] = {
            "images": len(img_files),
            "labels": len(lbl_files)
        }
    
    return info


def slice_dota_dataset(
    data_root: str,
    save_dir: str,
    crop_size: int = 1024,
    gap: int = 200,
    rates: Tuple[float, ...] = (1.0,),
    include_test: bool = False
):
    """
    åˆ‡ç‰‡ DOTA æ•°æ®é›†
    
    Args:
        data_root (str): åŸå§‹æ•°æ®æ ¹ç›®å½•
        save_dir (str): ä¿å­˜åˆ‡ç‰‡åæ•°æ®çš„ç›®å½•
        crop_size (int): åŸºç¡€è£å‰ªå°ºå¯¸
        gap (int): çª—å£é—´é‡å å¤§å°
        rates (Tuple[float, ...]): å¤šå°ºåº¦ç¼©æ”¾æ¯”ä¾‹
        include_test (bool): æ˜¯å¦åŒ…å«æµ‹è¯•é›†
    """
    data_root = Path(data_root)
    save_dir = Path(save_dir)
    
    LOGGER.info("ğŸš€ å¼€å§‹ DOTA æ•°æ®é›†åˆ‡ç‰‡å¤„ç†")
    LOGGER.info(f"åŸå§‹æ•°æ®è·¯å¾„: {data_root}")
    LOGGER.info(f"è¾“å‡ºè·¯å¾„: {save_dir}")
    LOGGER.info(f"åˆ‡ç‰‡å‚æ•°:")
    LOGGER.info(f"  - åŸºç¡€è£å‰ªå°ºå¯¸: {crop_size}x{crop_size}")
    LOGGER.info(f"  - é‡å å¤§å°: {gap}")
    LOGGER.info(f"  - å¤šå°ºåº¦æ¯”ä¾‹: {rates}")
    
    # æ£€æŸ¥æ•°æ®ç»“æ„
    if not check_data_structure(data_root):
        return False
    
    # è·å–æ•°æ®é›†ä¿¡æ¯
    dataset_info = get_dataset_info(data_root)
    LOGGER.info(f"æ•°æ®é›†ä¿¡æ¯:")
    for split, info in dataset_info.items():
        LOGGER.info(f"  - {split}: {info['images']} å›¾åƒ, {info['labels']} æ ‡ç­¾")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    save_dir.mkdir(parents=True, exist_ok=True)
    
    try:
        # åˆ‡ç‰‡è®­ç»ƒå’ŒéªŒè¯é›†
        LOGGER.info("ğŸ“¸ å¼€å§‹åˆ‡ç‰‡è®­ç»ƒå’ŒéªŒè¯é›†...")
        split_trainval(
            data_root=str(data_root),
            save_dir=str(save_dir),
            crop_size=crop_size,
            gap=gap,
            rates=rates
        )
        LOGGER.info("âœ… è®­ç»ƒå’ŒéªŒè¯é›†åˆ‡ç‰‡å®Œæˆ")
        
        # å¦‚æœéœ€è¦ï¼Œåˆ‡ç‰‡æµ‹è¯•é›†
        if include_test:
            test_dir = data_root / "images" / "test"
            if test_dir.exists():
                LOGGER.info("ğŸ“¸ å¼€å§‹åˆ‡ç‰‡æµ‹è¯•é›†...")
                split_test(
                    data_root=str(data_root),
                    save_dir=str(save_dir),
                    crop_size=crop_size,
                    gap=gap,
                    rates=rates
                )
                LOGGER.info("âœ… æµ‹è¯•é›†åˆ‡ç‰‡å®Œæˆ")
            else:
                LOGGER.warning(f"æœªæ‰¾åˆ°æµ‹è¯•é›†ç›®å½•: {test_dir}")
        
        # è·å–åˆ‡ç‰‡åçš„æ•°æ®é›†ä¿¡æ¯
        LOGGER.info("ğŸ“Š åˆ‡ç‰‡åæ•°æ®é›†ç»Ÿè®¡:")
        sliced_info = get_dataset_info(save_dir)
        for split, info in sliced_info.items():
            LOGGER.info(f"  - {split}: {info['images']} å›¾åƒ, {info['labels']} æ ‡ç­¾")
        
        LOGGER.info(f"ğŸ‰ æ•°æ®åˆ‡ç‰‡å®Œæˆï¼è¾“å‡ºè·¯å¾„: {save_dir}")
        return True
        
    except Exception as e:
        LOGGER.error(f"âŒ åˆ‡ç‰‡è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="DOTA æ•°æ®é›†åˆ‡ç‰‡å·¥å…·")
    
    parser.add_argument(
        "--data-root",
        type=str,
        required=True,
        help="åŸå§‹ DOTA æ•°æ®é›†æ ¹ç›®å½•"
    )
    
    parser.add_argument(
        "--save-dir",
        type=str,
        required=True,
        help="ä¿å­˜åˆ‡ç‰‡åæ•°æ®çš„ç›®å½•"
    )
    
    parser.add_argument(
        "--crop-size",
        type=int,
        default=1024,
        help="åŸºç¡€è£å‰ªå°ºå¯¸ (é»˜è®¤: 1024)"
    )
    
    parser.add_argument(
        "--gap",
        type=int,
        default=200,
        help="çª—å£é—´é‡å å¤§å° (é»˜è®¤: 200)"
    )
    
    parser.add_argument(
        "--rates",
        nargs="+",
        type=float,
        default=[1.0],
        help="å¤šå°ºåº¦ç¼©æ”¾æ¯”ä¾‹ (é»˜è®¤: [1.0])"
    )
    
    parser.add_argument(
        "--include-test",
        action="store_true",
        help="æ˜¯å¦åŒ…å«æµ‹è¯•é›†åˆ‡ç‰‡"
    )
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—
    setup_logger()
    
    # æ‰§è¡Œåˆ‡ç‰‡
    success = slice_dota_dataset(
        data_root=args.data_root,
        save_dir=args.save_dir,
        crop_size=args.crop_size,
        gap=args.gap,
        rates=tuple(args.rates),
        include_test=args.include_test
    )
    
    if success:
        print("\n" + "="*50)
        print("ğŸ¯ æ¥ä¸‹æ¥å¯ä»¥ä½¿ç”¨åˆ‡ç‰‡åçš„æ•°æ®è¿›è¡Œè®­ç»ƒ:")
        print(f"python -m ultralytics.models.yolo.obb.train data={args.save_dir}")
        print("="*50)
    else:
        sys.exit(1)


if __name__ == "__main__":
    main()
