#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤šå°ºåº¦æ£€æµ‹ç»“æœå¯è§†åŒ–è„šæœ¬
å°†ground truthã€æ¯ä¸ªå°ºåº¦çš„æ£€æµ‹ç»“æœã€æœ€ç»ˆåˆå¹¶æ•ˆæœæ‹¼æ¥åˆ°ä¸€å¼ å›¾ä¸Š

ä½¿ç”¨æ–¹æ³•:
python visualize_multiscale_results.py \
    --model best.pt \
    --image /path/to/image.jpg \
    --label /path/to/label.txt \
    --scales 640 832 1024 1280 \
    --save-dir runs/multiscale_visible
"""

import argparse
import os
from pathlib import Path
from typing import List, Tuple, Optional
import math

import cv2
import numpy as np
import torch
from ultralytics import YOLO
from ultralytics.utils import LOGGER


def cross_class_nms(boxes_list, iou_threshold=0.5):
    """
    è·¨ç±»åˆ«NMSï¼šå¯¹æ‰€æœ‰ç±»åˆ«çš„æ£€æµ‹æ¡†è¿›è¡ŒNMSï¼Œå»é™¤é‡å¤æ£€æµ‹
    ç”¨äºè§£å†³å¤šå°ºåº¦èåˆæ—¶åŒä¸€ä¸ªç›®æ ‡è¢«å¤šä¸ªç±»åˆ«æ£€æµ‹çš„é—®é¢˜
    
    Args:
        boxes_list: æ£€æµ‹æ¡†åˆ—è¡¨ [(cls, conf, x1, y1, x2, y2), ...]
        iou_threshold: IoUé˜ˆå€¼
    
    Returns:
        è¿‡æ»¤åçš„æ£€æµ‹æ¡†åˆ—è¡¨
    """
    if len(boxes_list) == 0:
        return []
    
    # æå–æ‰€æœ‰æ£€æµ‹æ¡†å’Œç½®ä¿¡åº¦
    boxes = np.array([[b[2], b[3], b[4], b[5]] for b in boxes_list])  # x1,y1,x2,y2
    scores = np.array([b[1] for b in boxes_list])  # ç½®ä¿¡åº¦
    
    # è®¡ç®—é¢ç§¯
    x1 = boxes[:, 0]
    y1 = boxes[:, 1]
    x2 = boxes[:, 2]
    y2 = boxes[:, 3]
    areas = (x2 - x1) * (y2 - y1)
    
    # æŒ‰ç½®ä¿¡åº¦æ’åº
    order = scores.argsort()[::-1]
    
    keep = []
    while order.size > 0:
        i = order[0]
        keep.append(i)
        
        if order.size == 1:
            break
        
        # è®¡ç®—IoU
        xx1 = np.maximum(x1[i], x1[order[1:]])
        yy1 = np.maximum(y1[i], y1[order[1:]])
        xx2 = np.minimum(x2[i], x2[order[1:]])
        yy2 = np.minimum(y2[i], y2[order[1:]])
        
        w = np.maximum(0.0, xx2 - xx1)
        h = np.maximum(0.0, yy2 - yy1)
        inter = w * h
        
        iou = inter / (areas[i] + areas[order[1:]] - inter)
        
        # ä¿ç•™IoUå°äºé˜ˆå€¼çš„æ¡†
        inds = np.where(iou <= iou_threshold)[0]
        order = order[inds + 1]
    
    # è¿”å›ä¿ç•™çš„æ£€æµ‹æ¡†
    return [boxes_list[i] for i in keep]


def parse_yolo_label(label_path: str, img_width: int, img_height: int) -> List[Tuple[int, float, float, float, float]]:
    """
    è§£æYOLOæ ¼å¼æ ‡ç­¾æ–‡ä»¶
    
    Args:
        label_path: æ ‡ç­¾æ–‡ä»¶è·¯å¾„
        img_width: å›¾åƒå®½åº¦
        img_height: å›¾åƒé«˜åº¦
    
    Returns:
        [(class_id, x1, y1, x2, y2), ...]
    """
    boxes = []
    if not os.path.exists(label_path):
        LOGGER.warning(f"   âš ï¸ æ ‡ç­¾æ–‡ä»¶ä¸å­˜åœ¨: {label_path}")
        return boxes
    
    with open(label_path, 'r') as f:
        lines = f.readlines()
        if len(lines) == 0:
            LOGGER.warning(f"   âš ï¸ æ ‡ç­¾æ–‡ä»¶ä¸ºç©º: {label_path}")
            return boxes
        
        for line_num, line in enumerate(lines, 1):
            line = line.strip()
            if not line:  # è·³è¿‡ç©ºè¡Œ
                continue
                
            parts = line.split()
            if len(parts) < 5:
                LOGGER.warning(f"   âš ï¸ æ ‡ç­¾æ ¼å¼é”™è¯¯ (è¡Œ{line_num}): {line} - éœ€è¦è‡³å°‘5ä¸ªå€¼")
                continue
            
            try:
                cls = int(parts[0])
                x_center = float(parts[1]) * img_width
                y_center = float(parts[2]) * img_height
                width = float(parts[3]) * img_width
                height = float(parts[4]) * img_height
                
                # æ£€æŸ¥åæ ‡æ˜¯å¦åˆç†ï¼ˆå½’ä¸€åŒ–å€¼åº”è¯¥åœ¨0-1ä¹‹é—´ï¼‰
                if not (0 <= float(parts[1]) <= 1 and 0 <= float(parts[2]) <= 1 and 
                       0 <= float(parts[3]) <= 1 and 0 <= float(parts[4]) <= 1):
                    LOGGER.warning(f"   âš ï¸ åæ ‡å€¼è¶…å‡ºèŒƒå›´ (è¡Œ{line_num}): {line} - YOLOæ ¼å¼åº”è¯¥æ˜¯å½’ä¸€åŒ–åæ ‡(0-1)")
                
                x1 = x_center - width / 2
                y1 = y_center - height / 2
                x2 = x_center + width / 2
                y2 = y_center + height / 2
                
                boxes.append((cls, x1, y1, x2, y2))
            except ValueError as e:
                LOGGER.warning(f"   âš ï¸ è§£æé”™è¯¯ (è¡Œ{line_num}): {line} - {e}")
                continue
    
    if len(boxes) > 0:
        LOGGER.info(f"   âœ… æˆåŠŸè§£ææ ‡ç­¾: {label_path} ({len(boxes)} ä¸ªç›®æ ‡)")
    
    return boxes


def draw_boxes(image: np.ndarray, boxes: List, color: Tuple[int, int, int] = None, 
               label: str = "", thickness: int = 2, show_class: bool = True,
               class_names: dict = None, show_conf: bool = True) -> np.ndarray:
    """
    åœ¨å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹æ¡†ï¼ˆæŒ‰ç±»åˆ«ç”¨ä¸åŒé¢œè‰²ï¼Œæ˜¾ç¤ºç±»åˆ«å’Œç½®ä¿¡åº¦ï¼‰
    
    Args:
        image: è¾“å…¥å›¾åƒ
        boxes: æ£€æµ‹æ¡†åˆ—è¡¨ [(cls, conf, x1, y1, x2, y2), ...] æˆ– [(cls, x1, y1, x2, y2), ...] (GT)
        color: ç»Ÿä¸€é¢œè‰² (å¦‚æœä¸ºNoneåˆ™æŒ‰ç±»åˆ«è‡ªåŠ¨åˆ†é…)
        label: æ ‡ç­¾æ–‡å­—
        thickness: çº¿å®½
        show_class: æ˜¯å¦æ˜¾ç¤ºç±»åˆ«æ ‡ç­¾
        class_names: ç±»åˆ«åç§°å­—å…¸ {0: 'class0', 1: 'class1', ...}
        show_conf: æ˜¯å¦æ˜¾ç¤ºç½®ä¿¡åº¦
    
    Returns:
        ç»˜åˆ¶åçš„å›¾åƒ
    """
    img = image.copy()
    
    # ç±»åˆ«é¢œè‰²æ˜ å°„ï¼ˆæ”¯æŒå¤šç±»åˆ«ï¼‰
    class_colors = {
        0: (0, 255, 0),      # ç»¿è‰² - class 0
        1: (255, 0, 0),      # è“è‰² - class 1
        2: (0, 0, 255),      # çº¢è‰² - class 2
        3: (255, 255, 0),    # é’è‰² - class 3
        4: (255, 0, 255),    # ç´«è‰² - class 4
        5: (0, 255, 255),    # é»„è‰² - class 5
    }
    
    # é»˜è®¤ç±»åˆ«åç§°
    if class_names is None:
        class_names = {0: 'hole', 1: 'cave', 2: 'unknow'}
    
    if len(boxes) == 0:
        LOGGER.debug(f"   draw_boxes: æ²¡æœ‰æ¡†éœ€è¦ç»˜åˆ¶")
    
    for box in boxes:
        if len(box) >= 5:
            # åˆ¤æ–­æ˜¯å¦åŒ…å«ç½®ä¿¡åº¦: (cls, conf, x1, y1, x2, y2) æˆ– (cls, x1, y1, x2, y2)
            if len(box) >= 6:
                cls, conf, x1, y1, x2, y2 = box[:6]
                conf = float(conf)
            else:
                cls, x1, y1, x2, y2 = box[:5]
                conf = None
            
            cls = int(cls)
            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)
            
            # é€‰æ‹©é¢œè‰²ï¼šå¦‚æœæŒ‡å®šäº†coloråˆ™ç”¨ç»Ÿä¸€é¢œè‰²ï¼Œå¦åˆ™æŒ‰ç±»åˆ«åˆ†é…
            box_color = color if color is not None else class_colors.get(cls, (128, 128, 128))
            
            # ç»˜åˆ¶çŸ©å½¢
            cv2.rectangle(img, (x1, y1), (x2, y2), box_color, thickness)
            
            # ç»˜åˆ¶ç±»åˆ«å’Œç½®ä¿¡åº¦æ ‡ç­¾
            if show_class or (show_conf and conf is not None):
                class_name = class_names.get(cls, f'cls{cls}')
                
                # ç»„åˆæ ‡ç­¾æ–‡å­—
                if conf is not None and show_conf:
                    label_text = f"{class_name} {conf:.2f}"
                else:
                    label_text = f"{class_name}"
                
                # è®¡ç®—æ ‡ç­¾èƒŒæ™¯å¤§å°
                (text_w, text_h), baseline = cv2.getTextSize(
                    label_text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1
                )
                
                # æ ‡ç­¾ä½ç½®
                label_y = max(y1 - 5, text_h + 5)
                
                # ç»˜åˆ¶æ ‡ç­¾èƒŒæ™¯
                cv2.rectangle(
                    img,
                    (x1, label_y - text_h - baseline),
                    (x1 + text_w, label_y),
                    box_color,
                    -1
                )
                
                # ç»˜åˆ¶æ ‡ç­¾æ–‡å­—ï¼ˆç™½è‰²ï¼‰
                cv2.putText(
                    img, label_text, (x1, label_y - baseline),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1
                )
    
    # æ·»åŠ å›¾ç‰‡æ ‡é¢˜
    if label:
        cv2.putText(img, f"{label} ({len(boxes)})", (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
    
    return img


def resize_with_padding(image: np.ndarray, target_size: int = 640) -> np.ndarray:
    """
    ç­‰æ¯”ä¾‹ç¼©æ”¾å›¾åƒå¹¶å¡«å……åˆ°ç›®æ ‡å°ºå¯¸
    
    Args:
        image: è¾“å…¥å›¾åƒ
        target_size: ç›®æ ‡å°ºå¯¸
    
    Returns:
        ç¼©æ”¾åçš„å›¾åƒ
    """
    h, w = image.shape[:2]
    scale = min(target_size / w, target_size / h)
    
    new_w = int(w * scale)
    new_h = int(h * scale)
    
    resized = cv2.resize(image, (new_w, new_h))
    
    # åˆ›å»ºç›®æ ‡å¤§å°çš„ç”»å¸ƒ
    canvas = np.zeros((target_size, target_size, 3), dtype=np.uint8)
    
    # å±…ä¸­æ”¾ç½®
    x_offset = (target_size - new_w) // 2
    y_offset = (target_size - new_h) // 2
    
    canvas[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = resized
    
    return canvas


def create_grid_image(images: List[np.ndarray], titles: List[str], 
                      cell_size: int = 640) -> np.ndarray:
    """
    å°†å¤šå¼ å›¾åƒæ‹¼æ¥æˆç½‘æ ¼
    
    Args:
        images: å›¾åƒåˆ—è¡¨
        titles: æ ‡é¢˜åˆ—è¡¨
        cell_size: æ¯ä¸ªå•å…ƒæ ¼å¤§å°
    
    Returns:
        æ‹¼æ¥åçš„å›¾åƒ
    """
    n = len(images)
    if n == 0:
        return np.zeros((cell_size, cell_size, 3), dtype=np.uint8)
    
    # è®¡ç®—ç½‘æ ¼å¸ƒå±€
    cols = math.ceil(math.sqrt(n))
    rows = math.ceil(n / cols)
    
    # åˆ›å»ºå¤§ç”»å¸ƒ
    grid_w = cols * cell_size
    grid_h = rows * cell_size
    grid = np.zeros((grid_h, grid_w, 3), dtype=np.uint8)
    
    for i, (img, title) in enumerate(zip(images, titles)):
        row = i // cols
        col = i % cols
        
        # ç¼©æ”¾å›¾åƒ
        resized = resize_with_padding(img, cell_size)
        
        # æ·»åŠ æ ‡é¢˜
        cv2.putText(resized, title, (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        # æ”¾ç½®åˆ°ç½‘æ ¼ä¸­
        y1 = row * cell_size
        x1 = col * cell_size
        grid[y1:y1+cell_size, x1:x1+cell_size] = resized
    
    return grid


class MultiscaleVisualizer:
    """å¤šå°ºåº¦æ£€æµ‹å¯è§†åŒ–ç±»"""
    
    def __init__(self, model_path: str, device: str = "cuda:0"):
        """
        åˆå§‹åŒ–å¯è§†åŒ–å™¨
        
        Args:
            model_path: æ¨¡å‹è·¯å¾„
            device: è®¾å¤‡
        """
        self.model_path = Path(model_path)
        self.device = device
        self.model = None
        self.model_name = self.model_path.parent.parent.name  # è·å–æ¨¡å‹åç§°
        
        if not self.model_path.exists():
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
        
        LOGGER.info(f"ğŸ” åŠ è½½æ¨¡å‹: {self.model_path}")
        self.model = YOLO(str(self.model_path))
        
        # Warmup: åšä¸€æ¬¡ç©ºæ¨ç†å°†æ¨¡å‹ç§»åˆ°GPU
        dummy_img = np.zeros((640, 640, 3), dtype=np.uint8)
        self.model.predict(dummy_img, device=device, verbose=False)
        LOGGER.info(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ (å·²ç§»è‡³ {device})")
    
    def predict_single_scale(self, image: np.ndarray, scale: int, 
                            conf: float = 0.25, iou: float = 0.5) -> List:
        """
        å•å°ºåº¦æ¨ç†
        
        Args:
            image: è¾“å…¥å›¾åƒ
            scale: æ¨ç†å°ºåº¦
            conf: ç½®ä¿¡åº¦é˜ˆå€¼
            iou: NMS IoUé˜ˆå€¼
        
        Returns:
            æ£€æµ‹æ¡†åˆ—è¡¨ [(cls, x1, y1, x2, y2), ...]
        """
        results = self.model.predict(
            source=image,
            imgsz=scale,
            conf=conf,
            iou=iou,
            device=self.device,
            verbose=False,
            save=False,
        )
        
        result = results[0]
        boxes = []
        
        if len(result.boxes) > 0:
            xyxy = result.boxes.xyxy.cpu().numpy()
            cls = result.boxes.cls.cpu().numpy()
            conf = result.boxes.conf.cpu().numpy()  # è·å–ç½®ä¿¡åº¦
            
            for i in range(len(xyxy)):
                # æ ¼å¼: (cls, conf, x1, y1, x2, y2)
                boxes.append((int(cls[i]), float(conf[i]), xyxy[i][0], xyxy[i][1], xyxy[i][2], xyxy[i][3]))
        
        return boxes
    
    def nms_fusion(self, all_boxes: List[List], iou_threshold: float = 0.5, 
                   class_agnostic: bool = True) -> List:
        """
        NMSèåˆå¤šå°ºåº¦ç»“æœ
        
        Args:
            all_boxes: æ‰€æœ‰å°ºåº¦çš„æ£€æµ‹æ¡† [(cls, conf, x1, y1, x2, y2), ...]
            iou_threshold: IoUé˜ˆå€¼
            class_agnostic: æ˜¯å¦ä½¿ç”¨è·¨ç±»åˆ«NMSï¼ˆé»˜è®¤Trueï¼Œè§£å†³å¤šæ ‡ç­¾é‡å¤é—®é¢˜ï¼‰
        
        Returns:
            èåˆåçš„æ£€æµ‹æ¡† [(cls, conf, x1, y1, x2, y2), ...]
        """
        # åˆå¹¶æ‰€æœ‰æ¡†
        merged = []
        for boxes in all_boxes:
            merged.extend(boxes)
        
        if len(merged) == 0:
            return []
        
        LOGGER.info(f"   èåˆå‰: {len(merged)} ä¸ªæ£€æµ‹æ¡†")
        
        # ä½¿ç”¨è·¨ç±»åˆ«NMS
        if class_agnostic:
            result = cross_class_nms(merged, iou_threshold)
            LOGGER.info(f"   è·¨ç±»åˆ«NMS: {len(merged)} -> {len(result)}")
            return result
        else:
            # æŒ‰ç±»åˆ«NMSï¼ˆåŸå§‹æ–¹æ³•ï¼‰
            boxes_array = np.array([[b[2], b[3], b[4], b[5]] for b in merged])  # x1,y1,x2,y2
            scores = np.array([b[1] for b in merged])  # ä½¿ç”¨ç½®ä¿¡åº¦ä½œä¸ºscore
            classes = np.array([b[0] for b in merged])
            
            keep_indices = []
            for cls in np.unique(classes):
                cls_mask = classes == cls
                cls_boxes = torch.from_numpy(boxes_array[cls_mask]).float()
                cls_scores = torch.from_numpy(scores[cls_mask]).float()
                
                keep = torch.ops.torchvision.nms(cls_boxes, cls_scores, iou_threshold)
                cls_indices = np.where(cls_mask)[0]
                keep_indices.extend(cls_indices[keep.numpy()].tolist())
            
            result = [merged[i] for i in keep_indices]
            LOGGER.info(f"   æŒ‰ç±»åˆ«NMS: {len(merged)} -> {len(result)}")
            return result
    
    def visualize_image(
        self,
        image_path: str,
        label_path: str,
        scales: List[int],
        save_dir: str,
        conf: float = 0.25,
        iou: float = 0.5,
        cell_size: int = 640,
        class_agnostic_nms: bool = True,
    ) -> str:
        """
        å¯è§†åŒ–å•å¼ å›¾åƒçš„å¤šå°ºåº¦æ£€æµ‹ç»“æœ
        
        Args:
            image_path: å›¾åƒè·¯å¾„
            label_path: æ ‡ç­¾è·¯å¾„
            scales: å°ºåº¦åˆ—è¡¨
            save_dir: ä¿å­˜ç›®å½•
            conf: ç½®ä¿¡åº¦é˜ˆå€¼
            iou: NMS IoUé˜ˆå€¼
            cell_size: å•å…ƒæ ¼å¤§å°
            class_agnostic_nms: æ˜¯å¦ä½¿ç”¨è·¨ç±»åˆ«NMSï¼ˆé»˜è®¤Trueï¼Œè§£å†³å¤šæ ‡ç­¾é‡å¤é—®é¢˜ï¼‰
        
        Returns:
            ä¿å­˜è·¯å¾„
        """
        image_path = Path(image_path)
        label_path = Path(label_path)
        
        # è¯»å–å›¾åƒ
        image = cv2.imread(str(image_path))
        if image is None:
            raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ: {image_path}")
        
        h, w = image.shape[:2]
        LOGGER.info(f"ğŸ“¸ å¤„ç†å›¾åƒ: {image_path.name} ({w}x{h})")
        LOGGER.info(f"   å›¾åƒè·¯å¾„: {image_path}")
        LOGGER.info(f"   æ ‡ç­¾è·¯å¾„: {label_path}")
        
        # è§£æground truth
        gt_boxes = parse_yolo_label(str(label_path), w, h)
        if len(gt_boxes) == 0:
            LOGGER.warning(f"   âš ï¸ æœªæ£€æµ‹åˆ°Ground Truthæ ‡æ³¨ï¼è¯·æ£€æŸ¥æ ‡ç­¾æ–‡ä»¶")
        else:
            LOGGER.info(f"   âœ… Ground Truth: {len(gt_boxes)} ä¸ªç›®æ ‡")
        
        # å‡†å¤‡å¯è§†åŒ–å›¾åƒåˆ—è¡¨
        vis_images = []
        vis_titles = []
        
        # 1. Ground Truthï¼ˆæŒ‰ç±»åˆ«ç€è‰²ï¼‰
        gt_img = draw_boxes(image, gt_boxes, label="GT", show_class=True)
        vis_images.append(gt_img)
        vis_titles.append(f"Ground Truth ({len(gt_boxes)})")
        
        # 2. æ¯ä¸ªå°ºåº¦çš„æ£€æµ‹ç»“æœï¼ˆæŒ‰ç±»åˆ«ç€è‰²ï¼‰
        all_scale_boxes = []
        
        for i, scale in enumerate(scales):
            boxes = self.predict_single_scale(image, scale, conf, iou)
            all_scale_boxes.append(boxes)
            
            # ä¸æŒ‡å®šé¢œè‰²ï¼Œè®©å…¶æŒ‰ç±»åˆ«è‡ªåŠ¨åˆ†é…
            scale_img = draw_boxes(image, boxes, label=f"Scale {scale}", show_class=True)
            vis_images.append(scale_img)
            vis_titles.append(f"Scale {scale} ({len(boxes)})")
            
            LOGGER.info(f"   Scale {scale}: {len(boxes)} ä¸ªæ£€æµ‹")
        
        # 3. èåˆç»“æœï¼ˆæŒ‰ç±»åˆ«ç€è‰²ï¼‰
        fused_boxes = self.nms_fusion(all_scale_boxes, iou, class_agnostic=class_agnostic_nms)
        fused_img = draw_boxes(image, fused_boxes, label="Fused", show_class=True)
        vis_images.append(fused_img)
        vis_titles.append(f"Fused ({len(fused_boxes)})")
        
        LOGGER.info(f"   æœ€ç»ˆèåˆ: {len(fused_boxes)} ä¸ªæ£€æµ‹")
        
        # åˆ›å»ºç½‘æ ¼å›¾åƒ
        grid = create_grid_image(vis_images, vis_titles, cell_size)
        
        # ä¿å­˜
        scale_str = "_".join(map(str, scales))
        save_path = Path(save_dir) / f"{self.model_name}_{scale_str}" / f"{image_path.stem}_multiscale.jpg"
        save_path.parent.mkdir(parents=True, exist_ok=True)
        
        cv2.imwrite(str(save_path), grid)
        LOGGER.info(f"   âœ… ä¿å­˜: {save_path}")
        
        return str(save_path)
    
    def visualize_directory(
        self,
        image_dir: str,
        label_dir: str,
        scales: List[int],
        save_dir: str,
        conf: float = 0.25,
        iou: float = 0.5,
        cell_size: int = 640,
        max_images: int = None,
        class_agnostic_nms: bool = True,
    ):
        """
        æ‰¹é‡å¯è§†åŒ–ç›®å½•ä¸­çš„å›¾åƒ
        
        Args:
            image_dir: å›¾åƒç›®å½•
            label_dir: æ ‡ç­¾ç›®å½•
            scales: å°ºåº¦åˆ—è¡¨
            save_dir: ä¿å­˜ç›®å½•
            conf: ç½®ä¿¡åº¦é˜ˆå€¼
            iou: NMS IoUé˜ˆå€¼
            cell_size: å•å…ƒæ ¼å¤§å°
            max_images: æœ€å¤§å¤„ç†å›¾åƒæ•°
            class_agnostic_nms: æ˜¯å¦ä½¿ç”¨è·¨ç±»åˆ«NMSï¼ˆé»˜è®¤Trueï¼Œè§£å†³å¤šæ ‡ç­¾é‡å¤é—®é¢˜ï¼‰
        """
        image_dir = Path(image_dir)
        label_dir = Path(label_dir)
        
        # è·å–å›¾åƒåˆ—è¡¨
        image_files = []
        for ext in [".jpg", ".jpeg", ".png", ".bmp"]:
            image_files.extend(image_dir.glob(f"*{ext}"))
            image_files.extend(image_dir.glob(f"*{ext.upper()}"))
        
        if max_images:
            image_files = image_files[:max_images]
        
        LOGGER.info(f"ğŸ¯ å¼€å§‹æ‰¹é‡å¯è§†åŒ– ({len(image_files)} å¼ å›¾åƒ)")
        LOGGER.info(f"   å›¾åƒç›®å½•: {image_dir}")
        LOGGER.info(f"   æ ‡ç­¾ç›®å½•: {label_dir}")
        
        for i, img_path in enumerate(image_files, 1):
            label_path = label_dir / f"{img_path.stem}.txt"
            
            LOGGER.info(f"\n[{i}/{len(image_files)}]")
            try:
                self.visualize_image(
                    str(img_path), str(label_path), scales, save_dir, conf, iou, cell_size, class_agnostic_nms
                )
            except Exception as e:
                LOGGER.error(f"   âŒ å¤„ç†å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
        
        LOGGER.info(f"\nâœ… æ‰¹é‡å¯è§†åŒ–å®Œæˆï¼")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="å¤šå°ºåº¦æ£€æµ‹ç»“æœå¯è§†åŒ–",
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )
    
    parser.add_argument("--model", type=str, required=True, help="æ¨¡å‹è·¯å¾„")
    parser.add_argument("--image", type=str, help="å•å¼ å›¾åƒè·¯å¾„")
    parser.add_argument("--image-dir", type=str, help="å›¾åƒç›®å½•ï¼ˆæ‰¹é‡å¤„ç†ï¼‰")
    parser.add_argument("--label", type=str, help="å•å¼ æ ‡ç­¾è·¯å¾„")
    parser.add_argument("--label-dir", type=str, help="æ ‡ç­¾ç›®å½•ï¼ˆæ‰¹é‡å¤„ç†ï¼‰")
    parser.add_argument("--scales", type=int, nargs="+", default=[640, 832, 1024, 1280],
                       help="å°ºåº¦åˆ—è¡¨")
    parser.add_argument("--save-dir", type=str, default="runs/multiscale_visible", help="ä¿å­˜ç›®å½•")
    parser.add_argument("--conf", type=float, default=0.25, help="ç½®ä¿¡åº¦é˜ˆå€¼")
    parser.add_argument("--iou", type=float, default=0.5, help="NMS IoUé˜ˆå€¼")
    parser.add_argument("--cell-size", type=int, default=640, help="å•å…ƒæ ¼å¤§å°")
    parser.add_argument("--device", type=str, default="cuda:0", help="è®¾å¤‡")
    parser.add_argument("--max-images", type=int, default=None, help="æœ€å¤§å¤„ç†å›¾åƒæ•°")
    parser.add_argument("--no-cross-class-nms", action="store_true", 
                       help="ç¦ç”¨è·¨ç±»åˆ«NMSï¼ˆé»˜è®¤å¯ç”¨ï¼Œè§£å†³å¤šæ ‡ç­¾é‡å¤é—®é¢˜ï¼‰")
    
    args = parser.parse_args()
    
    try:
        visualizer = MultiscaleVisualizer(args.model, args.device)
        class_agnostic_nms = not args.no_cross_class_nms
        
        LOGGER.info(f"ğŸ”§ è·¨ç±»åˆ«NMS: {'å¯ç”¨' if class_agnostic_nms else 'ç¦ç”¨'}")
        
        if args.image and args.label:
            # å•å¼ å›¾åƒ
            visualizer.visualize_image(
                args.image, args.label, args.scales, args.save_dir,
                args.conf, args.iou, args.cell_size, class_agnostic_nms
            )
        elif args.image_dir and args.label_dir:
            # æ‰¹é‡å¤„ç†
            visualizer.visualize_directory(
                args.image_dir, args.label_dir, args.scales, args.save_dir,
                args.conf, args.iou, args.cell_size, args.max_images, class_agnostic_nms
            )
        else:
            LOGGER.error("âŒ è¯·æä¾› --image/--label æˆ– --image-dir/--label-dir")
            
    except Exception as e:
        LOGGER.error(f"âŒ å¯è§†åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()

